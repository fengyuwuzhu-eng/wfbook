# 排错

[TOC]

You might need to investigate why a cephadm command failed or why a certain service no longer runs properly.

Cephadm deploys daemons as containers. This means that troubleshooting those containerized daemons might work differently than you expect (and that is certainly true if you expect this troubleshooting to work the way that troubleshooting does when the daemons involved aren’t containerized).

Here are some tools and commands to help you troubleshoot your Ceph environment.



## Pausing or disabling cephadm

If something goes wrong and cephadm is behaving badly, you can pause most of the Ceph cluster’s background activity by running the following command:

```
ceph orch pause
```

This stops all changes in the Ceph cluster, but cephadm will still periodically check hosts to refresh its inventory of daemons and devices.  You can disable cephadm completely by running the following commands:

```
ceph orch set backend ''
ceph mgr module disable cephadm
```

These commands disable all of the `ceph orch ...` CLI commands. All previously deployed daemon containers continue to exist and will start as they did before you ran these commands.

See [Disabling automatic deployment of daemons](https://docs.ceph.com/en/latest/cephadm/services/#cephadm-spec-unmanaged) for information on disabling individual services.

## Per-service and per-daemon events

In order to help with the process of debugging failed daemon deployments, cephadm stores events per service and per daemon. These events often contain information relevant to troubleshooting your Ceph cluster.

### Listing service events

To see the events associated with a certain service, run a command of the and following form:

```
ceph orch ls --service_name=<service-name> --format yaml
```

This will return something in the following form:

```
service_type: alertmanager
service_name: alertmanager
placement:
  hosts:
  - unknown_host
status:
  ...
  running: 1
  size: 1
events:
- 2021-02-01T08:58:02.741162 service:alertmanager [INFO] "service was created"
- '2021-02-01T12:09:25.264584 service:alertmanager [ERROR] "Failed to apply: Cannot
  place <AlertManagerSpec for service_name=alertmanager> on unknown_host: Unknown hosts"'
```

### Listing daemon events

To see the events associated with a certain daemon, run a command of the and following form:

```
ceph orch ps --service-name <service-name> --daemon-id <daemon-id> --format yaml
```

This will return something in the following form:

```
daemon_type: mds
daemon_id: cephfs.hostname.ppdhsz
hostname: hostname
status_desc: running
...
events:
- 2021-02-01T08:59:43.845866 daemon:mds.cephfs.hostname.ppdhsz [INFO] "Reconfigured
  mds.cephfs.hostname.ppdhsz on host 'hostname'"
```

## Checking cephadm logs

To learn how to monitor the cephadm logs as they are generated, read [Watching cephadm log messages](https://docs.ceph.com/en/latest/cephadm/operations/#watching-cephadm-logs).

If your Ceph cluster has been configured to log events to files, there will exist a cephadm log file called `ceph.cephadm.log` on all monitor hosts (see [Ceph daemon logs](https://docs.ceph.com/en/latest/cephadm/operations/#cephadm-logs) for a more complete explanation of this).

## Gathering log files

Use journalctl to gather the log files of all daemons:

Note

By default cephadm now stores logs in journald. This means that you will no longer find daemon logs in `/var/log/ceph/`.

To read the log file of one specific daemon, run:

```
cephadm logs --name <name-of-daemon>
```

Note: this only works when run on the same host where the daemon is running. To get logs of a daemon running on a different host, give the `--fsid` option:

```
cephadm logs --fsid <fsid> --name <name-of-daemon>
```

where the `<fsid>` corresponds to the cluster ID printed by `ceph status`.

To fetch all log files of all daemons on a given host, run:

```
for name in $(cephadm ls | jq -r '.[].name') ; do
  cephadm logs --fsid <fsid> --name "$name" > $name;
done
```

## Collecting systemd status

To print the state of a systemd unit, run:

```
systemctl status "ceph-$(cephadm shell ceph fsid)@<service name>.service";
```

To fetch all state of all daemons of a given host, run:

```
fsid="$(cephadm shell ceph fsid)"
for name in $(cephadm ls | jq -r '.[].name') ; do
  systemctl status "ceph-$fsid@$name.service" > $name;
done
```

## List all downloaded container images

To list all container images that are downloaded on a host:

Note

`Image` might also be called ImageID

```
podman ps -a --format json | jq '.[].Image'
"docker.io/library/centos:8"
"registry.opensuse.org/opensuse/leap:15.2"
```

## Manually running containers

Cephadm writes small wrappers that run a containers. Refer to `/var/lib/ceph/<cluster-fsid>/<service-name>/unit.run` for the container execution command.



## ssh errors

Error message:

```
execnet.gateway_bootstrap.HostNotFound: -F /tmp/cephadm-conf-73z09u6g -i /tmp/cephadm-identity-ky7ahp_5 root@10.10.1.2
...
raise OrchestratorError(msg) from e
orchestrator._interface.OrchestratorError: Failed to connect to 10.10.1.2 (10.10.1.2).
Please make sure that the host is reachable and accepts connections using the cephadm SSH key
...
```

Things users can do:

1. Ensure cephadm has an SSH identity key:

   ```
   [root@mon1~]# cephadm shell -- ceph config-key get mgr/cephadm/ssh_identity_key > ~/cephadm_private_key
   INFO:cephadm:Inferring fsid f8edc08a-7f17-11ea-8707-000c2915dd98
   INFO:cephadm:Using recent ceph image docker.io/ceph/ceph:v15 obtained 'mgr/cephadm/ssh_identity_key'
   [root@mon1 ~] # chmod 0600 ~/cephadm_private_key
   ```

> If this fails, cephadm doesn’t have a key. Fix this by running the following command:
>
> ```
> [root@mon1 ~]# cephadm shell -- ceph cephadm generate-ssh-key
> ```
>
> or:
>
> ```
> [root@mon1 ~]# cat ~/cephadm_private_key | cephadm shell -- ceph cephadm set-ssk-key -i -
> ```

1. Ensure that the ssh config is correct:

   ```
   [root@mon1 ~]# cephadm shell -- ceph cephadm get-ssh-config > config
   ```

2. Verify that we can connect to the host:

   ```
   [root@mon1 ~]# ssh -F config -i ~/cephadm_private_key root@mon1
   ```

### Verifying that the Public Key is Listed in the authorized_keys file

To verify that the public key is in the authorized_keys file, run the following commands:

```
[root@mon1 ~]# cephadm shell -- ceph cephadm get-pub-key > ~/ceph.pub
[root@mon1 ~]# grep "`cat ~/ceph.pub`"  /root/.ssh/authorized_keys
```

## Failed to infer CIDR network error

If you see this error:

```
ERROR: Failed to infer CIDR network for mon ip ***; pass --skip-mon-network to configure it later
```

Or this error:

```
Must set public_network config option or specify a CIDR network, ceph addrvec, or plain IP
```

This means that you must run a command of this form:

```
ceph config set mon public_network <mon_network>
```

For more detail on operations of this kind, see [Deploying additional monitors](https://docs.ceph.com/en/latest/cephadm/services/mon/#deploy-additional-monitors)

## Accessing the admin socket

Each Ceph daemon provides an admin socket that bypasses the MONs (See [Using the Admin Socket](https://docs.ceph.com/en/latest/rados/operations/monitoring/#rados-monitoring-using-admin-socket)).

To access the admin socket, first enter the daemon container on the host:

```
[root@mon1 ~]# cephadm enter --name <daemon-name>
[ceph: root@mon1 /]# ceph --admin-daemon /var/run/ceph/ceph-<daemon-name>.asok config show
```

## Calling miscellaneous ceph tools

To call miscellaneous like `ceph-objectstore-tool` or `ceph-monstore-tool`, you can run them by calling `cephadm shell --name <daemon-name>` like so:

```
root@myhostname # cephadm unit --name mon.myhostname stop
root@myhostname # cephadm shell --name mon.myhostname
[ceph: root@myhostname /]# ceph-monstore-tool /var/lib/ceph/mon/ceph-myhostname get monmap > monmap
[ceph: root@myhostname /]# monmaptool --print monmap
monmaptool: monmap file monmap
epoch 1
fsid 28596f44-3b56-11ec-9034-482ae35a5fbb
last_changed 2021-11-01T20:57:19.755111+0000
created 2021-11-01T20:57:19.755111+0000
min_mon_release 17 (quincy)
election_strategy: 1
0: [v2:127.0.0.1:3300/0,v1:127.0.0.1:6789/0] mon.myhostname
```

This command sets up the environment in a way that is suitable for extended daemon maintenance and running the daemon interactively.



## Restoring the MON quorum

In case the Ceph MONs cannot form a quorum, cephadm is not able to manage the cluster, until the quorum is restored.

In order to restore the MON quorum, remove unhealthy MONs form the monmap by following these steps:

1. Stop all MONs. For each MON host:

   ```
   ssh {mon-host}
   cephadm unit --name mon.`hostname` stop
   ```

2. Identify a surviving monitor and log in to that host:

   ```
   ssh {mon-host}
   cephadm enter --name mon.`hostname`
   ```

3. Follow the steps in [Removing Monitors from an Unhealthy Cluster](https://docs.ceph.com/en/latest/rados/operations/add-or-rm-mons/#rados-mon-remove-from-unhealthy)



## Manually deploying a MGR daemon

cephadm requires a MGR daemon in order to manage the cluster. In case the cluster the last MGR of a cluster was removed, follow these steps in order to deploy a MGR `mgr.hostname.smfvfd` on a random host of your cluster manually.

Disable the cephadm scheduler, in order to prevent cephadm from removing the new MGR. See [Enable Ceph CLI](https://docs.ceph.com/en/latest/cephadm/install/#cephadm-enable-cli):

```
ceph config-key set mgr/cephadm/pause true
```

Then get or create the auth entry for the new MGR:

```
ceph auth get-or-create mgr.hostname.smfvfd mon "profile mgr" osd "allow *" mds "allow *"
```

Get the ceph.conf:

```
ceph config generate-minimal-conf
```

Get the container image:

```
ceph config get "mgr.hostname.smfvfd" container_image
```

Create a file `config-json.json` which contains the information necessary to deploy the daemon:

```
{
  "config": "# minimal ceph.conf for 8255263a-a97e-4934-822c-00bfe029b28f\n[global]\n\tfsid = 8255263a-a97e-4934-822c-00bfe029b28f\n\tmon_host = [v2:192.168.0.1:40483/0,v1:192.168.0.1:40484/0]\n",
  "keyring": "[mgr.hostname.smfvfd]\n\tkey = V2VyIGRhcyBsaWVzdCBpc3QgZG9vZi4=\n"
}
```

Deploy the daemon:

```
cephadm --image <container-image> deploy --fsid <fsid> --name mgr.hostname.smfvfd --config-json config-json.json
```

## Analyzing core dumps

In case a Ceph daemon crashes, cephadm supports analyzing core dumps. To enable core dumps, run

```
ulimit -c unlimited
```

core dumps will now be written to `/var/lib/systemd/coredump`.

Note

core dumps are not namespaced by the kernel, which means they will be written to `/var/lib/systemd/coredump` on the container host.

Now, wait for the crash to happen again. (To simulate the crash of a daemon, run e.g. `killall -3 ceph-mon`)

Install debug packages by entering the cephadm shell and install `ceph-debuginfo`:

```
# cephadm shell --mount /var/lib/systemd/coredump
[ceph: root@host1 /]# dnf install ceph-debuginfo gdb zstd
[ceph: root@host1 /]# unzstd /mnt/coredump/core.ceph-*.zst
[ceph: root@host1 /]# gdb /usr/bin/ceph-mon /mnt/coredump/core.ceph-...
(gdb) bt
#0  0x00007fa9117383fc in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x00007fa910d7f8f0 in std::condition_variable::wait(std::unique_lock<std::mutex>&) () from /lib64/libstdc++.so.6
#2  0x00007fa913d3f48f in AsyncMessenger::wait() () from /usr/lib64/ceph/libceph-common.so.2
#3  0x0000563085ca3d7e in main ()
```

​        

​			作为存储管理员，您可以在存储集群中遇到整个节点故障，并且处理节点故障与处理磁盘故障类似。如果节点出现故障，而不是 Ceph  只为一个磁盘恢复 PG，则必须恢复该节点上磁盘上的所有 PG。Ceph 将检测 OSD 已停机并自动启动恢复过程，称为自我修复。 	

​			有三种节点故障情况：以下是替换节点时每个场景的高级工作流： 	

- ​					替换 节点，但从故障节点使用根和 Ceph OSD 磁盘。 			
  1. ​							禁用回填。 					
  2. ​							替换节点，从旧节点获取磁盘，并将它们添加到新节点中。 					
  3. ​							启用回填. 					
- ​					替换节点，重新安装操作系统，并从故障节点使用 Ceph OSD 磁盘。 			
  1. ​							禁用回填。 					
  2. ​							创建 Ceph 配置的备份。 					
  3. ​							替换 节点，再添加来自故障节点的 Ceph OSD 磁盘。 					
  4. ​							将磁盘配置为 JBOD. 					
  5. ​							安装操作系统。 					
  6. ​							恢复 Ceph 配置。 					
  7. ​							使用 Ceph 编排器命令将新节点添加到存储群集，并且 Ceph 守护进程会自动放置到对应的节点上。 					
  8. ​							启用回填. 					
- ​					替换 节点，重新安装操作系统，并且使用所有新的 Ceph OSD 磁盘。 			
  1. ​							禁用回填。 					
  2. ​							从存储集群移除故障节点上的所有 OSD。 					
  3. ​							创建 Ceph 配置的备份。 					
  4. ​							替换 节点，再添加来自故障节点的 Ceph OSD 磁盘。 					
     1. ​									将磁盘配置为 JBOD. 							
  5. ​							安装操作系统。 					
  6. ​							使用 Ceph 编排器命令将新节点添加到存储群集，并且 Ceph 守护进程会自动放置到对应的节点上。 					
  7. ​							启用回填. 					



# 添加或删除节点前的注意事项

​				Ceph 的一个出色的功能是在运行时添加或删除 Ceph OSD 节点。这意味着您可以调整存储集群容量的大小，或者在不关闭存储集群的情况下替换硬件。 		

​				当存储集群处于 `降级` 状态时，能够为 Ceph 客户端提供服务也具有操作优势。例如，您可以在正常工作时间内添加或删除或删除或替换硬件，而不是在加班或周间工作。但是，添加和移除 Ceph OSD 节点可能会对性能产生重大影响。 		

​				在添加或删除 Ceph OSD 节点前，请考虑对存储集群性能的影响： 		

- ​						无论您是扩展还是缩小存储集群容量，添加或删除 Ceph OSD 节点都会减少回填，作为存储集群重新平衡。在重新平衡期间，Ceph 使用其他资源，这可能会影响存储集群性能。 				
- ​						在生产用 Ceph 存储集群中，Ceph OSD 节点具有促进特定类型存储策略的特定硬件配置。 				
- ​						由于 Ceph OSD 节点是 CRUSH 层次结构的一部分，添加或删除节点的性能影响通常会影响使用 CRUSH 规则集的池的性能。 				



# 性能注意事项

​				在添加或删除 Ceph OSD 节点时，以下因素通常影响存储集群的性能： 		

- ​						Ceph 客户端将 I/O 接口的负载放在 Ceph；即，客户端将负载放入池。池映射到 CRUSH 规则集。Ceph 底层  CRUSH 层次结构允许 Ceph 在故障域之间放置数据。如果底层 Ceph OSD  节点涉及的池正在经历较高的客户端负载，客户端的负载可能会严重影响恢复时间并降低性能。由于写入操作需要数据复制以实现持久性，尤其是写入密集型客户端负载可增加存储集群恢复的时间。 				
- ​						通常，您要添加或删除的容量会影响存储集群恢复的时间。另外，添加或删除的节点的存储密度也可能影响恢复时间。例如，具有 36 个 OSD 的节点恢复通常比具有 12 个 OSD 的节点要长。 				
- ​						删除节点时，您必须确保您有足够的备用容量，以便您不会达到 `满比率` `或接近满比率`。如果存储群集达到 `满比率`，Ceph 将暂停写入操作，以防止数据丢失。 				
- ​						Ceph OSD 节点至少映射到一个 Ceph CRUSH 层次结构，其层次结构至少映射到一个池。使用 CRUSH 规则集的每个池在添加或删除 Ceph OSD 节点时都会遇到性能影响。 				
- ​						复制池往往使用更多的网络带宽来复制数据的深度副本，而纠删代码池则往往使用更多 CPU 来计算 `k+m` 编码区块。数据副本越多，存储集群恢复所需的时间就会越长。例如，一个更大的池或具有更多 `k+m` 块的池，恢复所需的时间要长于具有相同数据副本较少的复制池。 				
- ​						驱动器、控制器和网络接口卡都具有可能会影响恢复时间的吞吐量特征。通常，吞吐量较高的节点（如 10 Gbps 和 SSD）的恢复速度要快于吞吐量较低的节点，如 1 Gbps 和 SATA 驱动器。 				



# 添加或删除节点的建议

​				红帽建议在节点内一次性添加或删除一个 OSD，并在继续下一 OSD 前允许存储集群恢复。这有助于最小化对存储集群性能的影响。请注意，如果节点出现故障，您可能需要一次更改整个节点，而不必一次更改一个 OSD。 		

​				删除 OSD： 		

- ​						[*使用 Ceph 编排器移除 OSD 守护进程*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#removing-the-osd-daemons-using-the-ceph-orchestrator_ops). 				

​				添加 OSD： 		

- ​						[*在所有可用设备上使用部署 Ceph OSD*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#deploying-ceph-osds-on-all-available-devices_ops). 				
- ​						[*利用高级服务规范部署 Ceph OSD.*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#deploying-ceph-osds-using-advanced-service-specifications_ops) 				
- ​						使用 [*在特定设备和主机上部署 Ceph OSD.*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#deploying-ceph-osds-on-specific-devices-and-hosts_ops) 				

​				在添加或删除 Ceph OSD 节点时，请考虑其他持续进程对存储集群性能的影响。要减少对客户端 I/O 的影响，红帽建议以下内容： 		

**计算容量**

​					在移除 Ceph OSD 节点之前，请确保存储集群可以回填其所有 OSD 的内容，而不达到 `满比率`。达到 `满比率` 将导致存储集群拒绝写入操作。 			

**临时禁用清理**

​					清理对于确保存储集群数据的持久性至关重要，但它需要消耗大量资源。在添加或删除 Ceph OSD 节点之前，请先禁用清理和深度清理，并在继续操作前让当前的清理完成。 			

```none
ceph osd set noscrub
ceph osd set nodeep-scrub
```

​				添加或删除 Ceph OSD 节点并且存储集群返回到 `active+clean` 状态后，取消设置 `noscrub` 和 `nodeep-scrub` 设置。 		

```none
ceph osd unset noscrub
ceph osd unset nodeep-scrub
```

**限制回填和恢复**

​					如果您有合理的数据持久性，在 `降级` 状态下操作不会有任何问题。例如，您可以使用 osd_pool_default `_size = 3 和 osd_pool_default _min_size = 2` 来运行存储集群。您可以对存储集群进行可能的恢复速度最快的调整，但这对 Ceph 客户端 I/O 性能有很大影响。为保持最高的 Ceph 客户端 I/O 性能，请限制回填和恢复操作，并允许它们花费更长的时间。 			

```none
osd_max_backfills = 1
osd_recovery_max_active = 1
osd_recovery_op_priority = 1
```

​				您还可以考虑设置睡眠参数和延迟参数，如 `osd_recovery_sleep`。 		

**增加 PG 数量**

​					最后，如果您要扩展存储集群的大小，可能需要增加放置组的数量。如果您确定需要扩展 PG 数量，红帽建议增加 PG 数量。将放置组数量显著增加将会导致性能下降。 			



# 添加 Ceph OSD 节点

​				若要扩展红帽 Ceph 存储集群的容量，您可以添加 OSD 节点。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						具有网络连接的置备节点。 				

**流程**

1. ​						验证存储集群中的其他节点可以通过其短主机名访问新节点。 				

2. ​						临时禁用清理： 				

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph osd set noscrub
   [ceph: root@host01 /]# ceph osd set nodeep-scrub
   ```

3. ​						限制回填和恢复功能： 				

   **语法**

   ​							

   ```none
   ceph tell DAEMON_TYPE.* injectargs --OPTION_NAME VALUE [--OPTION_NAME VALUE]
   ```

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph tell osd.* injectargs --osd-max-backfills 1 --osd-recovery-max-active 1 --osd-recovery-op-priority 1
   ```

4. ​						将集群的公共 SSH 密钥提取到文件夹中： 				

   **语法**

   ​							

   ```none
   ceph cephadm get-pub-key > ~/PATH
   ```

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph cephadm get-pub-key > ~/ceph.pub
   ```

5. ​						将 ceph 集群的公共 SSH 密钥复制到新主机上的 root 用户的 `authorized_keys` 文件中： 				

   **语法**

   ​							

   ```none
   ssh-copy-id -f -i ~/PATH root@HOST_NAME_2
   ```

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ssh-copy-id -f -i ~/ceph.pub root@host02
   ```

6. ​						将新节点添加到 CRUSH map： 				

   **语法**

   ​							

   ```none
   ceph orch host add NODE_NAME IP_ADDRESS
   ```

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph orch host add host02 168.20.20.2
   ```

7. ​						为节点上的每个磁盘添加一个 OSD 到存储集群。 				

   - ​								[*在所有可用设备上使用部署 Ceph OSD*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#deploying-ceph-osds-on-all-available-devices_ops). 						
   - ​								[*利用高级服务规范部署 Ceph OSD.*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#deploying-ceph-osds-using-advanced-service-specifications_ops) 						
   - ​								使用 [*在特定设备和主机上部署 Ceph OSD.*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#deploying-ceph-osds-on-specific-devices-and-hosts_ops) 						

重要

​					在添加 OSD 节点到红帽 Ceph 存储集群时，红帽建议一次添加一个 OSD 守护进程，并在继续下一 OSD 前让集群恢复到 `active+clean` 状态。 			

# 删除 Ceph OSD 节点

​				要减少存储集群的容量，请移除 OSD 节点。 		

警告

​					在移除 Ceph OSD 节点之前，请确保存储集群可以回填所有 OSD 的内容，而不达到 `满比率`。达到 `满比率` 将导致存储集群拒绝写入操作。 			

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						对存储集群中所有节点的根级别访问权限。 				

**流程**

1. ​						检查存储集群的容量： 				

   **语法**

   ​							

   ```none
   ceph df
   rados df
   ceph osd df
   ```

2. ​						临时禁用清理： 				

   **语法**

   ​							

   ```none
   ceph osd set noscrub
   ceph osd set nodeep-scrub
   ```

3. ​						限制回填和恢复功能： 				

   **语法**

   ​							

   ```none
   ceph tell DAEMON_TYPE.* injectargs --OPTION_NAME VALUE [--OPTION_NAME VALUE]
   ```

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph tell osd.* injectargs --osd-max-backfills 1 --osd-recovery-max-active 1 --osd-recovery-op-priority 1
   ```

4. ​						从存储集群中移除节点上的每个 OSD： 				

   - ​								[*使用 Ceph 编排器移除 OSD 守护进程*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#removing-the-osd-daemons-using-the-ceph-orchestrator_ops). 						

     重要

     ​									在从存储集群中删除 OSD 节点时，红帽建议在节点上一次移除一个 OSD，并在继续移除下一个 OSD 之前，让集群恢复到 `active+clean` 状态。 							

     1. ​										删除 OSD 后，检查以确认存储集群没有达到 `接近完整比率` ： 								

        **语法**

        ​											

        ```none
        ceph -s
        ceph df
        ```

     2. ​										重复此步骤，直到节点上的所有 OSD 都从存储集群中移除。 								

5. ​						移除所有 OSD 后，删除主机： 				

   - ​								[*使用 Ceph 编排器使用删除主机.*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#removing-hosts-using-the-ceph-orchestrator_ops) 						



# 模拟节点失败

​				要模拟硬节点故障，请关闭节点并重新安装操作系统。 		

**先决条件**

- ​						运行正常的红帽 Ceph 存储集群。 				
- ​						对存储集群上所有节点的根级别访问权限。 				

**流程**

1. ​						检查存储集群的容量以了解删除节点的影响： 				

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph df
   [ceph: root@host01 /]# rados df
   [ceph: root@host01 /]# ceph osd df
   ```

2. ​						另外，还可禁用恢复和回填： 				

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph osd set noout
   [ceph: root@host01 /]# ceph osd set noscrub
   [ceph: root@host01 /]# ceph osd set nodeep-scrub
   ```

3. ​						关闭节点。 				

4. ​						如果要更改主机名，请从 CRUSH map 中删除节点： 				

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph osd crush rm host03
   ```

5. ​						检查存储集群的状态： 				

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph -s
   ```

6. ​						在节点上重新安装操作系统。 				

7. ​						添加新节点： 				

   - ​								[*使用 Ceph 编排器使用添加主机*](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/operations_guide/#adding-hosts-using-the-ceph-orchestrator_ops). 						

8. ​						另外，还可启用恢复和回填： 				

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph osd unset noout
   [ceph: root@host01 /]# ceph osd unset noscrub
   [ceph: root@host01 /]# ceph osd unset nodeep-scrub
   ```

9. ​						检查 Ceph 的健康状态： 				

   **示例**

   ​							

   ```none
   [ceph: root@host01 /]# ceph -s
   ```



Sometimes there is a need to investigate why a cephadm command failed or why a specific service no longer runs properly.

As cephadm deploys daemons as containers, troubleshooting daemons is slightly different. Here are a few tools and commands to help investigating issues.



## Pausing or disabling cephadm

If something goes wrong and cephadm is doing behaving in a way you do not like, you can pause most background activity with:

```
ceph orch pause
```

This will stop any changes, but cephadm will still periodically check hosts to refresh its inventory of daemons and devices.  You can disable cephadm completely with:

```
ceph orch set backend ''
ceph mgr module disable cephadm
```

This will disable all of the `ceph orch ...` CLI commands but the previously deployed daemon containers will still continue to exist and start as they did before.

Please refer to [Disable automatic deployment of daemons](https://docs.ceph.com/en/latest/cephadm/service-management/#cephadm-spec-unmanaged) for disabling individual services.

## Per-service and per-daemon events

In order to aid debugging failed daemon deployments, cephadm stores events per service and per daemon. They often contain relevant information:

```
ceph orch ls --service_name=<service-name> --format yaml
```

for example:

```yaml
service_type: alertmanager
service_name: alertmanager
placement:
  hosts:
  - unknown_host
status:
  ...
  running: 1
  size: 1
events:
- 2021-02-01T08:58:02.741162 service:alertmanager [INFO] "service was created"
- '2021-02-01T12:09:25.264584 service:alertmanager [ERROR] "Failed to apply: Cannot
  place <AlertManagerSpec for service_name=alertmanager> on unknown_host: Unknown hosts"'
```

Or per daemon:

```bash
ceph orch ceph --service-type mds --daemon-id=hostname.ppdhsz --format yaml
daemon_type: mds
daemon_id: cephfs.hostname.ppdhsz
hostname: hostname
status_desc: running
...
events:
- 2021-02-01T08:59:43.845866 daemon:mds.cephfs.hostname.ppdhsz [INFO] "Reconfigured
  mds.cephfs.hostname.ppdhsz on host 'hostname'"
```

## Checking cephadm logs

You can monitor the cephadm log in real time with:

```
ceph -W cephadm
```

You can see the last few messages with:

```
ceph log last cephadm
```

If you have enabled logging to files, you can see a cephadm log file called `ceph.cephadm.log` on monitor hosts (see [Ceph daemon logs](https://docs.ceph.com/en/latest/cephadm/operations/#cephadm-logs)).

## Gathering log files

Use journalctl to gather the log files of all daemons:

Note

By default cephadm now stores logs in journald. This means that you will no longer find daemon logs in `/var/log/ceph/`.

To read the log file of one specific daemon, run:

```
cephadm logs --name <name-of-daemon>
```

Note: this only works when run on the same host where the daemon is running. To get logs of a daemon running on a different host, give the `--fsid` option:

```bash
cephadm logs --fsid <fsid> --name <name-of-daemon>
```

where the `<fsid>` corresponds to the cluster ID printed by `ceph status`.

To fetch all log files of all daemons on a given host, run:

```bash
for name in $(cephadm ls | jq -r '.[].name') ; do
  cephadm logs --fsid <fsid> --name "$name" > $name;
done
```

## Collecting systemd status

To print the state of a systemd unit, run:

```
systemctl status "ceph-$(cephadm shell ceph fsid)@<service name>.service";
```

To fetch all state of all daemons of a given host, run:

```bash
fsid="$(cephadm shell ceph fsid)"
for name in $(cephadm ls | jq -r '.[].name') ; do
  systemctl status "ceph-$fsid@$name.service" > $name;
done
```

## 列出所有已下载的容器镜像

```
podman ps -a --format json | jq '.[].Image'
"docker.io/library/centos:8"
"registry.opensuse.org/opensuse/leap:15.2"
```

## Manually running containers

Cephadm writes small wrappers that run a containers. Refer to `/var/lib/ceph/<cluster-fsid>/<service-name>/unit.run` for the container execution command.



## ssh 错误

Error message:

```bash
execnet.gateway_bootstrap.HostNotFound: -F /tmp/cephadm-conf-73z09u6g -i /tmp/cephadm-identity-ky7ahp_5 root@10.10.1.2
...
raise OrchestratorError(msg) from e
orchestrator._interface.OrchestratorError: Failed to connect to 10.10.1.2 (10.10.1.2).
Please make sure that the host is reachable and accepts connections using the cephadm SSH key
...
```

Things users can do:

1. Ensure cephadm has an SSH identity key:

   ```
   [root@mon1~]# cephadm shell -- ceph config-key get mgr/cephadm/ssh_identity_key > ~/cephadm_private_key
   INFO:cephadm:Inferring fsid f8edc08a-7f17-11ea-8707-000c2915dd98
   INFO:cephadm:Using recent ceph image docker.io/ceph/ceph:v15 obtained 'mgr/cephadm/ssh_identity_key'
   [root@mon1 ~] # chmod 0600 ~/cephadm_private_key
   ```

> If this fails, cephadm doesn’t have a key. Fix this by running the following command:
>
> ```
> [root@mon1 ~]# cephadm shell -- ceph cephadm generate-ssh-key
> ```
>
> or:
>
> ```
> [root@mon1 ~]# cat ~/cephadm_private_key | cephadm shell -- ceph cephadm set-ssk-key -i -
> ```

1. Ensure that the ssh config is correct:

   ```
   [root@mon1 ~]# cephadm shell -- ceph cephadm get-ssh-config > config
   ```

2. Verify that we can connect to the host:

   ```
   [root@mon1 ~]# ssh -F config -i ~/cephadm_private_key root@mon1
   ```

### Verifying that the Public Key is Listed in the authorized_keys file

To verify that the public key is in the authorized_keys file, run the following commands:

```bash
[root@mon1 ~]# cephadm shell -- ceph cephadm get-pub-key > ~/ceph.pub
[root@mon1 ~]# grep "`cat ~/ceph.pub`"  /root/.ssh/authorized_keys
```

## Failed to infer CIDR network error

If you see this error:

```
ERROR: Failed to infer CIDR network for mon ip ***; pass --skip-mon-network to configure it later
```

Or this error:

```
Must set public_network config option or specify a CIDR network, ceph addrvec, or plain IP
```

This means that you must run a command of this form:

```
ceph config set mon public_network <mon_network>
```

For more detail on operations of this kind, see [Deploying additional monitors](https://docs.ceph.com/en/latest/cephadm/mon/#deploy-additional-monitors)

## Accessing the admin socket

Each Ceph daemon provides an admin socket that bypasses the MONs (See [Using the Admin Socket](https://docs.ceph.com/en/latest/rados/operations/monitoring/#rados-monitoring-using-admin-socket)).

To access the admin socket, first enter the daemon container on the host:

```
[root@mon1 ~]# cephadm enter --name <daemon-name>
[ceph: root@mon1 /]# ceph --admin-daemon /var/run/ceph/ceph-<daemon-name>.asok config show
```

## Restoring the MON quorum

In case the Ceph MONs cannot form a quorum, cephadm is not able to manage the cluster, until the quorum is restored.

In order to restore the MON quorum, remove unhealthy MONs form the monmap by following these steps:

1. Stop all MONs. For each MON host:

   ```
   ssh {mon-host}
   cephadm unit --name mon.`hostname` stop
   ```

2. Identify a surviving monitor and log in to that host:

   ```
   ssh {mon-host}
   cephadm enter --name mon.`hostname`
   ```

3. Follow the steps in [Removing Monitors from an Unhealthy Cluster](https://docs.ceph.com/en/latest/rados/operations/add-or-rm-mons/#rados-mon-remove-from-unhealthy)

## Manually deploying a MGR daemon

cephadm requires a MGR daemon in order to manage the cluster. In case the cluster the last MGR of a cluster was removed, follow these steps in order to deploy a MGR `mgr.hostname.smfvfd` on a random host of your cluster manually.

Disable the cephadm scheduler, in order to prevent cephadm from removing the new MGR. See [Enable Ceph CLI](https://docs.ceph.com/en/latest/cephadm/install/#cephadm-enable-cli):

```bash
ceph config-key set mgr/cephadm/pause true
```

Then get or create the auth entry for the new MGR:

```bash
ceph auth get-or-create mgr.hostname.smfvfd mon "profile mgr" osd "allow *" mds "allow *"
```

Get the ceph.conf:

```bash
ceph config generate-minimal-conf
```

Get the container image:

```bash
ceph config get "mgr.hostname.smfvfd" container_image
```

Create a file `config-json.json` which contains the information neccessary to deploy the daemon:

```json
{
  "config": "# minimal ceph.conf for 8255263a-a97e-4934-822c-00bfe029b28f\n[global]\n\tfsid = 8255263a-a97e-4934-822c-00bfe029b28f\n\tmon_host = [v2:192.168.0.1:40483/0,v1:192.168.0.1:40484/0]\n",
  "keyring": "[mgr.hostname.smfvfd]\n\tkey = V2VyIGRhcyBsaWVzdCBpc3QgZG9vZi4=\n"
}
```

Deploy the daemon:

```bash
cephadm --image <container-image> deploy --fsid <fsid> --name mgr.hostname.smfvfd --config-json config-json.json
```





# 处理数据中心故障

​			作为存储管理员，您可以采取强制措施以避免数据中心故障。这些强制措施包括： 	

- ​					配置数据中心基础架构. 			
- ​					在 CRUSH map 层次结构中设置故障域. 			
- ​					指定域中的故障节点. 			

# 避免数据中心故障

**配置数据中心基础架构**

​					扩展群集中的每个数据中心可以具有不同的存储集群配置，以反映本地功能和依赖项。在数据中心之间设置复制，以帮助保留数据。如果一个数据中心出现故障，存储集群中的其他数据中心将包含数据的副本。 			

**在 CRUSH map 层次结构中设置故障域**

​					域失败或故障转移是存储集群中域的冗余副本。如果某个活动域失败，则故障域将成为活动域。 			

​				默认情况下，CRUSH map 在扁平层次结构中列出存储群集中的所有节点。但是，为了获得最佳结果，在 CRUSH map  中创建逻辑层次结构。层次结构指定每个节点所属的域以及存储集群中这些域之间的关系，包括故障域。在层次结构中定义每个域的故障域可提高存储集群的可靠性。 		

​				在规划包含多个数据中心的存储集群时，请将节点置于 CRUSH map 层次结构中，以便在一个数据中心出现故障时，存储群集的其余部分会保持正常运行。 		

**在域中指定故障节点**

​					如果您计划对存储集群内的数据使用三向复制，请考虑故障域中节点的位置。如果数据中心内发生停机，则某些数据可能仅存在于一个副本中。发生这种情况时，有两个选项： 			

- ​						将数据保留为只读状态，使用标准设置。 				
- ​						在中断期间只使用一个副本进行实时。 				

​				使用标准设置，并且由于数据在节点间放置的随机性，并非所有数据都会受到影响，但一些数据只能有一个副本，存储集群将恢复到只读模式。但是，如果某些数据仅存在于一个副本中，则存储集群会恢复到只读模式。 		

# 处理数据中心故障

​				红帽 Ceph 存储可能会遭受基础架构的灾难性故障，例如丢失扩展群集中的一个数据中心。对于标准的对象存储用例，可以独立于它们之间的复制来配置所有三个数据中心。在这种情况下，每个数据中心中的存储集群配置可能会有所不同，这反映了本地功能和依赖项。 		

​				应考虑放置层次结构的逻辑结构。可以使用正确的 CRUSH  map，反映基础架构中故障域的层次结构。使用逻辑层次定义可提高存储群集的可靠性，而非使用标准层次结构定义。故障域在 CRUSH map  中定义。默认 CRUSH map  包含扁平层次结构中的所有节点。在三个数据中心环境中，如扩展集群，节点的放置应该以一个数据中心停机的方式进行管理，但存储集群会保持启动和运行。在对数据使用三向复制时，节点会驻留于哪个故障域。 		

​				在下例中，生成的 map 派生自具有 6 个 OSD 节点的存储集群的初始设置。在本例中，所有节点只有一个磁盘，因此只有一个 OSD。所有节点都排列在默认 *根* 下，即层次结构树的标准 *根目录* 下。由于分配给两个 OSD 的权重比较大，因此这些 OSD 收到的数据区块比其他 OSD 少。这些节点在稍后引入时比初始 OSD 磁盘大。这不会影响数据放置来防止一组节点的故障。 		

**示例**

​					

```none
[ceph: root@host01 /]# ceph osd tree
ID WEIGHT  TYPE NAME           UP/DOWN REWEIGHT PRIMARY-AFFINITY
-1 0.33554 root default
-2 0.04779     host host03
 0 0.04779         osd.0            up  1.00000          1.00000
-3 0.04779     host host02
 1 0.04779         osd.1            up  1.00000          1.00000
-4 0.04779     host host01
 2 0.04779         osd.2            up  1.00000          1.00000
-5 0.04779     host host04
 3 0.04779         osd.3            up  1.00000          1.00000
-6 0.07219     host host06
 4 0.07219         osd.4            up  0.79999          1.00000
-7 0.07219     host host05
 5 0.07219         osd.5            up  0.79999          1.00000
```

​				使用逻辑分层定义将节点分组到同一数据中心可以实现数据放置成熟度。可以通过可能的 *根*、*数据中心*、*机架*、*行* *和主机* 定义类型来反映三个数据中心扩展集群的故障域： 		

- ​						节点 host01 和 host02 驻留在数据中心 1(DC1) 				
- ​						节点 host03 和 host05 驻留在数据中心 2(DC2)中. 				
- ​						节点 host04 和 host06 驻留在数据中心 3(DC3) 				
- ​						所有数据中心属于同一结构（所有DC） 				

​				由于主机中的所有 OSD 都属于主机定义，因此无需进行任何更改。所有其他分配可在存储集群运行时调整： 		

- ​						使用以下命令定义 *存储桶* 结构： 				

  ```none
  ceph osd crush add-bucket allDC root
  ceph osd crush add-bucket DC1 datacenter
  ceph osd crush add-bucket DC2 datacenter
  ceph osd crush add-bucket DC3 datacenter
  ```

- ​						通过修改 CRUSH map 将节点移到此结构中的相应位置： 				

  ```none
  ceph osd crush move DC1 root=allDC
  ceph osd crush move DC2 root=allDC
  ceph osd crush move DC3 root=allDC
  ceph osd crush move host01 datacenter=DC1
  ceph osd crush move host02 datacenter=DC1
  ceph osd crush move host03 datacenter=DC2
  ceph osd crush move host05 datacenter=DC2
  ceph osd crush move host04 datacenter=DC3
  ceph osd crush move host06 datacenter=DC3
  ```

​				在此结构中，任何新主机也可以添加，也可以添加新磁盘。通过将 OSD 放置到层次结构中的正确位置，CRUSH 算法已被更改，将冗余部分放入结构中不同的故障域中。 		

​				以上示例会产生以下内容： 		

**示例**

​					

```none
[ceph: root@host01 /]# ceph osd tree
ID  WEIGHT  TYPE NAME               UP/DOWN REWEIGHT PRIMARY-AFFINITY
 -8 6.00000 root allDC
 -9 2.00000     datacenter DC1
 -4 1.00000         host host01
  2 1.00000             osd.2            up  1.00000          1.00000
 -3 1.00000         host host02
  1 1.00000             osd.1            up  1.00000          1.00000
-10 2.00000     datacenter DC2
 -2 1.00000         host host03
  0 1.00000             osd.0            up  1.00000          1.00000
 -7 1.00000         host host05
  5 1.00000             osd.5            up  0.79999          1.00000
-11 2.00000     datacenter DC3
 -6 1.00000         host host06
  4 1.00000             osd.4            up  0.79999          1.00000
 -5 1.00000         host host04
  3 1.00000             osd.3            up  1.00000          1.00000
 -1       0 root default
```

​				上方的列表通过显示 osd 树来显示生成的 CRUSH map。易于查看的是，主机如何属于数据中心，所有数据中心从属于同一顶级结构，但清楚区分各个位置。 		

注意

​					根据映射将数据放置到正确的位置时，只能在健康的集群中正常工作。某些 OSD 不可用时，可能会出现错误放置。这些错误一旦可能就会自动修正。 			

**其它资源**

- ​						如需更多信息，请参见《红帽 Ceph 存储策略指南》中的 [CRUSH 管理](https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/5/html-single/storage_strategies_guide/#crush_administration) 一章。 				