# 主机管理

[TOC]

`Cephadm` 通过使用 SSH 从 MGR 连接到集群中的主机来管理集群，从而内省环境、监视 `ceph` 守护进程以及部署或删除守护程序。每个 `Ceph` 集群生成一个惟一的 SSH 标识和密钥，用于连接到主机。引导过程会将此密钥添加到本地主机 root 用户的 `authorized_keys` 中。

首先，需要集群密钥的公钥部分。默认情况下，引导程序会将副本放在 `/etc/ceph/ceph.pub`，或者可以使用 `ceph cephadm get ssh pub key` 从集群获取公钥副本。

```bash
ceph cephadm get-pub-key > ~/Path

ceph cephadm get-pub-key > ~/ceph.pub
```

## 列出主机

运行以下形式的命令以列出与群集关联的主机：

```bash
ceph orch host ls [--format yaml] [--host-pattern <name>] [--label <label>] [--host-status <status>]
```

命令中，参数 “host-pattern”、“label” 和 “host-status” 是可选的，用于过滤。

* “host-pattern” 是一个正则表达式，它将与主机名匹配，并且只返回匹配的主机。
* “label” 仅返回具有指定标签的主机。
* “host-status” 仅返回具有指定状态（当前为“脱机”或“维护”）的主机。
* 这些筛选标志的任何组合都是有效的。可以同时根据名称、标签和状态进行筛选，也可以根据名称、标记和状态的任何适当子集进行筛选。

## 添加主机

1. 将集群的 SSH 公钥添加到新主机 root 用户的 `authorized_keys` 文件中：

   ```bash
   ssh-copy-id -f -i /etc/ceph/ceph.pub root@<new-host>
   ```

2. 告知 Ceph 新节点是集群的一部分。在此假设所有主机都有一个唯一的主机名，该主机名与主机本身上配置的主机名匹配。如果您的本地环境还没有配置 `DNS` 以使我们可以连接到这些主机名，或者您希望避免依赖 `DNS`，则还可以为每个主机提供 `IP` 地址：

   ```bash
   ceph orch host add <newhost> [<ip>] [<label1> ...]
   ```

    例如：

   ```bash
   ceph orch host add host2 10.10.0.102
   ```

   最好显式地提供主机 IP 地址。如没有提供，将立即通过 DNS 解析主机名，并使用该 IP 。
   
   还可以包括一个或多个标签，以立即为新主机添加标签。

### 添加多个主机

使用 YAML 文件同时将多个主机添加到存储集群。

也可以与服务规范相结合，以创建集群规范文件，在一个命令中部署整个集群。请参阅 `cephadm bootstrap --apply-spec` 在引导期间应用规范来执行此操作。

务必在主机容器中创建 `hosts.yaml` 文件，或者在本地主机上创建文件，然后使用 `cephadm` shell 在容器内挂载文件。`cephadm shell` 会自动将挂载的文件放置在 `/mnt` 中。

1. 将公共 `ssh` 密钥复制到您要添加的每个主机。 					

2. 使用文本编辑器创建 `hosts.yaml` 文件。 					

3. 将主机描述添加到 `hosts.yaml` 文件中。包含标签，以标识您要在每个主机上部署的守护进程的放置。使用三个短划线 (---) 分隔每个主机描述。

   ```yaml
   service_type: host
   hostname: node-00
   addr: 192.168.0.10
   labels:
   - example1
   - example2
   ---
   service_type: host
   hostname: node-01
   addr: 192.168.0.11
   labels:
   - grafana
   ---
   service_type: host
   hostname: node-02
   addr: 192.168.0.12
   ```
   
4. 如果在主机容器中创建了 `hosts.yaml` 文件，请调用 `ceph orch apply` 命令：

   ```bash
   ceph orch apply -i hosts.yaml
   Added host 'host00'
   Added host 'host01'
   Added host 'host02'
   ```

5. 如果直接在本地主机上创建了 `hosts.yaml` 文件，请使用 `cephadm shell` 来挂载该文件：

   ```bash
   cephadm shell --mount hosts.yaml -- ceph orch apply -i /mnt/hosts.yaml
   ```

6. 查看主机及其标签列表：								

   ```bash
   ceph orch host ls
   HOST      ADDR      LABELS          STATUS
   host00    host00    mon osd mgr
   host01    host01    mon osd mgr
   host02    host02    mon osd
   ```

   > **注意:**
   >
   > 如果主机在线且正常运行，则其状态为空。脱机主机显示 OFFLINE 状态，处于维护模式的主机则显示 MAINTENANCE 状态。

## 删除主机

删除主机上所有的守护进程后，可以安全地从群集中移除该主机。

1. 移除主机上的所有守护进程，主机将具有 `_no_schedule` 标签：

   ```bash
   ceph orch host drain <host>
   ```

2. 如有 OSD ，所有 OSD 将按计划删除。查看 OSD 删除进度：

   ```bash
   ceph orch osd rm status
   ```

3. 如 OSD 未进行移除，执行如下命令：

   ```bash
   # 防止在设备上自动部署 OSD。
   ceph orch apply osd --all-available-devices --unmanaged=true
   # 删除 OSD
   for osd_id in $(ceph orch ps HOST_NAME --daemon_type osd | grep osd | awk '{print  $1}' | cut -c 5-) ; do ceph orch osd rm $osd_id; done
   ```

4. 检查主机上是否存在未删除的守护进程：

   ```bash
   ceph orch ps <host>
   ```

5. 删除所有守护程序后，删除主机：

   ```bash
   ceph orch host rm <host>
   ```

6. 离线主机删除（如果主机离线且无法恢复，可以将其从集群中删除）

   ```bash
   ceph orch host rm <host> --offline --force
   ```

   > **警告:**
   >
   > 这可能会导致数据丢失。该命令通过为每个 OSD 调用 `osd purge-actual` ，从集群中强制清除 OSD 。应手动更新仍然包含此主机的任何服务规范。

7. 如果要删除的主机正在运行 node-exporter 或 crash 服务，请在主机上运行以下命令来删除它们：

   ```bash
   # 获取集群的 fsid 的详细信息以及服务名称
   cephadm ls
   cephadm rm-daemon --fsid CLUSTER-ID --name SERVICE-NAME
   # eg:
   cephadm rm-daemon --fsid cluster00 --name node-exporter
   ```

## 主机标签

orchestrator 支持为主机分配标签。标签是自由形式的，本身没有特定的含义，每个主机可以有多个标签。它们可用于指定守护进程的位置。

例如，将 `mon` 标签应用到部署了 MON 守护进程的所有主机，`mgr` 用于部署 MGR 守护进程的所有主机，将 `rgw` 用于 Ceph 对象网关等。 	

标记存储集群中的所有主机有助于简化系统管理任务，允许快速识别每个主机上运行的守护进程。此外，可以使用 Ceph 编排器或 YAML 文件在具有特定主机标签的主机上部署或删除守护进程。 	

可以立即为新主机添加一个或多个标签。

   ```bash
ceph orch host add host4 10.10.0.104 --labels=_admin
ceph orch host add host4 10.10.0.104 --labels=my_label1,my_label2
   ```
向现有主机添加标签：

```bash
ceph orch host label add my_hostname my_label
```
删除主机的标签：

```bash
ceph orch host label rm my_hostname my_label
```

### 特殊主机标签

以下主机标签对 cephadm 有特殊的意义。所有的都以 `_` 开头。

- `_no_schedule`

  不要在此主机上计划或部署守护程序。

  此标签阻止 cephadm 在此主机上部署守护程序。如果将其添加到已包含 Ceph 守护程序的现有主机上，将导致 cephadm 将这些守护程序移到其他位置（OSD 除外，不会自动删除）。

- `_no_autotune_memory`

  不要自动调整此主机上的内存。

  即使为该主机上的一个或多个守护程序启用了 `osd_memory_target_autotune` 或类似选项，此标签也将阻止对守护程序内存进行调优。

- `_admin`

  默认情况下， `_admin` 标签应用于集群中的第一个主机（引导最初运行的地方）。`client.admin` 密钥通过 `ceph orch client-keyring ...`  功能分发给该主机。将此标签添加到其他主机通常会导致 cephadm 在该主机 `/etc/ceph` 中部署 `ceph.conf` 和`client.admin` keyring 文件。

  从16.2.10（Pacific）和 17.2.1（Quincy）版本开始，除了默认位置 `/etc/ceph` 之外，还在 `/var/lib/ceph/<fsid>/config` 目录中存储 config 和 keyring 文件。
  
  建议为一个或多个其他主机提供 `_admin` 标签，以便 Ceph CLI（例如，通过`cephadm shell`）在多个主机上易于访问。

### 使用主机标签在特定主机上部署守护进程

使用主机标签在特定主机上部署守护进程有两种方法：从命令行使用 `--placement` 选项，以及使用 YAML 文件。

- 使用 `--placement` 选项从命令行部署守护进程：

  ```bash
  ceph orch apply prometheus --placement="label:mylabel"
  ```

- 要将守护进程分配给 YAML 文件中的特定主机标签，请在 YAML 文件中指定服务类型和标签：

  ```yaml
  service_type: prometheus
  placement:
    label: "mylabel"
  ```

## 维护模式

将主机置于和退出维护模式（停止主机上的所有 Ceph 守护程序）：

```bash
ceph orch host maintenance enter <hostname> [--force]
# --force 标志，用户可以绕过警告 warning，但不能忽略警报 alert。

ceph orch host maintenace exit <hostname>
```

## 重新扫描主机设备

某些服务器和外部机柜可能不会向内核注册设备移除或插入。register device removal or insertion with the kernel. 在这些情况下，您需要执行主机重新扫描。重新扫描通常无中断，可以使用以下 CLI 命令执行：

```bash
ceph orch host rescan <hostname> [--with-summary]
```

The `with-summary` flag provides a breakdown of the number of HBAs found and scanned, together with any that failed:

`with-summary` 标志提供了找到和扫描的 HBA 数量的细目，以及任何失败的 HBA ：

```bash
ceph orch host rescan rh9-ceph1 --with-summary
Ok. 2 adapters detected: 2 rescanned, 0 skipped, 0 failed (0.32s)
```

## 设置主机的初始 CRUSH 位置

主机可以包含一个 `location` 标识符，该标识符将指示 cephadm 创建位于指定层次结构中的新 CRUSH 主机。

```yaml
service_type: host
hostname: node-00
addr: 192.168.0.10
location:
  rack: rack1
```

> **Note：**
>
>  `location` 属性将仅影响初始 CRUSH 位置。将忽略 `location` 属性的后续更改。此外，删除主机不会删除任何CRUSH 存储桶。

## 操作系统调整配置文件

Cephadm can be used to manage operating-system-tuning profiles that apply sets of sysctl settings to sets of hosts.

Cephadm 可用于管理将 sysctl 设置集应用于主机集的操作系统调优配置文件。

以如下格式创建 YAML 规范文件：

```yaml
profile_name: 23-mon-host-profile
placement:
  hosts:
    - mon-host-01
    - mon-host-02
settings:
  fs.file-max: 1000000
  vm.swappiness: '13'
```

使用以下命令应用调优配置文件：

```bash
ceph orch tuned-profile apply -i <tuned-profile-file-name>
```

此配置文件被写入每个与 yaml 放置块中指定的主机匹配符合的主机的 `/etc/sysctl.d/` 目录中 ，并且 `sysctl --system` 在该主机上运行。

>  **Note：**
>
>  配置文件在 `/etc/sysctl` 中写入的确切文件名是  `<profile-name>-cephadm-tuned-profile.conf`，其中 `<profile-name>` 是在 YAML 规范中指定的 `profile_name` 设置。因为 sysctl 设置是按字典顺序应用的（按指定设置的文件名排序），所以您可能希望在规范中设置 `profile_name` ，以便在其他配置文件之前或之后应用。

> **Note：**
>
> 这些设置仅在主机级别应用，不特定于任何特定的守护程序或容器。

> **Note：**
>
> 当传递 `--no-overwrite` 选项时，应用调优的概要文件是幂等的。此外，如果传递 `--no-overwrite` 选项，则不会覆盖同名的现有配置文件。

### 查看配置文件

查看 cephadm 当前管理的所有配置文件：

```bash
ceph orch tuned-profile ls
```

> **Note：**
>
> 要进行修改并重新应用概要文件，请将 `--format yaml` 传递给 `tuned-profile ls` 命令。`tuned-profile ls --format yaml` 命令以易于复制和重新应用的格式显示概要文件。

### 删除配置文件

要删除以前应用的配置文件：

```bash
ceph orch tuned-profile rm <profile-name>
```

删除配置文件后，cephadm 会清理之前写入 `/etc/sysctl.d` 的文件。

### 修改配置文件

可以通过重新应用与要修改的配置文件同名的 YAML 规范来修改配置文件，但可以使用以下命令调整现有配置文件中的设置。

在现有配置文件中添加或修改设置：

```bash
ceph orch tuned-profile add-setting <profile-name> <setting-name> <value>
```

从现有配置文件中删除设置：

```bash
ceph orch tuned-profile rm-setting <profile-name> <setting-name>
```

> **Note：**
>
> 修改 placement 需要重新应用同名的 profile。请记住，概要文件是按其名称跟踪的，因此当应用与现有概要文件同名的概要文件时，它将覆盖旧概要文件，除非传递 `--no-overwrite` 标志。

## SSH 配置

### 默认行为

Cephadm 在 MON 中存储一个 SSH 密钥，用于连接到远程主机。当集群引导时，这个SSH 密钥会自动生成，不需要额外的配置。

生成新的 SSH key：

```bash
ceph cephadm generate-key
```

SSH 密钥的公共部分可以通过以下方式检索：

```bash
ceph cephadm get-pub-key
```

删除当前存储的 SSH 密钥：

```bash
ceph cephadm clear-key
```

直接导入现有密钥：

```bash
ceph config-key set mgr/cephadm/ssh_identity_key -i <key>
ceph config-key set mgr/cephadm/ssh_identity_pub -i <pub>
```

需要重新启动 MGR 守护进程，以重新加载配置：

```bash
ceph mgr fail
```

### 设置不同的 SSH 用户

Cephadm 必须能够以有足够权限（下载容器映像、启动容器和执行命令，且无需提示输入密码）的用户身份登录到所有 Ceph 集群节点。如果不想使用 “root” 用户（ cephadm 中的默认选项），则必须向 cephadm 提供将用于执行所有操作的用户的名称。

```bash
ceph cephadm set-user <user>
```

在运行此操作之前，需要将集群 ssh 密钥添加到此用户 authorized_keys 文件中，并且非 root 用户必须具有无密码 sudo 的权限。

### 自定义 SSH 配置

Cephadm 生成一个适当的 `ssh_config` 配置文件，用于连接到远程主机。此配置如下所示：

```ini
Host *
User root
StrictHostKeyChecking no
UserKnownHostsFile /dev/null
```

有两种方法自定义配置：

1. 导入将由 MON 存储的自定义配置文件：

   ```bash
   ceph cephadm set-ssh-config -i <ssh_config_file>
   ```

   要删除自定义 SSH 配置并恢复为默认行为：

   ```
   ceph cephadm clear-ssh-config
   ```

2. 可以使用以下命令设置 SSH 配置文件的路径：

   ```
   ceph config set mgr mgr/cephadm/ssh_config_file <path>
   ```

   不推荐这种方法。路径名必须对任何 MGR 守护程序可见，cephadm 以容器形式运行所有守护程序。这意味着需要将该文件放置在用于部署的自定义容器映像中，或者手动分发到 MGR 数据目录 (主机的`/var/lib/ceph/<cluster-fsid>/mgr.<id>` ，容器内 `/var/lib/ceph/mgr/ceph-<id>` ) 。

## FQDN vs 裸机名

> **Note：**
>
> cephadm 要求通过 `ceph orch host add` 给出的主机名等于远程主机上 `hostname` 的输出。否则 cephadm 无法确保 `ceph * metadata` 返回的名称与 cephadm 已知的主机匹配。这可能会导致 CEPHADM_STRAY_HOST 警告。

配置新主机时，有两种有效的方法可以设置主机名：

1. 使用裸机名。在这种情况下：

- `hostname` 返回裸机名。
- `hostname -f` 返回 FQDN 。

2. 使用 FQDN 。在这种情况下：

- `hostname` 返回 FQDN 。
- `hostname -s` 返回裸机名。

> 系统的 FQDN（完全限定域名）是 resolver（3）为主机名返回的名称，例如 `ursula.example.com` 。通常是主机名后跟 DNS 域名（第一个点后面的部分）。可以使用 `hostname --fqdn` 检查 FQDN，也可以使用 `dnsdomainname` 检查域名。
>
> ```bash
> 您不能使用 hostname 或 dnsdomainname 更改 FQDN。
> 
> The recommended method of setting the FQDN is to make the hostname
> be an alias for the fully qualified name using /etc/hosts, DNS, or
> NIS.建议设置 FQDN 的方法是使主机名
> 使用/etc/hosts、DNS或
> 尼斯。例如:如果主机名是 "ursula", 在 /etc/hosts 中可能有如下的行
> 
> 127.0.1.1    ursula.example.com ursula
> ```

这意味着，`man hostname` 建议 `hostname` 返回裸机名。This in turn means that Ceph will return the bare host names when executing `ceph * metadata`. 这反过来意味着Ceph将在执行Ceph*元数据时返回裸机名。This in turn means cephadm also requires the bare host name when adding a host to the cluster: `ceph orch host add <bare-name>`.这反过来意味着cephadm在向集群添加主机时也需要裸机名：ceph-orch-host-add＜裸机名＞。