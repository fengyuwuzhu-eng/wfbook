# 主机管理

[TOC]

`Cephadm` 通过使用 SSH 从 MGR 连接到集群中的主机来管理集群，从而内省环境、监视 `ceph` 守护进程以及部署或删除守护程序。每个 `Ceph` 集群生成一个惟一的 SSH 标识和密钥，用于连接到主机。引导过程会将此密钥添加到本地主机的根用户的 `authorized_keys` 中。

首先，需要集群密钥的公钥部分。默认情况下，引导程序会将副本放在 `/etc/ceph/ceph.pub`，或者可以使用 `ceph cephadm get ssh pub key` 从集群获取公钥副本。

```bash
ceph cephadm get ssh pub key > ~/Path
ceph cephadm get-pub-key > ~/Path

ceph cephadm get-pub-key > ~/ceph.pub
```

## 列出主机

```bash
ceph orch host ls [--format yaml] [--host-pattern <name>] [--label <label>] [--host-status <status>]
```

Any combination of these filtering flags is valid. You may filter against name, label and/or status simultaneously.

命令中，参数 “host-pattern”、“label” 和 “host-status” 是可选的，用于过滤。

* “host-pattern” 是一个正则表达式，它将与主机名匹配，并且只返回匹配的主机。
* “label” 仅返回具有指定标签的主机。
* “host-status” 仅返回具有指定状态（当前为“脱机”或“维护”）的主机。
* 这些筛选标志的任何组合都是有效的。可以同时根据名称、标签和 / 或状态进行筛选。

## 添加主机

1. 将集群的 SSH 公钥添加到新主机 root 用户的 `authorized_keys` 文件中：

   ```bash
   ssh-copy-id -f -i /etc/ceph/ceph.pub root@<new-host>
   ```

2. 告知 Ceph 新节点是集群的一部分。在此假设所有主机都有一个唯一的主机名，该主机名与主机本身上配置的主机名匹配。如果您的本地环境还没有配置 `DNS` 以使我们可以连接到这些主机名，或者您希望避免依赖 `DNS`，则还可以为每个主机提供 `IP` 地址：

   ```bash
   ceph orch host add <newhost> [<ip>] [<label1> ...]
   ```

    例如：

   ```bash
   ceph orch host add host2 10.10.0.102
   ```

   最好显式地提供主机 IP 地址。如没有提供，那么将立即通过 DNS 解析主机名，并使用该 IP 。

### 添加多个主机

使用 YAML 文件同时将多个主机添加到存储集群。

也可以与服务规范相结合，以创建集群规范文件，在一个命令中部署整个集群。请参阅 `cephadm bootstrap --apply-spec` 在引导期间应用规范来执行此操作。

务必在本地主机上创建 `hosts.yaml` 文件，或者在本地主机上创建文件，然后使用 `cephadm` shell 在容器内挂载文件。`cephadm` shell 会自动将挂载的文件放置在 `/mnt` 中。

1. 将公共 `ssh` 密钥复制到您要添加的每个主机。 					

2. 使用文本编辑器创建 `hosts.yaml` 文件。 					

3. 将主机描述添加到 `hosts.yaml` 文件中。包含标签，以标识您要在每个主机上部署的守护进程的放置。使用三个短划线 (---) 分隔每个主机描述。

   ```yaml
   ---
   service_type: host
   hostname: node-00
   addr: 192.168.0.10
   labels:
   - example1
   - example2
   ---
   service_type: host
   hostname: node-01
   addr: 192.168.0.11
   labels:
   - grafana
   ---
   service_type: host
   hostname: node-02
   addr: 192.168.0.12
   ```
   
4. 如果在主机容器中创建了 `hosts.yaml` 文件，请调用 `ceph orch apply` 命令：

   ```bash
   ceph orch apply -i hosts.yaml
   Added host 'host00'
   Added host 'host01'
   Added host 'host02'
   ```

5. 如果直接在本地主机上创建了 `hosts.yaml` 文件，请使用 `cephadm` shell 来挂载该文件：

   ```bash
   cephadm shell --mount hosts.yaml -- ceph orch apply -i /mnt/hosts.yaml
   ```

6. 查看主机及其标签列表：								

   ```bash
   ceph orch host ls
   HOST      ADDR      LABELS          STATUS
   host00    host00    mon osd mgr
   host01    host01    mon osd mgr
   host02    host02    mon osd
   ```

   **注意:**

   如果主机在线且正常运行，则其状态为空。脱机主机显示 OFFLINE 状态，处于维护模式的主机则显示 MAINTENANCE 状态。

## 删除主机

删除主机上所有的守护进程后，可以安全地从群集中移除该主机。

1. 移除主机上的所有守护进程，主机将具有 `_no_schedule` 标签：

   ```bash
   ceph orch host drain <host>
   ```

2. 如有 OSD ，所有 OSD 将按计划删除。查看 OSD 删除进度：

   ```bash
   ceph orch osd rm status
   ```

3. 如 OSD 未进行移除，执行如下命令：

   ```bash
   # 防止在设备上自动部署 OSD。
   ceph orch apply osd --all-available-devices --unmanaged=true
   # 删除 OSD
   for osd_id in $(ceph orch ps HOST_NAME --daemon_type osd | grep osd | awk '{print  $1}' | cut -c 5-) ; do ceph orch osd rm $osd_id; done
   ```

4. 检查主机上是否存在未删除的守护进程：

   ```bash
   ceph orch ps <host>
   ```

5. 删除所有守护程序后，删除主机：

   ```bash
   ceph orch host rm <host>
   ```

6. 离线主机删除（如果主机离线且无法恢复，可以将其从集群中删除）

   ```bash
   ceph orch host rm <host> --offline --force
   ```

7. 如果要删除的主机正在运行 node-exporter 或 crash 服务，请在主机上运行以下命令来删除它们：

   ```bash
   # 获取集群的 fsid 的详细信息以及服务名称
   cephadm ls
   cephadm rm-daemon --fsid CLUSTER-ID --name SERVICE-NAME
   # eg:
   cephadm rm-daemon --fsid cluster00 --name node-exporter
   ```
   这可能会导致数据丢失，因为将通过调用 `osd purge-actual` 把每个 osd 强制从集群中清除。Service specs that still contain this host should be manually updated.仍包含此主机的服务规范应手动更新。

## 主机标签

orchestrator 支持为主机分配标签。标签是自由形式的，本身没有特定的含义，每个主机可以有多个标签。它们可用于指定守护进程的位置。

例如，将 `mon` 标签应用到部署了监控守护进程的所有主机，`mgr` 用于部署管理器守护进程的所有主机，将 `rgw` 用于 Ceph 对象网关等。 	

标记存储集群中的所有主机有助于简化系统管理任务，允许快速识别每个主机上运行的守护进程。此外，可以使用 Ceph 编排器或 YAML 文件在具有特定主机标签的主机上部署或删除守护进程。 	

可以立即为新主机添加一个或多个标签。

   ```bash
ceph orch host add host4 10.10.0.104 --labels=_admin
ceph orch host add host4 10.10.0.104 --labels=my_label1,my_label2
   ```
向现有主机添加标签：

```bash
ceph orch host label add my_hostname my_label
```
删除主机的标签：

```bash
ceph orch host label rm my_hostname my_label
```

### 特殊主机标签

以下主机标签对 cephadm 有特殊的意义。所有的都以 `_` 开头。

- `_no_schedule`

  不要在此主机上计划或部署守护程序。

  此标签阻止 cephadm 在此主机上部署守护程序。如果将其添加到已包含 Ceph 守护程序的现有主机上，将导致 cephadm 将这些守护程序移到其他位置（OSD 除外，不会自动删除）。

- `_no_autotune_memory`

  不要自动调整此主机上的内存。

  即使为该主机上的一个或多个守护程序启用了 `osd_memory_target_autotune` 或类似选项，此标签也将阻止对守护程序内存进行调优。

- `_admin`

  将 `client.admin` 和 `ceph.conf` 分发到此主机。

  默认情况下， `_admin` 标签应用于集群中的第一个主机（引导最初运行的地方）。`client.admin` 密钥通过 `ceph orch client-keyring ...`  功能分发给该主机。将此标签添加到其他主机通常会导致 cephadm 在该主机 `/etc/ceph` 中部署 `ceph.conf` 和`client.admin` keyring 文件。
  
Starting from versions 16.2.10 (Pacific) and 17.2.1 (Quincy) in addition to the default location `/etc/ceph/` cephadm also stores config and keyring files in the `/var/lib/ceph/<fsid>/config` directory.从16.2.10（Pacific）和 17.2.1（Quincy）版本开始，除了默认位置 `/etc/ceph` 之外，还在 `/var/lib/ceph/<fsid>/config` 目录中存储 config 和 keyring 文件。
  
  建议为一个或多个其他主机提供 `_admin` 标签，以便 Ceph CLI（例如，通过`cephadm shell`）在多个主机上易于访问。将 `_admin` 标签添加到其他主机：
  
   ```bash
   ceph orch host label add <host> _admin
   ```

### 使用主机标签在特定主机上部署守护进程

使用主机标签在特定主机上部署守护进程有两种方法：从命令行使用 `--placement` 选项，以及使用 YAML 文件。

- 使用 `--placement` 选项从命令行部署守护进程：

  ```bash
  ceph orch apply prometheus --placement="label:mylabel"
  ```

- 要将守护进程分配给 YAML 文件中的特定主机标签，请在 YAML 文件中指定服务类型和标签：

  ```yaml
  service_type: prometheus
  placement:
    label: "mylabel"
  ```

## 维护模式

将主机置于和退出维护模式（停止主机上的所有 Ceph 守护程序）：

```bash
ceph orch host maintenance enter <hostname> [--force]
# --force 标志，用户可以绕过警告 warning，但不能忽略警报 alert。

ceph orch host maintenace exit <hostname>
```

## 重新扫描主机设备

某些服务器和外部机柜可能不会向内核注册设备移除或插入。register device removal or insertion with the kernel. 在这些情况下，您需要执行主机重新扫描。重新扫描通常无中断，可以使用以下 CLI 命令执行：

```bash
ceph orch host rescan <hostname> [--with-summary]
```

 `with-summary` 标志提供了找到和扫描的 HBA 数量的细目，以及任何失败的 HBA ：

```bash
ceph orch host rescan rh9-ceph1 --with-summary
Ok. 2 adapters detected: 2 rescanned, 0 skipped, 0 failed (0.32s)
```

## 设置主机的初始 CRUSH 位置

instruct cephadm to create a new CRUSH host located in the specified。主机可以包含一个 `location` 标识符，该标识符将指示 cephadm 创建位于指定层次结构中的新 CRUSH 主机。

```yaml
service_type: host
hostname: node-00
addr: 192.168.0.10
location:
  rack: rack1
```

> **Note：**
>
>  `location` 属性将仅影响初始 CRUSH 位置。Subsequent changes of the `location` property will be ignored. 将忽略位置属性的后续更改。Also, removing a host will no remove any CRUSH buckets.此外，删除主机不会删除任何CRUSH存储桶。

## 操作系统调整配置文件

Cephadm can be used to manage operating-system-tuning profiles that apply sets of sysctl settings to sets of hosts.

Cephadm 可用于管理将sysctl设置集应用于主机集的操作系统调优配置文件。

以如下格式创建 YAML 规范文件：

```yaml
profile_name: 23-mon-host-profile
placement:
  hosts:
    - mon-host-01
    - mon-host-02
settings:
  fs.file-max: 1000000
  vm.swappiness: '13'
```

使用以下命令应用调优配置文件：

```bash
ceph orch tuned-profile apply -i <tuned-profile-file-name>
```

此配置文件被写入每个主机的 `/etc/sysctl.d/`目录中 。that matches the hosts specified in the placement block of the yaml, and `sysctl --system` is run on the host.

>  Note
>
> The exact filename that the profile is written to within `/etc/sysctl.d/` is `<profile-name>-cephadm-tuned-profile.conf`, where `<profile-name>` is the `profile_name` setting that you specify in the YAML spec. Because sysctl settings are applied in lexicographical order (sorted by the filename in which the setting is specified), you may want to set the `profile_name` in your spec so that it is applied before or after other conf files.配置文件在/etc/sysctl中写入的确切文件名。d/is＜profile name＞-cephadm调谐配置文件。conf，其中＜profile  name＞是您在YAML规范中指定的配置文件名称设置。因为sysctl设置是按字典顺序应用的（按指定设置的文件名排序），所以您可能希望在规范中设置配置文件名称，以便在其他conf文件之前或之后应用。

> Note
>
> and are not specific to any particular daemon or container.这些设置仅在主机级别应用，不特定于任何特定的守护程序或容器。

> Note
>
> Applying tuned profiles is idempotent when the `--no-overwrite` option is passed. Moreover, if the `--no-overwrite` option is passed, existing profiles with the same name are not overwritten.当传递--no覆盖选项时，应用调优的概要文件是幂等的。此外，如果传递--no覆盖选项，则不会覆盖同名的现有配置文件。

### 查看配置文件

查看 cephadm 当前管理的所有配置文件：

```bash
ceph orch tuned-profile ls
```

> Note
>
> To make modifications and re-apply a profile, pass `--format yaml` to the `tuned-profile ls` command. The `tuned-profile ls --format yaml` command presents the profiles in a format that is easy to copy and re-apply.
>
> 要进行修改并重新应用概要文件，请将--format yaml传递给调优的概要文件ls命令。调优后的概要文件ls--format yaml命令以易于复制和重新应用的格式显示概要文件。

### 删除配置文件

要删除以前应用的配置文件：

```bash
ceph orch tuned-profile rm <profile-name>
```

When a profile is removed, cephadm cleans up the file previously written to `/etc/sysctl.d`.

删除配置文件后，cephadm会清理之前写入/etc/sysctl.d的文件。

### 修改配置文件

Profiles can be modified by re-applying a YAML spec with the same name as the profile that you want to modify, but settings within existing profiles can be adjusted with the following commands.可以通过重新应用与要修改的配置文件同名的YAML规范来修改配置文件，但可以使用以下命令调整现有配置文件中的设置。

在现有配置文件中添加或修改设置：

```bash
ceph orch tuned-profile add-setting <profile-name> <setting-name> <value>
```

从现有配置文件中删除设置：

```bash
ceph orch tuned-profile rm-setting <profile-name> <setting-name>
```

> Note:
>
> Modifying the placement requires re-applying a profile with the same name. Remember that profiles are tracked by their names, so when a profile with the same name as an existing profile is applied, it overwrites the old profile unless the `--no-overwrite` flag is passed.
>
> 修改放置需要重新应用同名的轮廓。请记住，概要文件是按其名称跟踪的，因此当应用与现有概要文件同名的概要文件时，它将覆盖旧概要文件，除非传递--no覆盖标志。

## SSH 配置

### 默认行为

Cephadm 在 MON 中存储一个 SSH 密钥，用于连接到远程主机。当集群引导时，这个SSH 密钥会自动生成，不需要额外的配置。

生成新的 SSH key：

```bash
ceph cephadm generate-key
```

SSH 密钥的公共部分可以通过以下方式检索：

```bash
ceph cephadm get-pub-key
```

删除当前存储的SSH密钥：

```bash
ceph cephadm clear-key
```

直接导入现有密钥：

```bash
ceph config-key set mgr/cephadm/ssh_identity_key -i <key>
ceph config-key set mgr/cephadm/ssh_identity_pub -i <pub>
```

需要重新启动 MGR 守护进程，以重新加载配置：

```bash
ceph mgr fail
```

### 设置不同的 SSH 用户

Cephadm 必须能够以有足够权限下载容器映像、启动容器和执行命令，且无需提示输入密码的用户身份登录到所有 Ceph 集群节点。如果不想使用 “root” 用户（ cephadm 中的默认选项），则必须向 cephadm 提供将用于执行所有操作的用户的名称。

```bash
ceph cephadm set-user <user>
```

在运行此操作之前，需要将集群 ssh 密钥添加到此用户 authorized_keys 文件中，并且非 root 用户必须具有无密码 sudo 的权限。

### 自定义 SSH 配置

Cephadm 生成一个适当的 `ssh_config` 配置文件，用于连接到远程主机。此配置如下所示：

```ini
Host *
User root
StrictHostKeyChecking no
UserKnownHostsFile /dev/null
```

有两种方法自定义配置：

1. 导入将由 MON 存储的自定义配置文件：

   ```bash
   ceph cephadm set-ssh-config -i <ssh_config_file>
   ```

   要删除自定义 SSH 配置并恢复为默认行为：

   ```
   ceph cephadm clear-ssh-config
   ```

2. 可以使用以下命令设置 SSH 配置文件的路径：

   ```
   ceph config set mgr mgr/cephadm/ssh_config_file <path>
   ```

   不推荐这种方法。路径名必须对任何 MGR 守护程序可见，cephadm 以容器形式运行所有守护程序。这意味着需要将该文件放置在用于部署的自定义容器映像中，或者手动分发到 MGR 数据目录 (`/var/lib/ceph/<cluster-fsid>/mgr.<id>` on the host, visible at `/var/lib/ceph/mgr/ceph-<id>` from inside the container) 。

## FQDN vs bare host names

> **Note:**
>
> cephadm 要求通过 `ceph orch host add` 给出的主机名等于远程主机上 `hostname` 的输出。否则 cephadm 无法确保 `ceph * metadata` 返回的名称与 cephadm 已知的主机匹配。这可能会导致 CEPHADM_STRAY_HOST 警告。

配置新主机时，有两种有效的方法可以设置主机名：

1. Using the bare host name. In this case:使用裸机名。在这种情况下：

- `hostname` returns the bare host name.
- `hostname -f` returns the FQDN.

2. Using the fully qualified domain name as the host name. In this case:

- `hostname` returns the FQDN
- `hostname -s` return the bare host name

Note that `man hostname` recommends `hostname` to return the bare host name:注意，man hostname建议hostname返回裸机名：

> The FQDN (Fully Qualified Domain Name) of the system is the name that the resolver(3) returns for the host name, such as, ursula.example.com. It is usually the hostname followed by the DNS domain name (the part after the first dot). You can check the FQDN using `hostname --fqdn` or the domain name using `dnsdomainname`.系统的FQDN（完全限定域名）是解析器（3）为主机名返回的名称，例如ursula.example.com。通常是主机名后跟DNS域名（第一个点后面的部分）。可以使用hostname--FQDN检查FQDN，也可以使用dnsdomainname检查域名。
>
> ```bash
> 您不能使用 hostname 或 dnsdomainname 更改 FQDN。
> 
> The recommended method of setting the FQDN is to make the hostname
> be an alias for the fully qualified name using /etc/hosts, DNS, or
> NIS. For example, 如果主机名是 "ursula", one might have
> a line in /etc/hosts which reads
> 
>     127.0.1.1    ursula.example.com ursula
> ```

Which means, `man hostname` recommends `hostname` to return the bare host name. This in turn means that Ceph will return the bare host names when executing `ceph * metadata`. This in turn means cephadm also requires the bare host name when adding a host to the cluster: `ceph orch host add <bare-name>`.这意味着，man hostname建议hostname返回裸机名。这反过来意味着Ceph将在执行Ceph*元数据时返回裸机名。这反过来意味着cephadm在向集群添加主机时也需要裸机名：ceph-orch-host-add＜裸机名＞。