# 主机管理

[TOC]

`Cephadm`通过使用 SSH 从 MGR 连接到集群中的主机来管理集群，从而内省环境、监视 `ceph` 守护进程以及部署或删除守护程序。每个 `Ceph` 集群生成一个惟一的 SSH 标识和密钥，用于连接到主机。引导过程会将此密钥添加到本地主机的根用户的 `authorized_keys` 中。

首先，需要集群密钥的公钥部分。默认情况下，引导程序会将副本放在 `/etc/ceph/ceph.pub`，或者可以使用 `ceph cephadm get ssh pub key` 从集群获取公钥副本。

列出与集群关联的主机：

```bash
ceph orch host ls [--format yaml]
```

## 添加主机

1. 将集群的 SSH 公钥添加到新主机 root 用户的 `authorized_keys` 文件中：

   ```bash
   ssh-copy-id -f -i /etc/ceph/ceph.pub root@<new-host>
   ```

2. 告知 Ceph 新节点是集群的一部分。在此假设所有主机都有一个唯一的主机名，该主机名与主机本身上配置的主机名匹配。如果您的本地环境还没有配置`DNS`以使我们可以连接到这些主机名，或者您希望避免依赖`DNS`，则还可以为每个主机提供`IP`地址：

   ```bash
   ceph orch host add <newhost> [<ip>] [<label1> ...]
   ```

   例如：

   ```bash
   ceph orch host add host2 10.10.0.102
   ```
   

最好显式地提供主机 IP 地址。如果没有提供 IP ，那么将立即通过 DNS 解析主机名，并使用该 IP 。

### 添加多个主机

使用 YAML 文件同时将多个主机添加到存储集群。 			

务必在本地主机上创建 `hosts.yaml` 文件，或者在本地主机上创建文件，然后使用 `cephadm` shell 在容器内挂载 文件。`cephadm` shell 会自动将挂载的文件放置在 `/mnt` 中。 				

**流程**

1. 将公共 `ssh` 密钥复制到您要添加的每个主机。 					

2. 使用文本编辑器创建 `hosts.yaml` 文件。 					

3. 将主机描述添加到 `hosts.yaml` 文件中。包含标签，以标识您要在每个主机上部署的守护进程的放置。使用三个短划线 (---) 分隔每个主机描述。

   ```yaml
   service_type: host
   addr:
   hostname: host00
   labels:
   - mon
   - osd
   - mgr
   ---
   service_type: host
   addr:
   hostname: host01
   labels:
   - mon
   - osd
   - mgr
   ---
   service_type: host
   addr:
   hostname: host02
   labels:
   - mon
   - osd
   ```

4. 如果在主机容器中创建了 `hosts.yaml` 文件，请调用 `ceph orch apply` 命令：

   ```bash
   ceph orch apply -i hosts.yaml
   Added host 'host00'
   Added host 'host01'
   Added host 'host02'
   ```

5. 如果直接在本地主机上创建了 `hosts.yaml` 文件，请使用 `cephadm` shell 来挂载该文件：

   ```bash
   cephadm shell --mount hosts.yaml -- ceph orch apply -i /mnt/hosts.yaml
   ```

6. 查看主机及其标签列表：								

   ```bash
   ceph orch host ls
   HOST      ADDR      LABELS          STATUS
   host00    host00    mon osd mgr
   host01    host01    mon osd mgr
   host02    host02    mon osd
   ```

   **注意:**

   如果主机在线且正常运行，则其状态为空。脱机主机显示 OFFLINE 状态，处于维护模式的主机则显示 MAINTENANCE 状态。

## 删除主机

从存储群集中删除主机的方式有两种。使用的方法取决于主机是运行 node-exporter 还是崩溃服务。

**流程**

1. 如果主机没有运行 node-exporter 或崩溃服务，编辑放置规格文件并删除主机名的所有实例。默认情况下，放置规格文件命名为 `cluster.yml`。（此步骤可以不进行）

   ```yaml
   Update:
   
   service_type: rgw
   placement:
     hosts:
     - host01
     - host02
   
   To:
   
   service_type: rgw
   placement:
     hosts:
     - host01
   ```

2. 移除主机上的所有守护进程，主机将具有 `_no_schedule` 标签：

   ```bash
   ceph orch host drain <host>
   ```

3. 如有 OSD ，所有 OSD 将按计划删除。查看 OSD 删除进度：

   ```bash
   ceph orch osd rm status
   ```

4. 检查主机上是否存在未删除的守护进程：

   ```bash
   ceph orch ps <host>
   ```

5. 删除所有守护程序后，从 `cephadm` 环境中删除主机：

   ```bash
   ceph orch host rm <host>
   ```

6. 离线主机删除（如果主机离线且无法恢复，可以将其从集群中删除）

   ```bash
   ceph orch host rm <host> --offline --force
   ```

7. 如果要删除的主机正在运行 node-exporter 或 crash 服务，请在主机上运行以下命令来删除它们：

   ```bash
   cephadm rm-daemon --fsid CLUSTER-ID --name SERVICE-NAME
   # eg:
   cephadm rm-daemon --fsid cluster00 --name node-exporter
   ```
   This can potentially cause data loss as osds will be forcefully purged from the cluster by calling `osd purge-actual` for each osd. Service specs that still contain this host should be manually updated.
   
   这可能会导致数据丢失，因为 osd 将通过为每个 osd 调用 osd purge-actual 被强制从集群中清除。仍包含此主机的服务规范应手动更新。

## 主机标签

orchestrator 支持为主机分配标签。标签是自由形式的，本身没有特定的含义，每个主机可以有多个标签。它们可用于指定守护进程的位置。

例如，将 `mon` 标签应用到部署了监控守护进程的所有主机，`mgr` 用于部署管理器守护进程的所有主机，将 `rgw` 用于 Ceph 对象网关等。 	

标记存储集群中的所有主机有助于简化系统管理任务，允许快速识别每个主机上运行的守护进程。此外，可以使用 Ceph 编排器或 YAML 文件在具有特定主机标签的主机上部署或删除守护进程。 	

可以立即为新主机添加一个或多个标签。

   ```bash
ceph orch host add host4 10.10.0.104 --labels=_admin
ceph orch host add host4 10.10.0.104 --labels=my_label1,my_label2
   ```
向现有主机添加标签：

```bash
ceph orch host label add my_hostname my_label
```
删除主机的标签：

```bash
ceph orch host label rm my_hostname my_label
```

### 特殊主机标签

以下主机标签对cephadm有特殊的意义。所有的都以 `_` 开头。

- `_no_schedule`

  不要在此主机上计划或部署守护程序。

  此标签阻止cephadm在此主机上部署守护程序。如果将其添加到已包含 Ceph 守护程序的现有主机，将导致 cephadm 将这些守护程序移到其他位置（OSD 除外，不会自动删除）。

- `_no_autotune_memory`

  不要自动调整此主机上的内存。

  即使为该主机上的一个或多个守护程序启用了 `osd_memory_target_autotune` 或类似选项，此标签也将阻止对守护程序内存进行调优。

- `_admin`

  将 `client.admin` 和 `ceph.conf` 分发到此主机。

  默认情况下， `_admin` 标签应用于集群中的第一个主机（引导最初运行的地方）。`client.admin` 密钥通过 `ceph orch client-keyring ...`  功能分发给该主机。将此标签添加到其他主机通常会导致 cephadm 在 `/etc/ceph` 中部署 `ceph.conf` 和`client.admin` keyring 文件。
  该标签最初仅应用于引导主机。建议为一个或多个其他主机提供 `_admin` 标签，以便 Ceph CLI（例如，通过`cephadm shell`）在多个主机上易于访问。将 `_admin` 标签添加到其他主机：

   ```bash
   ceph orch host label add <host> _admin
   ```

### 使用主机标签在特定主机上部署守护进程

使用主机标签在特定主机上部署守护进程有两种方法：从命令行使用 `--placement` 选项，以及使用 YAML 文件。

- 使用 `--placement` 选项从命令行部署守护进程：

  ```bash
  ceph orch apply prometheus --placement="label:mylabel"
  ```

- 要将守护进程分配给 YAML 文件中的特定主机标签，请在 YAML 文件中指定服务类型和标签：

  ```yaml
  service_type: prometheus
  placement:
    label: "mylabel"
  ```

## 维护模式

将主机置于和退出维护模式（停止主机上的所有 Ceph 守护程序）：

```bash
ceph orch host maintenance enter <hostname> [--force]
ceph orch host maintenace exit <hostname>
```

进入维护模式时，设置强制标志，允许用户绕过警告（而不是警报）。allows the user to bypass warnings (but not alerts)

## Host Specification

多个主机可以一次添加。使用 `ceph orch apply -i` 提交一个 multi-document YAML 文件：

```yaml
---
service_type: host
hostname: node-00
addr: 192.168.0.10
labels:
- example1
- example2
---
service_type: host
hostname: node-01
addr: 192.168.0.11
labels:
- grafana
---
service_type: host
hostname: node-02
addr: 192.168.0.12
```

这可以与服务规范（下面）结合使用，创建一个集群规范文件，以便在一个命令中部署整个集群。请参阅 `cephadm bootstrap --apply-spec` 在引导过程中实现。在添加之前，必须将群集SSH密钥复制到主机。

## SSH 配置

### 默认行为

Cephadm在 MON 中存储一个SSH密钥，用于连接到远程主机。当集群引导时，这个SSH密钥会自动生成，不需要额外的配置。

生成新的 SSH key：

```bash
ceph cephadm generate-key
```

SSH密钥的公共部分可以通过以下方式检索：

```bash
ceph cephadm get-pub-key
```

删除当前存储的SSH密钥：

```bash
ceph cephadm clear-key
```

直接导入现有密钥：

```bash
ceph config-key set mgr/cephadm/ssh_identity_key -i <key>
ceph config-key set mgr/cephadm/ssh_identity_pub -i <pub>
```

需要重新启动 MGR 守护进程，以重新加载配置：

```bash
ceph mgr fail
```

### 设置不同的 SSH 用户

Cephadm 必须能够以有足够权限下载容器映像、启动容器和执行命令，且无需提示输入密码的用户身份登录到所有Ceph集群节点。如果不想使用“root”用户（cephadm中的默认选项），则必须向 cephadm 提供将用于执行所有操作的用户的名称。

```bash
ceph cephadm set-user <user>
```

在运行此操作之前，需要将集群ssh密钥添加到此用户 authorized_keys 文件中，并且非root用户必须具有无密码sudo的权限。

### 自定义SSH配置

Cephadm生成一个适当的 `ssh_config` 配置文件，用于连接到远程主机。此配置如下所示：

```ini
Host *
User root
StrictHostKeyChecking no
UserKnownHostsFile /dev/null
```

有两种方法自定义配置：

1. 导入将由 MON 存储的自定义配置文件：

   ```bash
   ceph cephadm set-ssh-config -i <ssh_config_file>
   ```

   要删除自定义 SSH 配置并恢复为默认行为：

   ```
   ceph cephadm clear-ssh-config
   ```

2. 可以使用以下命令设置 SSH 配置文件的路径：

   ```
   ceph config set mgr mgr/cephadm/ssh_config_file <path>
   ```

   我们不推荐这种方法。路径名必须对任何 MGR 守护程序可见，cephadm 以容器形式运行所有守护程序。这意味着需要将该文件放置在用于部署的自定义容器映像中，或者手动分发到 MGR 数据目录（/var/lib/ceph//mgr.在主机上，在容器内部的/var/lib/ceph/mgr/ceph-处可见）。 (`/var/lib/ceph/<cluster-fsid>/mgr.<id>` on the host, visible at `/var/lib/ceph/mgr/ceph-<id>` from inside the container).

## FQDN vs bare host names

> Note:
>
> cephadm 要求通过 `ceph orch host add` 给出的主机名等于远程主机上 `hostname` 的输出。

否则 cephadm 无法确保 `ceph * metadata` 返回的名称与 cephadm 已知的主机匹配。 Thi这可能会导致 CEPHADM_STRAY_HOST 警告。

配置新主机时，有两种有效的方法可以设置主机名：

1. Using the bare host name. In this case:

- `hostname` returns the bare host name.
- `hostname -f` returns the FQDN.

2. Using the fully qualified domain name as the host name. In this case:

- `hostname` returns the FQDN
- `hostname -s` return the bare host name

Note that `man hostname` recommends `hostname` to return the bare host name:

> The FQDN (Fully Qualified Domain Name) of the system is the name that the resolver(3) returns for the host name, such as, ursula.example.com. It is usually the hostname followed by the DNS domain name (the part after the first dot). You can check the FQDN using `hostname --fqdn` or the domain name using `dnsdomainname`.
>
> ```bash
> You cannot change the FQDN with hostname or dnsdomainname.
> 
> The recommended method of setting the FQDN is to make the hostname
> be an alias for the fully qualified name using /etc/hosts, DNS, or
> NIS. For example, if the hostname was "ursula", one might have
> a line in /etc/hosts which reads
> 
>        127.0.1.1    ursula.example.com ursula
> ```

Which means, `man hostname` recommends `hostname` to return the bare host name. This in turn means that Ceph will return the bare host names when executing `ceph * metadata`. This in turn means cephadm also requires the bare host name when adding a host to the cluster: `ceph orch host add <bare-name>`.