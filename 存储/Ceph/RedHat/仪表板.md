# 仪表板指南

Red Hat Ceph Storage 7

## 使用 Ceph Dashboard 监控 Ceph 集群

 Red Hat Ceph Storage Documentation Team  

[法律通告](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#idm140565632177488)

**摘要**

​				本指南说明了如何使用 Red Hat Ceph Storage Dashboard 进行监控和管理。 		

​				红帽致力于替换我们的代码、文档和 Web 属性中存在问题的语言。我们从这四个术语开始：master、slave、黑名单和白名单。由于此项工作十分艰巨，这些更改将在即将推出的几个发行版本中逐步实施。详情请查看 [CTO Chris Wright 信息](https://www.redhat.com/en/blog/making-open-source-more-inclusive-eradicating-problematic-language)。 		

------

# 第 1 章 Ceph 仪表板概述

​			作为存储管理员，Red Hat Ceph Storage 控制面板提供管理和监控功能，允许您管理和监控集群，以及视觉化与其相关的信息和性能统计信息。控制面板使用由 `ceph-mgr` 守护进程托管的 Web 服务器。 	

​			控制面板可从 Web 浏览器访问，包含许多有用的管理和监控功能，例如配置管理器模块并监控 OSD 状态。 	

**先决条件**

- ​					系统管理员级别体验。 			

## 1.1. Ceph Dashboard 组件

​				仪表板的功能由多个组件提供。 		

- ​						用于部署的 Cephadm 应用。 				
- ​						嵌入式仪表板 `ceph-mgr` 模块。 				
- ​						嵌入的 Prometheus `ceph-mgr` 模块。 				
- ​						Prometheus 时间序列数据库。 				
- ​						Prometheus node-exporter 守护进程，在存储集群的每个主机上运行。 				
- ​						用于监控用户界面和警报的 Grafana 平台。 				

**其它资源**

- ​						如需更多信息，请参阅 [*Prometheus 网站*](https://prometheus.io/)。 				
- ​						如需更多信息，请参阅 [*Grafana 网站*](https://grafana.com/)。 				

## 1.2. Ceph 仪表板功能

​				Ceph 仪表板提供以下功能： 		

- ​						**多用户和角色管理** ：控制面板支持多个具有不同权限和角色的用户帐户。可以使用命令行和 Web 用户界面来管理用户帐户和角色。控制面板支持多种增强密码安全性的方法。可以配置密码复杂性规则，要求用户在登录后或可配置的时间段后更改密码。 				
- ​						**单点登录(SSO)** ：控制面板支持使用 SAML 2.0 协议通过外部身份提供程序进行身份验证。 				
- ​						**审计** ：仪表板后端可以配置为记录 Ceph 管理器日志中的所有 PUT、POST 和 DELETE API 请求。 				

**管理功能**

- ​						**查看集群层次结构** ：例如，查看 CRUSH 映射，以确定特定 OSD ID 在哪个主机上运行。如果 OSD 出现问题，这非常有用。 				
- ​						**配置管理器模块** ：您可以查看和更改 Ceph 管理器模块的参数。 				
- ​						**嵌入式 Grafana 仪表板** ：Ceph Dashboard Grafana 仪表板可能嵌入到外部应用程序和网页中，以提供有关 Prometheus 模块收集的信息和性能指标。 				
- ​						**查看并过滤日志** ：您可以查看事件和审计日志，并根据优先级、关键字、日期或时间范围过滤它们。 				
- ​						**切换仪表板组件** ：您可以启用和禁用仪表板组件，以便仅提供您需要的功能。 				
- ​						**管理 OSD 设置**  ：您可以使用控制面板设置集群范围的 OSD 标志。您也可以将 OSD 标记为 up、down 或 out，清除和重新加权  OSD，执行清理操作，修改各种清理相关配置选项，选择 profile 以调整回填活动级别。您可以设置和更改 OSD  的设备类别，按设备类别显示和排序 OSD。您可以在新的驱动器和主机上部署 OSD。 				
- ​						**查看警报** ：警报页面允许您查看当前警报的详情。 				
- ​						**升级** ：您可以使用仪表板升级 Ceph 集群版本。 				
- ​						**镜像的服务质量** ：您可以为镜像设置性能限制，例如限制 IOPS 或读取 BPS burst 率。 				

**监控功能**

- ​						**用户名和密码保护** ：您只能通过提供可配置的用户名和密码来访问控制面板。 				

- ​						**集群整体健康状况** ： 显示性能和容量指标。这还显示总体集群状态、存储利用率，例如对象数量、原始容量、每个池的使用情况、池列表及其状态和用量统计。 				

- ​						**主机** ：提供与集群关联的所有主机的列表，以及运行的服务和已安装的 Ceph 版本。 				

- ​						**性能计数器** ：显示每个正在运行的服务的详细统计信息。 				

- ​						**Monitors**: 列出所有 monitor、其仲裁状态和打开的会话。 				

- ​						**配置编辑器** ：显示所有可用的配置选项、描述、类型、默认和当前设置的值。这些值可编辑。 				

- ​						**集群日志** ：显示并过滤集群事件的最新更新，并根据优先级、日期或关键字审核日志文件。 				

- ​						**设备管理** ：列出 Orchestrator 已知的所有主机。列出附加到主机的所有驱动器及其属性。显示推动健康预测、SMART 数据和闪烁的 LED。 				

- ​						**查看存储集群容量** ：您可以在 Ceph 仪表板的 *Capacity* 面板中查看 Red Hat Ceph Storage 集群的原始存储容量。 				

- ​						**池** ：列出和管理所有 Ceph 池及其详细信息。例如：应用程序、放置组、复制大小、EC 配置集、配额、CRUSH 规则集等。 				

- ​						**OSD** ：列出和管理所有 OSD、其状态和使用量统计，以及 OSD map、元数据和性能计数器等详细信息。列出与 OSD 关联的所有驱动器。 				

- ​						**镜像** ：列出所有 RBD 镜像及其属性，如 size、object 和 features。创建、复制、修改和删除 RBD 镜像。创建、删除和回滚选定镜像的快照，防止或取消保护这些快照以进行修改。复制或克隆快照，扁平化克隆的镜像。 				

  注意

  ​							特定镜像的 *Overall Performance* 选项卡中的 I/O 性能图仅在通过设置 *Cluster* > *Manager 模块* > *Prometheus* 中的 `rbd_stats_pool` 参数来指定包括该镜像的池后才会显示值。 					

- ​						**RBD 镜像功能** ：启用并配置 RBD 镜像到远程 Ceph 服务器。列出所有活跃同步守护进程及其状态、池和 RBD 镜像，包括它们的同步状态。 				

- ​						**Ceph 文件系统** ：列出所有活动的 Ceph 文件系统(CephFS)客户端和相关池，包括它们的使用量统计数据。驱除活跃的 CephFS 客户端，管理 CephFS 配额和快照，并浏览 CephFS 目录结构。 				

- ​						**对象网关(RGW)** ：列出所有活跃对象网关及其性能计数器。显示和管理，包括添加、编辑、删除对象网关用户及其详情，如配额，以及用户的存储桶及其详情，如所有者或配额。 				

- ​						**NFS** ：使用 NFS Ganesha 管理 CephFS 和 Ceph 对象网关 S3 bucket 的 NFS 导出。 				

**安全功能**

- ​						**SSL 和 TLS 支持** ：Web 浏览器与仪表板之间的所有 HTTP 通信均通过 SSL 保护。可以使用内置命令创建自签名证书，但也可以导入由证书颁发机构(CA)签名和发布的自定义证书。 				

**其它资源**

- ​						如需更多信息，请参阅 *Red Hat Ceph Storage Dashboard 指南中的 [\*切换 Ceph\*仪表板](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#toggling-ceph-dashboard-features_dash)*  功能。 				

## 1.3. Red Hat Ceph Storage Dashboard 架构

​				控制面板架构依赖于 Ceph 管理器仪表板插件和其他组件。请参见以下图以了解它们如何协同工作。 		

[![Ceph 仪表板架构图](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/835053b1c91445e4fd9f76290e6a8b76/dash_dashboard-architecture.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/835053b1c91445e4fd9f76290e6a8b76/dash_dashboard-architecture.png)

# 第 2 章 Ceph Dashboard 安装和访问

​			作为系统管理员，您可以使用 bootstrap 集群中提供的凭证访问仪表板。 	

​			Cephadm 默认安装控制面板。以下是仪表板 URL 的示例： 	



```none
URL: https://host01:8443/
User: admin
Password: zbiql951ar
```

注意

​				更新浏览器，再清除 Cookie，然后再访问仪表板 URL。 		

​			以下是可用于 Ceph 仪表板配置的 Cephadm bootstrap 选项： 	

- ​					[-initial-dashboard-user *INITIAL_DASHBOARD_USER*] - 在 bootstrapping 设置 initial-dashboard-user 时使用这个选项。 			
- ​					[-initial-dashboard-password *INITIAL_DASHBOARD_PASSWORD*] - 在 bootstrapping 设置 initial-dashboard-password 时使用该选项。 			
- ​					[–ssl-dashboard-port *SSL_DASHBOARD_PORT*] - 当 bootstrap 设置自定义仪表板端口而不是默认的 8443 端口时使用这个选项。 			
- ​					[-dashboard-key *DASHBOARD_KEY*] - 在 bootstrap 设置用于 SSL 的自定义密钥时使用这个选项。 			
- ​					[–dashboard-crt *DASHBOARD_CRT*] - 在 bootstrap 来为 SSL 设置自定义证书时使用这个选项。 			
- ​					[–skip-dashboard] - 当 bootstrap 在没有仪表板的情况下部署 Ceph 时使用这个选项。 			
- ​					[–dashboard-password-noupdate] - 如果您使用了以上两个选项并不希望在第一次登陆时重置密码时，在 bootstrap 中使用这个选项。 			
- ​					[-allow-fqdn-hostname] - 在 bootstrap 时使用该选项以允许完全限定的主机名。 			
- ​					[-skip-prepare-host] - 在 bootstrap 时使用该选项跳过主机准备。 			

注意

​				为了避免与仪表板相关的外部 URL 连接问题，请将完全限定域名(FQDN)用于主机名，例如 `host01.ceph.redhat.com`。 		

注意

​				在客户端互联网浏览器中直接打开 Grafana URL，并接受安全例外来查看 Ceph 仪表板上的图形。重新加载浏览器以查看更改。 		

**示例**

​				



```none
[root@host01 ~]# cephadm bootstrap --mon-ip 127.0.0.1 --registry-json cephadm.txt  --initial-dashboard-user  admin --initial-dashboard-password zbiql951ar --dashboard-password-noupdate --allow-fqdn-hostname
```

注意

​				在使用 `cephadm` 增强存储集群时，您可以使用 `--image` 选项用于自定义容器镜像或本地容器镜像。 		

注意

​				只有在 bootstrap 没有使用 `--dashboard-password-noupdate` 选项时，您必须在第一次使用 bootstrap 时更改密码。您可以在 `var/log/ceph/cephadm.log` 文件中找到 Ceph 仪表板凭据。使用 "Ceph Dashboard is now available at" 字符串进行搜索。 		

​			本节涵盖以下任务： 	

- ​					[*Ceph 控制面板的网络端口要求*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#network-port-requirements-for-ceph-dashboard_dash) 			
- ​					[*访问 Ceph 仪表板*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#accessing-the-ceph-dashboard_dash) 			
- ​					[*在 Ceph 仪表板上扩展集群*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#expanding-the-cluster-on-the-ceph-dashboard_dash) 			
- ​					[*升级集群*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#upgrading-a-cluster_dash) 			
- ​					[*切换 Ceph 仪表板功能*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#toggling-ceph-dashboard-features_dash) 			
- ​					[*了解 Ceph 仪表板的初始页面*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#understanding-the-landing-page-of-the-ceph-dashboard_dash) 			
- ​					[*手动启用 Red Hat Ceph Storage Dashboard*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#enabling-red-hat-ceph-storage-dashboard-manually_dash) 			
- ​					[*使用 Ceph 仪表板更改仪表板密码*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#changing-the-dashboard-password-using-the-ceph-dashboard_dash) 			
- ​					[*使用命令行界面更改 Ceph 仪表板密码*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#changing-the-ceph-dashboard-password-using-the-command-line-interface_dash) 			
- ​					[*为 Grafana 设置 `admin` 用户密码*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#setting-admin-user-password-for-grafana_dash) 			
- ​					[*创建管理员帐户，将用户同步到 Ceph 仪表板*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#creating-an-admin-account-for-syncing-users-to-the-ceph-dashboard_dash) 			
- ​					[*使用红帽单点登录将用户同步到 Ceph 控制面板*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#syncing-users-to-the-ceph-dashboard-using-red-hat-single-sign-on_dash) 			
- ​					[*为 Ceph 控制面板启用单点登录*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#enabling-single-sign-on-for-the-ceph-dashboard_dash) 			
- ​					[*为 Ceph 控制面板禁用单点登录*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#disabling-single-sign-on-for-the-ceph-dashboard_dash) 			

## 2.1. Ceph 控制面板的网络端口要求

​				Ceph 仪表板组件使用某些必须可以被访问的 TCP 网络端口。默认情况下，在安装 Red Hat Ceph Storage 时，在 `firewalld` 中自动打开网络端口。 		

表 2.1. TCP 端口要求

| 端口 | 使用                                                       | 原始主机                                                     | 目的地主机                                                   |
| ---- | ---------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 8443 | 仪表板 Web 界面                                            | 需要访问 Grafana 服务器上的 Ceph Dashboard UI 和主机的 IP 地址，因为 AlertManager 服务也可以启动到 Dashboard 的连接以报告警报。 | Ceph 管理器主机。                                            |
| 3000 | Grafana                                                    | 需要访问 Grafana 仪表板 UI 和所有 Ceph Manager 主机和 Grafana 服务器的 IP 地址。 | 运行 Grafana 服务器的主机。                                  |
| 2049 | NFS-Ganesha                                                | 需要访问 NFS 的 IP 地址。                                    | 提供 NFS 服务的 IP 地址。                                    |
| 9095 | 基本 Prometheus 图形的默认 Prometheus 服务器               | 需要访问 Prometheus UI 以及运行 Prometheus 的所有 Ceph Manager 主机和 Grafana 服务器或主机的 IP 地址。 | 运行 Prometheus 的主机或主机。                               |
| 9093 | Prometheus Alertmanager                                    | 需要访问 Alertmanager Web UI 以及运行 Prometheus 的所有 Ceph Manager 主机和 Grafana 服务器或主机的 IP 地址。 | Grafana 服务器下所有 Ceph Manager 主机。                     |
| 9094 | Prometheus Alertmanager 可配置从多个实例组成的高可用性集群 | Grafana 服务器下所有 Ceph Manager 主机。                     | Prometheus Alertmanager High Availability（对等点守护进程同步），因此 `src` 和 `dst` 应该都是运行 Prometheus Alertmanager 的主机。 |
| 9100 | Prometheus `node-exporter` 守护进程                        | 运行 Prometheus 的主机需要查看节点导出器指标 Web UI 以及运行 Prometheus 的所有 Ceph Manager 主机和 Grafana 服务器或主机。 | 所有存储集群主机，包括 MON、OSDS、Grafana 服务器主机。       |
| 9283 | Ceph Manager Prometheus exporter 模块                      | 运行 Prometheus 的主机需要访问 Ceph 导出器 metrics Web UI 和 Grafana 服务器。 | 所有 Ceph Manager 主机。                                     |

**其它资源**

- ​						有关更多信息，请参阅 [*Red Hat Ceph Storage 安装指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/installation_guide)。 				
- ​						如需更多信息，请参阅[*配置和管理网络*](https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/8/html-single/configuring_and_managing_networking/index)中的[*使用和配置防火墙*](https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/8/html-single/configuring_and_managing_networking/index#using-and-configuring-firewalls_configuring-and-managing-networking)。 				

## 2.2. 访问 Ceph 仪表板

​				您可以访问 Ceph 仪表板来管理和监控 Red Hat Ceph Storage 集群。 		

**先决条件**

- ​						成功安装 Red Hat Ceph Storage 仪表板。 				
- ​						NTP 正在正确同步时钟。 				

**流程**

1. ​						在网页浏览器中输入以下 URL： 				

   **语法**

   ​							

   

   ```none
   https://HOST_NAME:PORT
   ```

   ​						*替换：* 				

   - ​								带有活跃管理器主机的完全限定域名(FQDN)的 *HOST_NAME*。 						

   - ​								*PORT* 带有端口 `8443` 						

     **示例**

     ​									

     

     ```none
     https://host01:8443
     ```

     ​								您也可以在 Cephadm shell 中运行以下命令获取仪表板的 URL： 						

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# ceph mgr services
     ```

     ​								此命令将显示当前配置的所有端点。查找 `dashboard` 键，以获取用于访问仪表板的 URL。 						

2. ​						在登录页面中，输入用户名 `admin` 和 bootstrap 中提供的默认密码。 				

3. ​						首次登录 Red Hat Ceph Storage 仪表板时，您必须更改密码。 				

4. ​						登录后，会显示仪表板默认登录页面，其中提供了 Red Hat Ceph Storage 集群的状态、性能、清单和容量指标的高级别概述。 				

   图 2.1. Ceph 仪表板登录页面

   [![Ceph 仪表板登录页面](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/487ab193bbb517affc8059ba273df2fe/dash_ceph-dashboard-landing-page.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/487ab193bbb517affc8059ba273df2fe/dash_ceph-dashboard-landing-page.png)

5. ​						点仪表板登录页面上的菜单图标(  					![Menu icon](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/6eddb5667ec4a3e55f01b22a58ecce42/dash_dashboard-vertical-menu.png) 					 )，折叠或显示垂直菜单中的选项。 				

**其它资源**

- ​						有关更多信息，请参阅 *Red Hat [\*Ceph Storage Dashboard 指南中的使用 Ceph\*仪表板更改仪表板密码](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#changing-the-dashboard-password-using-the-ceph-dashboard_dash)* 。 				

## 2.3. 在 Ceph 仪表板中扩展集群

​				您可以使用控制面板扩展 Red Hat Ceph Storage 集群来添加主机、添加 OSD 和创建服务，如  Alertmanager、Cephadm-exporter、CephFS-mirror、Grafana、ingress、MDS、NFS、node-exporter、Prometheus、RBD-mirror 和 Ceph 对象网关等服务。 		

​				引导新的存储集群后，会创建 Ceph Monitor 和 Ceph Manager 守护进程，集群处于 *HEALTH_WARN* 状态。在仪表板上创建集群的所有服务后，集群的健康状况从 *HEALTH_WARN* 更改为 *HEALTH_OK* 状态。 		

**先决条件**

- ​						启动的存储集群。如需了解更多详细信息 [*，请参阅 \*Red Hat Ceph Storage 安装指南中的\* 引导*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/installation_guide#bootstrapping-a-new-storage-cluster_install) 新存储集群部分。 				
- ​						在 Red Hat Ceph Storage 仪表板中，用户至少为 `cluster-manager` 角色。如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的 Ceph\*仪表板上的用户角色和权限](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-roles-and-permissions-on-the-ceph-dashboard_dash)*  部分。 				

**流程**

1. ​						将 Bootstrapped 主机中的 admin 密钥复制到其他主机： 				

   **语法**

   ​							

   

   ```none
   ssh-copy-id -f -i /etc/ceph/ceph.pub root@HOST_NAME
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ssh-copy-id -f -i /etc/ceph/ceph.pub root@host02
   [ceph: root@host01 /]# ssh-copy-id -f -i /etc/ceph/ceph.pub root@host03
   ```

2. ​						使用 bootstrap 过程中提供的默认凭证登录到控制面板。 				

3. ​						更改密码，再使用新密码登录控制到仪表板。 				

4. ​						在登录页面上，单击 *Expand Cluster*。 				

   图 2.2. 展开集群

   ![展开集群](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/dc6ce115dfcea4eda75d2b30982b5038/dash_expand-cluster.png)

5. ​						添加主机： 				

   1. ​								在 *Add Hosts* 窗口中，单击 *+Add*。 						

   2. ​								提供主机名。这与从 bootstrapped 主机复制密钥时提供的主机名相同。 						

      注意

      ​									您可以在 *Add Hosts* 对话框中使用 工具提示来获取更多详细信息。 							

   3. ​								可选：提供主机的对应 IP 地址。 						

   4. ​								可选：选择将要创建服务的主机的标签。 						

   5. ​								点*添加主机*。 						

   6. ​								对于存储集群中的所有主机，请按照以下步骤操作。 						

6. ​						在 *Add Hosts* 窗口中，单击 *Next*。 				

7. ​						创建 OSD： 				

   1. ​								在 *Create OSD* 窗口中，对于主设备，单击 *+Add*。 						
   2. ​								在*主设备*窗口中，过滤该设备并选择设备。 						
   3. ​								点击 *Add*。 						
   4. ​								可选：在 *Create OSD* 窗口中，如果您有任何共享设备，如 WAL 或 DB 设备，则添加设备。 						
   5. ​								可选：点复选框*加密*以对功能进行加密。 						
   6. ​								在 *Create OSD* 窗口中，单击 *Next*。 						

8. ​						创建服务： 				

   1. ​								在 *Create Services* 窗口中，单击 *+Create*。 						
   2. ​								在 *Create Service* 对话框中， 						
      1. ​										从下拉菜单中选择服务的类型。 								
      2. ​										提供服务 ID，即服务的唯一名称。 								
      3. ​										通过主机或标签提供放置。 								
      4. ​										选择主机。 								
      5. ​										提供需要部署的守护进程或服务数量。 								
   3. ​								点 *Create Service*。 						

9. ​						在 *Create Service* 窗口中，单击 *Next*。 				

10. ​						查看 *Cluster Resources*,*Hosts by Services*,*Host Details*。如果要编辑任何参数，点 *Back* 并按照上述步骤操作。 				

    图 2.3. 查看集群

    [![查看集群](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f6bcc37fb5779af4bf1f0926ec7bb300/dash_review-cluster.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f6bcc37fb5779af4bf1f0926ec7bb300/dash_review-cluster.png)

11. ​						点 *Expand Cluster*。 				

12. ​						您会收到集群扩展成功的通知。 				

13. ​						在控制面板上，集群健康状态更改为 *HEALTH_OK* 状态。 				

**验证**

1. ​						登录到 `cephadm` shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						运行 `ceph -s` 命令。 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph -s
   ```

   ​						集群的运行状况是 *HEALTH_OK*。 				

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的 Ceph\*仪表板上的用户角色和权限](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-roles-and-permissions-on-the-ceph-dashboard_dash)*  部分。 				
- ​						如需了解更多详细信息，请参阅 [*Red Hat Ceph Storage 安装指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/installation_guide)。 				

## 2.4. 升级集群

​				使用控制面板升级 Ceph 集群。 		

​				集群镜像从 `registry.redhat.io` 自动拉取。（可选）使用自定义镜像进行升级。 		

**流程**

1. ​						通过仪表板上的 **Cluster > Upgrade** 页面查看集群升级是否可用和升级。 				

   注意

   ​							如果仪表板显示 `Not retrieve upgrade` 信息，请检查 registry 是否已添加到容器配置文件中，并具有适当的登录凭证到 Podman 或 docker。 					

   ​						如果需要 **，** 在升级过程中点 **暂停** 或停止。升级进度会在进度栏中显示，以及升级过程中的信息信息。 				

   注意

   ​							在停止升级时，升级会首先暂停，然后提示您停止升级。 					

2. ​						可选。在 **Upgrade** 页面的 **Cluster logs** 部分查看集群日志。 				

3. ​						通过确认集群状态显示 OK 状态来验证升级是否已成功完成。 				

## 2.5. 切换 Ceph 仪表板功能

​				您可以通过根据需要启用或禁用功能来自定义 Red Hat Ceph Storage  仪表板组件。所有功能都会默认启用。当禁用某个功能时，web-interface 元素会变为隐藏的，相关的 REST API  端点会拒绝该功能的任何进一步请求。启用和禁用仪表板功能可以通过命令行界面或 Web 界面完成。 		

​				可用功能： 		

- ​						Ceph 块设备： 				
  - ​								镜像管理，`rbd` 						
  - ​								镜像，`mirroring` 						
- ​						Ceph 文件系统，`cephfs` 				
- ​						Ceph 对象网关, `rgw` 				
- ​						NFS Ganesha 网关 `nfs` 				

注意

​					默认情况下，Ceph Manager 与 Ceph 监控器共存。 			

注意

​					您可以一次性禁用多个功能。 			

重要

​					禁用某个功能后，可能需要 20 秒来反映 web 界面中的更改。 			

**先决条件**

- ​						安装并配置 Red Hat Ceph Storage 仪表板软件。 				
- ​						用户访问 Ceph Manager 主机或控制面板 Web 界面。 				
- ​						对 Ceph Manager 主机的 root 级别访问权限。 				

**流程**

- ​						从仪表板 web 界面中切换仪表板功能： 				

  1. ​								在仪表板登录页面中，进入 *Cluster* 下拉菜单。 						
  2. ​								选择 *Manager Modules*，然后选择 *Dashboard*。 						
  3. ​								在 *Edit Manager 模块* 页面中，您可以通过选中或取消选中功能名称旁边的选择框来启用或禁用仪表板功能。 						
  4. ​								完成选择后，向下滚动并单击 *更新*。 						

- ​						使用命令行界面切换仪表板功能： 				

  1. ​								登录到 Cephadm shell： 						

     **示例**

     ​									

     

     ```none
     [root@host01 ~]# cephadm shell
     ```

  2. ​								列出功能状态： 						

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# ceph dashboard feature status
     ```

  3. ​								禁用一个功能： 						

     

     ```none
     [ceph: root@host01 /]# ceph dashboard feature disable rgw
     ```

     ​								本例禁用 Ceph 对象网关功能。 						

  4. ​								启用一个功能： 						

     

     ```none
     [ceph: root@host01 /]# ceph dashboard feature enable cephfs
     ```

     ​								这个示例启用了 Ceph Filesystem 功能。 						

## 2.6. 了解 Ceph 仪表板的登录页面

​				登录页面通过导航栏和单个面板显示整个 Ceph 集群的概述。 		

​				导航栏提供以下选项： 		

- ​						有关任务和通知的消息。 				
- ​						链接到 Red Hat Ceph Storage 仪表板的文档、Ceph Rest API 和详细信息。 				
- ​						用户管理和遥测配置的链接。 				
- ​						用于更改密码和注销仪表板的链接。 				

图 2.4. 导航栏

![导航栏](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/e5c0e990a5d6ce45df0cfbc4b69b74e4/dash_navigation-bar.png)

​				除此之外，单个面板还显示有关集群状态的特定信息。 		

**类别**

​					登录页面将面板分为以下三种类别： 			

1. ​						**Status** 				
2. ​						**容量** 				
3. ​						**性能** 				

图 2.5. Ceph 仪表板登录页面

[![Ceph dashboard Landing 页面](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/487ab193bbb517affc8059ba273df2fe/dash_ceph-dashboard-landing-page.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/487ab193bbb517affc8059ba273df2fe/dash_ceph-dashboard-landing-page.png)

**状态面板**

​					状态面板显示集群和主机和守护进程状态的健康状态。 			

​				**集群状态** ：显示 Ceph 存储集群的当前状态。 		

​				**主机** ：显示 Ceph 存储集群中的主机总数。 		

​				**Monitors**: 显示 Ceph 监控器和仲裁状态的数量。 		

​				**OSD** ：显示 Ceph 存储集群中的 OSD 总数，以及状态为 *up*, 和 *in* 的数量。 		

​				**管理器** ：显示管理器守护进程的数量和状态。 		

​				**对象网关** ：显示 Ceph 存储集群中的对象网关数。 		

​				**Metadata Servers**: 显示 Ceph 文件系统(CephFS)的元数据服务器的数量和状态。 		

**Capacity 面板**

​					容量面板显示存储使用指标。 			

​				**原始容量** ：显示集群的原始存储容量的利用率和可用性。 		

​				**对象**：显示池中对象总数，将对象划分为 *Healthy*、*Misplaced*、*Degraded* 或 *Unfound* 状态。 		

​				**PG 状态** ：显示放置组的总数量，以及一个根据状态 *Clean*、*Working*、*Warning* 或 *Unknown* 显示的 PG 图。为了简化对 PG 状态的显示，*Working* 和 *Warning* 实际上包括多个状态。 		

***Working\* 状态包括具有任何这些状态的 PG：**

- ​						激活 				
- ​						backfill_wait 				
- ​						回填 				
- ​						创建 				
- ​						deep 				
- ​						degraded 				
- ​						forced_backfill 				
- ​						forced_recovery 				
- ​						peering 				
- ​						peered 				
- ​						recovering 				
- ​						recovery_wait 				
- ​						repair 				
- ​						清理 				
- ​						snaptrim 				
- ​						snaptrim_wait 				

***Warning\* 状态包含具有任何这些状态的 PG：**

- ​						backfill_toofull 				
- ​						backfill_unfound 				
- ​						down 				
- ​						incomplete 				
- ​						不一致 				
- ​						recovery_toofull 				
- ​						recovery_unfound 				
- ​						remapped 				
- ​						snaptrim_error 				
- ​						stale 				
- ​						undersized 				

​				**池** ：显示 Ceph 集群中的存储池数量。 		

​				**每个 OSD 的 PG** ：显示每个 OSD 的 PG 数量。 		

**性能面板**

​					性能面板显示与数据传输速度相关的信息。 			

​				**客户端读/写** ：显示每秒的总输入/输出操作、每秒读取数和每秒写入数。 		

​				**客户端吞吐量** ：显示客户端吞吐量、读取吞吐量和写入吞吐量。 		

​				**恢复吞吐量** ：显示集群修复和平衡操作的速度。例如，显示由于磁盘丢失而可能移动的任何后台数据的状态。 		

​				**Scrubbing**: 显示 Ceph 是否清理数据以验证其完整性。 		

**其它资源**

- ​						有关更多信息，请参阅 *Red Hat [\*Ceph Storage Dashboard 指南中的在 Ceph\*仪表板中](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#monitor-the-cluster-on-the-ceph-dashboard)*  监控集群部分。 				

## 2.7. 使用 Ceph 仪表板更改仪表板密码

​				默认情况下，用于访问仪表板的密码在引导集群时由系统随机生成。首次登录 Red Hat Ceph Storage 仪表板时，您必须更改密码。您可以使用控制面板更改 `admin` 用户的密码。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				

**流程**

1. ​						登录到仪表板： 				

   

   ```none
   https://HOST_NAME:8443
   ```

2. ​						点 *Dashboard Settings* 图标，然后点 *User Management*。 				

   图 2.6. 用户管理

   ![用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2689f14927254476949f39cf05984062/dash_dashboard-settings-user-management.png)

3. ​						若要更改 **admin** 的密码，请单击此密码。 				

4. ​						在 *Edit* 下拉菜单中选择 *Edit*。 				

5. ​						在 *Edit User* 窗口中，输入新密码并更改其他参数，然后点 *Edit User*。 				

   图 2.7. 编辑用户管理

   [![编辑用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f55339e1703169a0f549118b0b4031cd/dash_edit-user-management.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f55339e1703169a0f549118b0b4031cd/dash_edit-user-management.png)

   ​						您将会登出并重定向到登录屏幕。此时会出现确认密码更改的通知。 				

## 2.8. 使用命令行界面更改 Ceph 仪表板密码

​				如果您忘记了 Ceph 仪表板密码，您可以使用命令行界面更改密码。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						安装了仪表板的主机的根级别访问。 				

**流程**

1. ​						登录到 Cephadm shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						创建 `dashboard_password.yml` 文件： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# touch dashboard_password.yml
   ```

3. ​						编辑该文件并添加新仪表板密码： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# vi dashboard_password.yml
   ```

4. ​						重置仪表板密码： 				

   **语法**

   ​							

   

   ```none
   ceph dashboard ac-user-set-password DASHBOARD_USERNAME -i PASSWORD_FILE
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard ac-user-set-password admin -i dashboard_password.yml
   {"username": "admin", "password": "$2b$12$i5RmvN1PolR61Fay0mPgt.GDpcga1QpYsaHUbJfoqaHd1rfFFx7XS", "roles": ["administrator"], "name": null, "email": null, "lastUpdate": , "enabled": true, "pwdExpirationDate": null, "pwdUpdateRequired": false}
   ```

**验证**

- ​						使用新密码登录控制面板。 				

## 2.9. 为 Grafana 设置 admin 用户密码

​				默认情况下，`cephadm` 不会为 Grafana 创建管理员用户。使用 Ceph 编排器，您可以创建 admin 用户并设置密码。 		

​				使用这些凭证，您可以使用 admin 用户提供的密码登录到存储集群的 Grafana URL。 		

**先决条件**

- ​						安装了监控堆栈的 Red Hat Ceph Storage 集群。 				
- ​						`cephadm` 主机的 root 级别访问权限。 				
- ​						启用 `dashboard` 模块。 				

**流程**

1. ​						作为 root 用户，创建一个 `grafana.yml` 文件并提供以下详情： 				

   **语法**

   ​							

   

   ```none
   service_type: grafana
   spec:
     initial_admin_password: PASSWORD
   ```

   **示例**

   ​							

   

   ```none
   service_type: grafana
   spec:
     initial_admin_password: mypassword
   ```

2. ​						将 `grafana.yml` 文件挂载到容器的一个目录中： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell --mount grafana.yml:/var/lib/ceph/grafana.yml
   ```

   注意

   ​							每次退出 shell 时，您都必须在部署守护进程前将该文件挂载到容器中。 					

3. ​						可选：检查是否启用了 `dashboard` Ceph Manager 模块： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph mgr module ls
   ```

4. ​						可选：启用 `dashboard` Ceph Manager 模块： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph mgr module enable dashboard
   ```

5. ​						使用 `orch` 命令应用规格： 				

   **语法**

   ​							

   

   ```none
   ceph orch apply -i FILE_NAME.yml
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph orch apply -i /var/lib/ceph/grafana.yml
   ```

6. ​						重新部署 `grafana` 服务： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph orch redeploy grafana
   ```

   ​						这会创建一个名为 `admin` 的 admin 用户，用户具有所给密码，用户可以使用这些凭证登录到 Grafana URL。 				

**验证：**

- ​						使用凭证登录到 Grafana： 				

  **语法**

  ​							

  

  ```none
  https://HOST_NAME:PORT
  ```

  **示例**

  ​							

  

  ```none
  https://host01:3000/
  ```

## 2.10. 手动启用 Red Hat Ceph Storage Dashboard

​				如果您在引导过程中使用 `--skip-dashboard` 选项安装了 Red  Hat Ceph Storage 集群，仪表板 URL 和凭证不会出现在引导输出中。您可以使用命令行界面手动启用仪表板。虽然部署了  Prometheus、Grafana、Alertmanager、Alertmanager 和 node-exporter  等监控堆栈组件，但它们会被禁用，您必须手动启用。 		

**先决条件**

- ​						在 bootstrap 中使用 `--skip-dashboard` 选项安装运行的 Red Hat Ceph Storage 集群。 				
- ​						需要启用控制面板的主机的根级别访问权限。 				

**流程**

1. ​						登录到 Cephadm shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						检查 Ceph Manager 服务： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph mgr services
   
   {
       "prometheus": "http://10.8.0.101:9283/"
   }
   ```

   ​						您可以看到没有配置 Dashboard URL。 				

3. ​						启用 dashboard 模块： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph mgr module enable dashboard
   ```

4. ​						为仪表板访问创建自签名证书： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard create-self-signed-cert
   ```

   注意

   ​							您可以禁用证书验证以避免认证错误。 					

5. ​						检查 Ceph Manager 服务： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph mgr services
   
   {
       "dashboard": "https://10.8.0.101:8443/",
       "prometheus": "http://10.8.0.101:9283/"
   }
   ```

6. ​						创建 admin 用户和密码以访问 Red Hat Ceph Storage 仪表板： 				

   **语法**

   ​							

   

   ```none
   echo -n "PASSWORD" > PASSWORD_FILE
   ceph dashboard ac-user-create admin -i PASSWORD_FILE administrator
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# echo -n "p@ssw0rd" > password.txt
   [ceph: root@host01 /]# ceph dashboard ac-user-create admin -i password.txt administrator
   ```

7. ​						启用监控堆栈。详情请参阅 *Red Hat Ceph Storage Dashboard 指南中的* [*启用监控堆栈*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#enabling-monitoring-stack_dash) 部分。 				

**其它资源**

- ​						请参阅 *Red Hat [\*Ceph Storage Operations Guide\*中的使用 Ceph Orchestrator 部署监控堆栈](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/operations_guide/#deploying-the-monitoring-stack-using-the-ceph-orchestrator_ops)*  部分。 				

## 2.11. 创建管理员帐户，将用户同步到 Ceph 仪表板

​				您必须创建 admin 帐户，以便将用户同步到 Ceph 仪表板。 		

​				在创建了帐户后，请使用 Red Hat Single Sign-on(SSO)将用户同步到 Ceph 仪表板。请参阅  *[\*Red Hat Ceph Storage Dashboard Guide\*中的使用红帽单点登录部分将用户同步到 Ceph 仪表板](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#syncing-users-to-the-ceph-dashboard-using-red-hat-single-sign-on_dash)* 。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				
- ​						用户添加到仪表板中。 				
- ​						所有主机上的 root 级别访问权限。 				
- ​						从 ZIP 文件安装的 Red Hat Single Sign-On。如需更多信息，请参阅[*通过 zip 文件安装 Red Hat Single Sign-On*](https://access.redhat.com/documentation/zh-cn/red_hat_single_sign-on/7.4/html-single/server_installation_and_configuration_guide/index#installing_rh_sso_from_a_zip_file)。 				

**流程**

1. ​						在安装了 Red Hat Ceph Storage 的系统中下载 [*Red Hat Single Sign-On 7.4.0 服务器*](https://access.redhat.com/jbossnetwork/restricted/softwareDetail.html?softwareId=80791&product=core.service.rhsso&version=7.4&downloadType=distributions)。 				

2. ​						解压文件夹： 				

   

   ```none
   [root@host01 ~]# unzip rhsso-7.4.0.zip
   ```

3. ​						进入 `standalone/configuration` 目录并打开 `standalone.xml` 进行编辑： 				

   

   ```none
   [root@host01 ~]# cd standalone/configuration
   [root@host01 configuration]# vi standalone.xml
   ```

4. ​						将 `localhost` 和两个 `127.0.0.1` 实例的所有实例替换为安装 Red Hat SSO 的计算机的 IP 地址。 				

5. ​						要从 `rh-sso-7.4` 文件夹的 `bin` 目录中启动服务器，请运行 `standalone` 引导脚本： 				

   

   ```none
   [root@host01 bin]# ./standalone.sh
   ```

6. ​						创建 admin 账户，https: *IP_ADDRESS* :8080/auth，带有一个用户名和密码： 				

   注意

   ​							您只需要在第一次登录到控制台时创建一个 admin 帐户 					

7. ​						使用创建的凭据登录 admin 控制台。 				

**其它资源**

- ​						要在仪表板上为用户添加角色，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建角色](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-roles-on-the-ceph-dashboard_dash)*  部分。 				
- ​						有关在仪表板上创建用户，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建用户\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-users-on-the-ceph-dashboard_dash) 部分*。 				

## 2.12. 使用 Red Hat Single Sign-On 将用户同步到 Ceph 仪表板

​				您可以使用红帽单点登录(SSO)与轻量级目录访问协议(LDAP)集成来把用户同步到 Red Hat Ceph Storage 仪表板。 		

​				用户被添加到特定域中，它们可以通过 SSO 访问仪表板，而无需密码进行任何额外的要求。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				
- ​						用户添加到仪表板中。请参阅 *Red [\*Hat Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建用户\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-users-on-the-ceph-dashboard_dash) 部分*。 				
- ​						所有主机上的 root 级别访问权限。 				
- ​						为同步用户创建的 admin 帐户。请参阅 [*Red \*Hat Ceph Storage 仪表板指南中的创建管理员帐户，以便将用户同步到** Ceph 仪表板部分](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-an-admin-account-for-syncing-users-to-the-ceph-dashboard_dash)。 				

**流程**

1. ​						要创建域，点 *Master* 下拉菜单。在这个域中，您可以提供对用户和应用程序的访问权限。 				

2. ​						在 *Add Realm* 窗口中，输入区分大小写的域名，并将参数 *Enabled* 设置为 ON，点 *Create* ： 				

   [![添加 realm 窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/9f687c52a88fbb1d2bf521bed7722692/dash_sso-add-realm-window.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/9f687c52a88fbb1d2bf521bed7722692/dash_sso-add-realm-window.png)

3. ​						在 *Realm Settings* 选项卡中，设置以下参数并点 *Save* ： 				

   1. ​								enabled - ON 						

   2. ​								用户管理的访问 - ON 						

   3. ​								记录下 SAML 2.0 身份提供商元数据的链接地址，粘贴到 *Client Settings* 中。 						

      [![添加 realm 设置窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/4da3f1a7d35f0219931f6c3306f373c8/dash_sso-add-realm-settings-window.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/4da3f1a7d35f0219931f6c3306f373c8/dash_sso-add-realm-settings-window.png)

4. ​						在 *Clients* 选项卡中，点 *Create* ： 				

   [![添加客户端](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/e7a10533c193662465a23c76959bdba4/dash_sso-add-client.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/e7a10533c193662465a23c76959bdba4/dash_sso-add-client.png)

5. ​						在 *Add Client* 窗口中设置以下参数，点 *Save* ： 				

   1. ​								Client ID - BASE_URL:8443/auth/saml2/metadata 						

      **示例**

      ​									https://example.ceph.redhat.com:8443/auth/saml2/metadata 							

   2. ​								客户端协议 - saml 						

6. ​						在 *Client* 窗口中，在 *Settings* 选项卡中设置以下参数： 				

   表 2.2. 客户端设置标签页

   | **参数的名称**         | **语法**                                                     | **示例**                                                     |
   | ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
   | `客户端 ID`            | BASE_URL:8443/auth/saml2/metadata                            | https://example.ceph.redhat.com:8443/auth/saml2/metadata     |
   | `Enabled`              | ON                                                           | ON                                                           |
   | `客户端协议`           | saml                                                         | saml                                                         |
   | `包括 AuthnStatement`  | ON                                                           | ON                                                           |
   | `签署文档`             | ON                                                           | ON                                                           |
   | `签名算法`             | RSA_SHA1                                                     | RSA_SHA1                                                     |
   | `SAML 签名密钥名称`    | KEY_ID                                                       | KEY_ID                                                       |
   | `有效重定向 URL`       | BASE_URL:8443/*                                              | https://example.ceph.redhat.com:8443/*                       |
   | `基本 URL`             | BASE_URL:8443                                                | https://example.ceph.redhat.com:8443/                        |
   | `Master SAML 处理 URL` | https://localhost:8080/auth/realms/*REALM_NAME*/protocol/saml/descriptor | https://localhost:8080/auth/realms/Ceph_LDAP/protocol/saml/descriptor |

   注意

   ​							从 *Realm Settings* 选项卡中粘贴 SAML 2.0 身份提供程序元数据的链接。 					

   ​						在 Fine Grain SAML Endpoint Configuration 下，设置以下参数并点 *Save* ： 				

   表 2.3. 精细的 SAML 配置

   | **参数的名称**                                    | **语法**                  | **示例**                                         |
   | ------------------------------------------------- | ------------------------- | ------------------------------------------------ |
   | `Assertion Consumer Service POST Binding URL`     | BASE_URL:8443/#/dashboard | https://example.ceph.redhat.com:8443/#/dashboard |
   | `Assertion Consumer Service Redirect Binding URL` | BASE_URL:8443/#/dashboard | https://example.ceph.redhat.com:8443/#/dashboard |
   | `Logout Service Redirect Binding URL`             | BASE_URL:8443/            | https://example.ceph.redhat.com:8443/            |

7. ​						在 *Clients* 窗口的 *Mappers* 选项卡中，设置以下参数并点 *Save* ： 				

   表 2.4. 客户端映射程序标签

   | **参数的名称**    | **Value** |
   | ----------------- | --------- |
   | `协议`            | saml      |
   | `名称`            | username  |
   | `Mapper Property` | 用户属性  |
   | `属性`            | username  |
   | `SAML 属性名称`   | username  |

8. ​						在 *Clients Scope* 选项卡中，选择 *role_list* ： 				

   1. ​								在 *Mappers* 选项卡中，选择 *角色列表*，将 *Single Role Attribute* 设置为 ON。 						

9. ​						选择 *User_Federation* 选项卡： 				

   1. ​								在 *User Federation* 窗口中，从下拉菜单中选择 *ldap* ： 						

   2. ​								在 *User_Federation* 窗口中，*Settings* 选项卡设置以下参数，*然后单击保存* ： 						

      表 2.5. 用户 Federation Settings 标签页

      | **参数的名称**         | **Value**                                                    |
      | ---------------------- | ------------------------------------------------------------ |
      | `控制台显示名称`       | rh-ldap                                                      |
      | `导入用户`             | ON                                                           |
      | `Edit_Mode`            | READ_ONLY                                                    |
      | `用户名 LDAP 属性`     | username                                                     |
      | `RDN LDAP 属性`        | username                                                     |
      | `UUID LDAP 属性`       | nsuniqueid                                                   |
      | `用户对象类`           | inetOrgPerson                                                |
      | `organizationalPerson` | rhatPerson                                                   |
      | `连接 URL`             | 示例：ldap://ldap.corp.redhat.com，点 *Test Connection*。您将收到 LDAP 连接成功的通知。 |
      | `用户 DN`              | ou=users, dc=example, dc=com                                 |
      | `绑定类型`             | simple                                                       |

      ​								点 *Test authentication*。您将收到 LDAP 身份验证成功的通知。 						

   3. ​								在 *Mappers* 选项卡中，选择 *first name* 行并编辑以下参数，然后单击 *Save* ： 						

      - ​										LDAP 属性 - 指定名称 								

   4. ​								在 *User_Federation* 选项卡，*Settings* 选项卡中，点 *Synchronize all users*: 						

      [![用户联邦同步](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/d9c41821993e88e74463b2086f0e2888/dash_sso-user-federation-synchronize.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/d9c41821993e88e74463b2086f0e2888/dash_sso-user-federation-synchronize.png)

      ​								您将收到用户同步成功完成的通知。 						

10. ​						在 *Users* 选项卡中，搜索添加到仪表板中的用户并点击 Search 图标： 				

    [![用户搜索标签页](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/4648b15874549cd62f7320e4f0bf49ce/dash_sso-users-tab-search.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/4648b15874549cd62f7320e4f0bf49ce/dash_sso-users-tab-search.png)

11. ​						要查看用户，请点特定行。您应该看到联邦链接，作为提供给*用户联邦*的名称。 				

    [![用户详情](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f45772c91b07d63f4fd63e3e8a862cc7/dash_sso-users-details.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f45772c91b07d63f4fd63e3e8a862cc7/dash_sso-users-details.png)

    重要

    ​							不要手动添加用户，因为用户不会由 LDAP 同步。如果手动添加，点 *Delete* 来删除用户。 					

**验证**

- ​						用户添加到 realm，控制面板可以使用其电子邮件地址和密码访问 Ceph 仪表板。 				

  **示例**

  ​							https://example.ceph.redhat.com:8443 					

**其它资源**

- ​						要在仪表板上为用户添加角色，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建角色](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-roles-on-the-ceph-dashboard_dash)*  部分。 				

## 2.13. 为 Ceph 仪表板启用单点登录

​				Ceph 控制面板支持使用安全断言标记语言(SAML)2.0 协议进行外部身份验证。在将单点登录(SSO)与 Ceph  控制面板搭配使用之前，请创建控制面板用户帐户并分配所需的角色。Ceph  控制面板对用户执行授权，身份验证过程由现有的身份提供程序(IdP)执行。您可以使用 SAML 协议启用单点登录。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						安装 Ceph 控制面板. 				
- ​						对 Ceph Manager 主机的 root 级别访问权限。 				

**流程**

1. ​						要在 Ceph Dashboard 中配置 SSO，请运行以下命令： 				

   **语法**

   ​							

   

   ```none
   cephadm shell CEPH_MGR_HOST ceph dashboard sso setup saml2 CEPH_DASHBOARD_BASE_URL IDP_METADATA IDP_USERNAME_ATTRIBUTE IDP_ENTITY_ID SP_X_509_CERT SP_PRIVATE_KEY
   ```

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell host01 ceph dashboard sso setup saml2 https://dashboard_hostname.ceph.redhat.com:8443 idp-metadata.xml username https://10.70.59.125:8080/auth/realms/realm_name /home/certificate.txt /home/private-key.txt
   ```

   ​						**替换** 				

   - ​								*CEPH_MGR_HOST* 与 Ceph `mgr` 主机。例如，`host01` 						
   - ​								*CEPH_DASHBOARD_BASE_URL* 带有可以访问 Ceph 仪表板的基本 URL。 						
   - ​								*IDP_METADATA*，包含到远程或本地路径的 URL，或 IdP 元数据 XML 的内容。支持的 URL 类型包括 http、https 和 文件。 						
   - ​								**可选**:*IDP_USERNAME_ATTRIBUTE*，包含用于从身份验证响应中获取用户名的属性。默认为 *uid*。 						
   - ​								**可选** ：当 IdP 元数据中存在多个实体 ID 时，使用 IdP 实体 ID 的 *IDP_ENTITY_ID*。 						
   - ​								**可选**:*SP_X_509_CERT*，包含 Ceph Dashboard 用来签名和加密的证书文件路径。 						
   - ​								**可选** ：*SP_PRIVATE_KEY* 以及 Ceph Dashboard 用来签名和加密的私钥的文件路径。 						

2. ​						验证当前的 SAML 2.0 配置： 				

   **语法**

   ​							

   

   ```none
   cephadm shell CEPH_MGR_HOST ceph dashboard sso show saml2
   ```

   **示例**

   ​							

   

   ```none
   [root@host01 ~]#  cephadm shell host01 ceph dashboard sso show saml2
   ```

3. ​						要启用 SSO，运行以下命令： 				

   **语法**

   ​							

   

   ```none
   cephadm shell CEPH_MGR_HOST ceph dashboard sso enable saml2
   SSO is "enabled" with "SAML2" protocol.
   ```

   **示例**

   ​							

   

   ```none
   [root@host01 ~]#  cephadm shell host01 ceph dashboard sso enable saml2
   ```

4. ​						打开您的仪表板 URL。 				

   **示例**

   ​							

   

   ```none
   https://dashboard_hostname.ceph.redhat.com:8443
   ```

5. ​						在 SSO 页面上，输入登录凭据。SSO 会重定向到仪表板 Web 界面。 				

**其它资源**

- ​						要禁用单点登录，请参阅 [*Red \*Hat Ceph Storage 仪表板指南中的 Ceph\* 仪表板禁用单点登录*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#disabling-single-sign-on-for-the-ceph-dashboard_dash)。 				

## 2.14. 为 Ceph 仪表板禁用单点登录

​				您可以使用 SAML 2.0 协议禁用 Ceph 控制面板的单点登录。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						安装 Ceph 控制面板. 				
- ​						对 Ceph Manager 主机的 root 级别访问权限。 				
- ​						为 Ceph Dashboard 启用单点登录 				

**流程**

1. ​						要查看 SSO 的状态，请运行以下命令： 				

   **语法**

   ​							

   

   ```none
   cephadm shell CEPH_MGR_HOST ceph dashboard sso status
   ```

   **示例**

   ​							

   

   ```none
   [root@host01 ~]#  cephadm shell host01 ceph dashboard sso status
   SSO is "enabled" with "SAML2" protocol.
   ```

2. ​						要禁用 SSO，请运行以下命令： 				

   **语法**

   ​							

   

   ```none
   cephadm shell CEPH_MGR_HOST ceph dashboard sso disable
   SSO is "disabled".
   ```

   **示例**

   ​							

   

   ```none
   [root@host01 ~]#  cephadm shell host01 ceph dashboard sso disable
   ```

**其它资源**

- ​						要启用单点登录，请参阅 [*Red \*Hat Ceph Storage 仪表板指南中的为 Ceph\* 仪表板启用单点登录*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#enabling-single-sign-on-for-the-ceph-dashboard_dash)。 				

# 第 3 章 管理 Ceph 仪表板上的角色

​			作为存储管理员，您可以在仪表板上创建、编辑、克隆和删除角色。 	

​			默认情况下，有 8 个系统角色。您可以创建自定义角色，并授予这些角色的权限。这些角色可以根据要求分配给用户。 	

​			本节涵盖了以下管理任务： 	

- ​					[*Ceph 仪表板上的用户角色和权限*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#user-roles-and-permissions-on-the-ceph-dashboard_dash) 			
- ​					[*在 Ceph 控制面板创建角色*.](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#creating-roles-on-the-ceph-dashboard_dash) 			
- ​					[*编辑 Ceph 仪表板上的角色*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#editing-roles-on-the-ceph-dashboard_dash) 			
- ​					[*在 Ceph 仪表板上克隆角色*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#cloning-roles-on-the-ceph-dashboard_dash) 			
- ​					[*删除 Ceph 仪表板的角色*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#deleting-roles-on-the-ceph-dashboard_dash) 			

## 3.1. Ceph 仪表板上的用户角色和权限

​				用户帐户与一组角色关联，它们定义可以访问的特定仪表板功能。 		

​				Red Hat Ceph Storage 仪表板功能或模块在安全范围内分组。安全范围是预定义的和静态。Red Hat Ceph Storage 仪表板中当前可用的**安全范围**是： 		

- ​						**CephFS** ：包括与 CephFS 管理相关的所有功能。 				
- ​						**config-opt** ：包含与 Ceph 配置选项管理相关的所有功能。 				
- ​						**dashboard-settings** ：允许编辑仪表板设置。 				
- ​						**Grafana** ：包括与 Grafana 代理相关的所有功能。 				
- ​						**Host** ：包括与 Hosts 菜单条目相关的所有功能。 				
- ​						**log** ：包含与 Ceph 日志管理相关的所有功能。 				
- ​						**manager**: 包含与 Ceph 管理器管理相关的所有功能。 				
- ​						**monitor** ：包含与 Ceph 监视器管理相关的所有功能。 				
- ​						**NFS-ganesha** ：包含与 NFS-Ganesha 管理相关的所有功能。 				
- ​						**OSD** ：包含与 OSD 管理相关的所有功能。 				
- ​						**池** ：包含与池管理相关的所有功能。 				
- ​						**Prometheus** ：包括与 Prometheus 警报管理相关的所有功能。 				
- ​						**rbd-image**: 包含与 RBD 镜像管理相关的所有功能。 				
- ​						**rbd-mirroring** ：包含与 RBD 镜像管理相关的所有功能。 				
- ​						**rgw** ：包含与 Ceph 对象网关(RGW)管理相关的所有功能。 				

​				角色指定了一个安全范围和一组权限之间的一组映射。有四种**权限** ： 		

- ​						**读** 				
- ​						**创建** 				
- ​						**Update（更新）** 				
- ​						**删除** 				

![安全范围和权限](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3fcedeaf5ec6d4007b2a89352651e496/dash-security-scope-permission.png)

​				**system roles** 列表包括 		

- ​						**administrator** ：允许所有安全范围的完整权限。 				
- ​						**block-manager** ：允许 RBD-image 和 RBD-mirroring 范围的完整权限。 				
- ​						**cephfs-manager** ：允许 Ceph 文件系统范围的完整权限。 				
- ​						**cluster-manager** ：允许主机、OSD、监控、管理器和 config-opt 范围的完整权限。 				
- ​						**ganesha-manager** ：允许 NFS-Ganesha 范围的完整权限。 				
- ​						**pool-manager** ：允许池范围的完整权限。 				
- ​						**read-only** ：允许所有安全范围的读取权限，但仪表板设置和 config-opt 范围除外。 				
- ​						**rgw-manager** ：允许 Ceph 对象网关范围的完整权限。 				

[![系统角色](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/5d35b9e9d8b5abbff677486bf33af2f9/dash-system-roles.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/5d35b9e9d8b5abbff677486bf33af2f9/dash-system-roles.png)

​				例如，您需要提供 `rgw-manager` 对所有 Ceph 对象网关操作的用户的访问权限。 		

**其它资源**

- ​						有关在 Ceph 控制面板中创建用户，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建用户\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-users-on-the-ceph-dashboard_dash) 部分*。 				
- ​						有关在 Ceph 控制面板中创建角色，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建角色\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-roles-on-the-ceph-dashboard_dash) 部分*。 				

## 3.2. 在 Ceph 仪表板上创建角色

​				您可以在仪表板上创建自定义角色，并且这些角色可以根据其角色分配给用户。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						点 *Dashboard Settings* 图标，然后点 *User Management*。 				

   ![用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2689f14927254476949f39cf05984062/dash_dashboard-settings-user-management.png)

3. ​						在 *Roles* 选项卡上，单击 *Create*。 				

4. ​						在 *Create Role* 窗口中，设置 *Name*,*Description*，然后选择此角色的权限，然后单击 *Create Role* 按钮。 				

   [![创建角色窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/51f1c109d76215dd1e6d0599ea328f9f/dash_user-management-create-role-window.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/51f1c109d76215dd1e6d0599ea328f9f/dash_user-management-create-role-window.png)

   ​						在本例中，使用 `ganesha-manager` 和 `rgw-manager` 角色的用户可以管理所有 NFS-Ganesha 网关和 Ceph 对象网关操作。 				

5. ​						您会收到一条通知角色已成功创建。 				

6. ​						点行的 *Expand/Collapse* 图标，以查看提供给角色的详细信息和权限。 				

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的 Ceph\*仪表板上的用户角色和权限](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-roles-and-permissions-on-the-ceph-dashboard_dash)*  部分。 				
- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-users-on-the-ceph-dashboard_dash)*  用户部分。 				

## 3.3. 编辑 Ceph 仪表板的角色

​				控制面板允许您在仪表板上编辑角色。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				
- ​						在仪表板上创建角色。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						点 *Dashboard Settings* 图标，然后点 *User Management*。 				

   ![用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2689f14927254476949f39cf05984062/dash_dashboard-settings-user-management.png)

3. ​						在 *Roles* 选项卡上，点击您要编辑的角色。 				

4. ​						在 *Edit Role* 窗口中，编辑参数，然后点 *Edit Role*。 				

   [![编辑角色窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/cd25f318210c29123725c10eaec6d2d2/dash_user-management-edit-role-window.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/cd25f318210c29123725c10eaec6d2d2/dash_user-management-edit-role-window.png)

5. ​						您会收到成功更新该角色的通知。 				

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建角色](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-roles-on-the-ceph-dashboard_dash)*  部分。 				

## 3.4. 在 Ceph 仪表板上克隆角色

​				当您想要为现有角色分配额外权限时，您可以克隆系统角色并在 Red Hat Ceph Storage 控制面板中进行编辑。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				
- ​						角色在仪表板上创建。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						点 *Dashboard Settings* 图标，然后点 *User Management*。 				

   ![用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2689f14927254476949f39cf05984062/dash_dashboard-settings-user-management.png)

3. ​						在 *Roles* 选项卡上，点击您要克隆的角色。 				

4. ​						从 *Edit* 下拉菜单中选择 *Clone*。 				

5. ​						在 *Clone Role* 对话框中，输入角色的详细信息，然后单击 *Clone Role*。 				

   ![删除角色窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3a0e3ad6a1ed32d0957d997be7c9b7c0/dash_user-management-clone-role-window.png)

6. ​						克隆角色后，您可以根据要求自定义权限。 				

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建角色](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-roles-on-the-ceph-dashboard_dash)*  部分。 				

## 3.5. 删除 Ceph 仪表板的角色

​				您可以删除您在 Red Hat Ceph Storage 仪表板中创建的自定义角色。 		

注意

​					您无法删除 Ceph 控制面板的系统角色。 			

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				
- ​						在仪表板上创建自定义角色。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						点 *Dashboard Settings* 图标，然后点 *User Management*。 				

   ![用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2689f14927254476949f39cf05984062/dash_dashboard-settings-user-management.png)

3. ​						在 *Roles* 选项卡上，点击您要删除的角色。 				

4. ​						从 *Edit* 下拉菜单中选择 *Delete*。 				

5. ​						在 *Delete Role* 对话框中，点 *Yes, I am sure*，然后点 *Delete Role*。 				

   ![删除角色窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/400294c9bed98f0d92b1c827cb65deb4/dash_user-management-delete-role-window.png)

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建角色](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-roles-on-the-ceph-dashboard_dash)*  部分。 				

# 第 4 章 在 Ceph 仪表板上管理用户

​			作为存储管理员，您可以在 Red Hat Ceph Storage 仪表板上使用特定角色创建、编辑和删除用户。基于角色的访问权限控制会根据其角色和要求向每个用户提供。 	

​			您还可以在仪表板上创建、编辑、导入、导出和删除 Ceph 客户端身份验证密钥。创建身份验证密钥后，您可以使用命令行界面(CLI)轮转密钥。密钥轮转符合当前的行业和安全合规性要求。 	

​			本节涵盖了以下管理任务： 	

- ​					[*在 Ceph 控制面板创建用户*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#creating-users-on-the-ceph-dashboard_dash) 			
- ​					[*在 Ceph 仪表板上编辑用户*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#editing-users-on-the-ceph-dashboard_dash) 			
- ​					[*删除 Ceph 仪表板上的用户*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#deleting-users-on-the-ceph-dashboard_dash) 			
- ​					[*用户功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#user-capabilities_dash) 			
- ​					[*访问功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#access-capabilities_dash) 			
- ​					[*创建用户功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#creating-user-capabilities_dash) 			
- ​					[*编辑用户功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#editing-user-capabilities_dash) 			
- ​					[*导入用户功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#importing-user-capabilities_dash) 			
- ​					[*导出用户功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#exporting-user-capabilities_dash) 			
- ​					[*删除用户功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#deleting-user-capabilities_dash) 			

## 4.1. 在 Ceph 仪表板中创建用户

​				您可以根据其角色在 Red Hat Ceph Storage 仪表板中创建用户，并有足够的角色和权限。例如，如果您希望用户管理 Ceph 对象网关操作，您可以为该用户提供 `rgw-manager` 角色。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				

注意

​					Red Hat Ceph Storage 仪表板不支持更改用户密码时的任何电子邮件验证。此行为是有意设计的，因为控制面板支持单点登录(SSO)，此功能可以委派给 SSO 提供程序。 			

**流程**

1. ​						登录到仪表板。 				

2. ​						点 *Dashboard Settings* 图标，然后点 *User Management*。 				

   ![用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2689f14927254476949f39cf05984062/dash_dashboard-settings-user-management.png)

3. ​						在 *Users* 选项卡中，点 *Create*。 				

4. ​						在 *Create User* 窗口中，设置 *Username* 和其他参数，包括角色，然后点 *Create User*。 				

   [![创建用户窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/04b5730bb613226f0a50f25277e3c654/dash_user-management-create-user-window.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/04b5730bb613226f0a50f25277e3c654/dash_user-management-create-user-window.png)

5. ​						您收到用户创建成功的通知。 				

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建角色](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-roles-on-the-ceph-dashboard_dash)*  部分。 				
- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的 Ceph\*仪表板上的用户角色和权限](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-roles-and-permissions-on-the-ceph-dashboard_dash)*  部分。 				

## 4.2. 在 Ceph 仪表板中编辑用户

​				您可以编辑 Red Hat Ceph Storage 仪表板中的用户。您可以根据要求修改用户的密码和角色。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				
- ​						在控制面板上创建的用户。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						点 *Dashboard Settings* 图标，然后点 *User Management*。 				

   ![用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2689f14927254476949f39cf05984062/dash_dashboard-settings-user-management.png)

3. ​						要编辑该用户，请点行。 				

4. ​						在 *Users* 选项卡中，从 *Edit* 下拉菜单中选择 *Edit*。 				

5. ​						在 *Edit User* 窗口中，编辑 password 和角色等参数，然后点 *Edit User*。 				

   [![编辑用户窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/b01614b9d585dc14dcc43ec5a2c53501/dash_user-management-edit-user-window.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/b01614b9d585dc14dcc43ec5a2c53501/dash_user-management-edit-user-window.png)

   注意

   ​							如果要禁用任何用户对 Ceph 仪表板的访问，可以在 *Edit User* 窗口中取消选择 *Enabled* 选项。 					

6. ​						您收到用户创建成功的通知。 				

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-users-on-the-ceph-dashboard_dash)*  用户部分。 				

## 4.3. 删除 Ceph 仪表板中的用户

​				您可以删除 Ceph 仪表板中的用户。有些用户可能会从系统中删除。可以从 Ceph 控制面板删除对此类用户的访问权限。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				
- ​						在控制面板上创建的用户。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						点 *Dashboard Settings* 图标，然后点 *User Management*。 				

   ![用户管理](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2689f14927254476949f39cf05984062/dash_dashboard-settings-user-management.png)

3. ​						在 *Users* 选项卡中，点击您要删除的用户。 				

4. ​						从 *Edit* 下拉菜单中选择 *Delete*。 				

5. ​						在 *Delete User* 对话框中，点 *Yes, I am sure* box，然后点 *Delete User* 保存该设置。 				

   ![删除用户窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/4d1ef89725f1f421c4907c696c59d92b/dash_user-management-delete-user-window.png)

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-users-on-the-ceph-dashboard_dash)*  用户部分。 				

## 4.4. 用户功能

​				Ceph 在池内存储数据 RADOS 对象，无论使用的 Ceph 客户端如何。Ceph  用户必须有权访问给定池才能读取和写入数据，并且必须具有可执行权限才能使用 Ceph 管理的命令。通过创建用户，您可以控制其对 Red Hat  Ceph Storage 集群、其池以及池中数据的访问。 		

​				Ceph 具有 `用户类型` 的概念，其始终为 `客户端`。您需要使用 `*TYPE*.*ID*` 定义用户，其中 ID 是用户 ID，如 `client.admin`。此用户输入是因为 Cephx 协议不仅供客户端使用，也使用非客户端，如 Ceph 监控器、OSD 和元数据服务器。区分用户类型有助于区分客户端用户和其他用户。这种区别简化了访问控制、用户监控和可追溯性。 		

### 4.4.1. 功能

​					Ceph 使用功能（大写）来描述授予经过身份验证的用户的权限，以操作 monitor、OSD 和元数据服务器的功能。该功能会根据应用程序标签限制对池中数据、池中的一个命名空间或一组池的访问。Ceph 管理用户指定在创建或更新用户时用户的功能。 			

​					您可以将功能设置为监控、管理器、OSD 和元数据服务器。 			

- ​							Ceph 监控功能包括 `r`、`w` 和 `x` 访问设置。它们可用于聚合使用配置集 ` *NAME*的预定义配置集`。 					
- ​							OSD 功能包括 `r`、`w`、`x`、`class-read` 和 `class-write` 访问设置。它们可用于聚合使用配置集 ` *NAME*的预定义配置集`。 					
- ​							Ceph 管理器功能包括 `r`、`w` 和 `x` 访问设置。它们可用于聚合使用配置集 ` *NAME*的预定义配置集`。 					
- ​							对于管理员，元数据服务器(MDS)功能包括 `allow *`。 					

注意

​						Ceph 对象网关守护进程(`radosgw`)是 Red Hat Ceph Storage 集群的客户端，不表示 Ceph 存储集群守护进程类型。 				

**其它资源**

- ​							如需了解更多详细信息，[*请参阅访问功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#access-capabilities_dash)。 					

## 4.5. 访问功能

​				本节介绍可提供给 Ceph 用户或 Ceph 客户端的不同访问或实体功能，如块设备、对象存储、文件系统和原生 API。 		

​				另外，您可以在将角色分配给客户端时描述功能配置集。 		

- `allow`, 描述

  ​							守护进程的以前访问设置。表示只适用于 MDS 的 `rw` 					

- `r`, 描述

  ​							授予用户 *读取访问权限*。需要 monitor 来检索 CRUSH map。 					

- `w`, 描述

  ​							授予用户对对象 *的写入访问权限*。 					

- `x`, 描述

  ​							授予用户调用类方法（即 *读取和写入* ）的能力，并在 monitor 上执行 `auth` 操作。 					

- `class-read`, 描述

  ​							授予用户调用类读取方法的能力。`x` 的子集. 					

- `class-write`, 描述

  ​							授予用户调用类写入方法的能力。`x` 的子集. 					

- *，`所有`, 描述

  ​							授予用户对特定守护进程或  **池的读取** 、*写入和执行权限*，以及执行 admin 命令的能力。 					

​				以下条目描述了有效的功能配置集： 		

- `配置集 osd`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户权限以 OSD 连接到其他 OSD 或 monitor。在 OSD 上延迟，使 OSD 能够处理复制心跳流量和状态报告。 					

- `配置集 mds`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户权限以 MDS 连接到其他 MDS 或 monitor。 					

- `配置集 bootstrap-osd`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户引导 OSD 的权限。限制部署工具，如 `ceph-volume` 和 `cephadm`，以便在引导 OSD 时具有添加密钥的权限。 					

- `配置集 bootstrap-mds`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户引导元数据服务器的权限。对部署工具（如 `cephadm` ）进行故障排除，以便在引导元数据服务器时具有添加密钥的权限。 					

- `配置集 bootstrap-rbd`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户引导 RBD 用户的权限。对部署工具（如 `cephadm` ）进行故障排除，以便在引导 RBD 用户时具有添加密钥的权限。 					

- `配置集 bootstrap-rbd-mirror`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户 bootstrap `rbd-mirror` 守护进程用户的权限。对部署工具（如 `cephadm` ）进行故障排除，以便在引导 `rbd-mirror` 守护进程时具有添加密钥的权限。 					

- `profile rbd`, 描述

  ​							这适用于 Ceph Monitor、Ceph Manager 和 Ceph OSD。授予用户操作 RBD 镜像的权限。当用作  monitor 大写时，它提供了 RBD 客户端应用所需的最小特权；此类特权包括阻止其他客户端用户的功能。当用作 OSD 上限时，它提供了一个  RBD 客户端应用，具有对指定池的读写访问权限。Manager 大写支持可选的 `pool` 和 `namespace` 关键字参数。 					

- `profile rbd-mirror`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户操作 RBD 镜像并检索 RBD 镜像 config-key secret 的权限。它提供了操作 `rbd-mirror` 守护进程的用户所需的最小特权。 					

- `profile rbd-read-only`, 描述

  ​							这适用于 Ceph 监控器和 Ceph OSD。授予用户对 RBD 镜像的只读权限。Manager 大写支持可选的 `pool` 和 `namespace` 关键字参数。 					

- `profile simple-rados-client`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户 monitor、OSD 和 PG 数据的只读权限。供直接 librados 客户端应用使用。 					

- `profile simple-rados-client-with-blocklist`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户 monitor、OSD 和 PG 数据的只读权限。供直接 librados 客户端应用使用。还包括添加 blocklist 条目以构建高可用性(HA)应用程序的权限。 					

- `配置集 fs-client`, 描述

  ​							这仅适用于 Ceph Monitor。授予用户 monitor、OSD、PG 和 MDS 数据的只读权限。适用于 CephFS 客户端。 					

- `profile role-definer`, 描述

  ​							这适用于 Ceph Monitor 和 Auth。授予用户 auth 子系统的所有权限，对 monitor 具有只读访问权限，而不授予其他任何权限。用于自动化工具。警告：除非真正知道您要做的事情，否则不要分配这一点，因为安全影响会非常大且普遍。 					

- `配置集崩溃`, 描述

  ​							这适用于 Ceph 监控器和 Ceph 管理器。授予用户对 monitor 的只读访问权限。与管理器 crash 模块一起使用，将守护进程 `崩溃转储` 上传到监控存储中，以便稍后进行分析。 					

**其它资源**

- ​						如需了解更多详细信息，请参阅 [用户 capabilities_](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-capabilities_dash)。 				

## 4.6. 创建用户功能

​				在 Ceph 控制面板中，创建具有不同功能的基于角色的访问权限用户。 		

​				有关不同用户功能的详情，请查看 [*用户功能和*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-capabilities_dash) [*访问功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#access-capabilities_dash) 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 Cluster 下拉菜单中，选择 *Users*。 				

3. ​						单击 *+ Create*。 				

4. ​						在 *Create User* 窗口中，提供以下详情： 				

   1. ​								用户实体 - 将其指定为 `*TYPE*。*ID*`。 						

   2. ​								Entity - 这可以是 `mon`、`mgr`、`osd`、或 `mds`。 						

   3. ​								实体功能 - 提供您可以提供给用户的不同功能的详细信息。例如，"allow `*"和配置集崩溃` 是可分配给客户端的一些功能。 						

      注意

      ​									您可以根据要求向用户添加更多实体。 							

      [![创建用户功能](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/335f19ebb8a9409dec116f558d4c4cb0/dash_create-user-capabilities.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/335f19ebb8a9409dec116f558d4c4cb0/dash_create-user-capabilities.png)

5. ​						点*创建用户*。 				

6. ​						您会收到成功创建用户的通知。 				

## 4.7. 编辑用户功能

​				在仪表板上编辑用户或客户端的角色。 		

​				有关不同用户功能的详情，请查看 [*用户功能和*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-capabilities_dash) [*访问功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#access-capabilities_dash) 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 Cluster 下拉菜单中，选择 *Users*。 				

3. ​						选择您要编辑的角色的用户。 				

4. ​						点 *Edit*。 				

5. ​						在 *Edit User* 窗口中，编辑 ` 实体 和实体功能`。 				

   注意

   ​							您可以根据要求向用户添加更多实体。 					

   [![编辑用户功能](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/d52cd3088f531a3c25ffaa3d3f38799e/dash_edit-user-capabilities.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/d52cd3088f531a3c25ffaa3d3f38799e/dash_edit-user-capabilities.png)

6. ​						点 *Edit User*。 				

7. ​						您会收到成功编辑用户的通知。 				

## 4.8. 导入用户功能

​				在仪表板上，将用户或客户端的角色从本地主机导入到客户端。 		

​				有关不同用户功能的详情，请查看 [*用户功能和*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-capabilities_dash) [*访问功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#access-capabilities_dash) 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				

**流程**

1. ​						在本地主机上创建密钥环文件： 				

   **示例**

   ​							

   

   ```none
   [localhost:~]$ cat import.keyring
   
   [client.test11]
   	key = AQD9S29kmjgJFxAAkvhFar6Af3AWKDY2DsULRg==
   	caps mds = "allow *"
   	caps mgr = "allow *"
   	caps mon = "allow *"
   	caps osd = "allow r"
   ```

2. ​						登录到仪表板。 				

3. ​						在 Cluster 下拉菜单中，选择 *Users*。 				

4. ​						选择您要导入其角色的用户。 				

5. ​						在 *Edit* 下拉菜单中选择 *Import*。 				

6. ​						在 *Import User* 窗口中，单击 *Choose file*，选择相应的文件。 				

7. ​						点 *Import User* 				

   [![导入用户功能](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/368fcea0b405d1c2d181528062f31c54/dash_import-user-capabilities.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/368fcea0b405d1c2d181528062f31c54/dash_import-user-capabilities.png)

8. ​						您会收到成功导入密钥的通知。 				

## 4.9. 导出用户功能

​				将用户或客户端的角色从控制面板导出到本地主机。 		

​				有关不同用户功能的详情，请查看 [*用户功能和*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#user-capabilities_dash) [*访问功能*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#access-capabilities_dash) 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 Cluster 下拉菜单中，选择 *Users*。 				

3. ​						选择您要导出的角色的用户。 				

4. ​						在 *Edit* 下拉菜单中选择 *Export*。 				

5. ​						在 *Ceph 用户导出数据* 对话框中，单击 *Copy to Clipboard* 图标。 				

   ![导出用户功能](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/c31677c380d38a6a76b309d56eefbc5e/dash_export-user-capabilities.png)

6. ​						您会收到成功复制密钥的通知。 				

7. ​						在本地系统中创建密钥环文件并粘贴密钥： 				

   **示例**

   ​							

   

   ```none
   [localhost:~]$ cat exported.keyring
   
   [client.test11]
   	key = AQD9S29kmjgJFxAAkvhFar6Af3AWKDY2DsULRg==
   	caps mds = "allow *"
   	caps mgr = "allow *"
   	caps mon = "allow *"
   	caps osd = "allow r"
   ```

## 4.10. 删除用户功能

​				删除仪表板上的用户或客户端的角色。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						控制面板的管理员级别访问权限。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 Cluster 下拉菜单中，选择 *Users*。 				

3. ​						选择您要删除的用户。 				

4. ​						在 *Edit* 下拉菜单中选择 *Delete*。 				

5. ​						在 *Delete entity* 窗口中，选择 *Yes, I am sure*。 				

   ![删除用户功能](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/4da25a75563a7a644674f2881a96292c/dash_delete-user-capabilities.png)

6. ​						单击 *Delete entity*。 				

7. ​						您会收到成功删除用户的通知。 				

# 第 5 章 管理 Ceph 守护进程

​			作为存储管理员，您可以在 Red Hat Ceph Storage 仪表板上管理 Ceph 守护进程。 	

## 5.1. 守护进程操作

​				Red Hat Ceph Storage 仪表板允许您启动、停止、重启和重新部署守护进程。 		

注意

​					除了监控和管理器守护进程外，所有守护进程都支持这些操作。 			

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						在存储集群中至少配置一个守护进程。 				

**流程**

​					您可以通过两种方式管理守护进程。 			

​				**在 Services 页面中：** 		

1. ​						登录控制面板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Services*。 				

3. ​						通过守护进程查看服务详情，以便在其行中点 *Expand/Collapse* 图标来对其执行操作。 				

4. ​						在 *Details* 中，选择所需守护进程旁边的下拉菜单，以执行 *Start*, *Stop*, *Restart*, 或 *Redeploy*。 				

   图 5.1. 管理守护进程

   [![管理守护进程](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a7aa7bcc80e70c89130b005145766e37/dash_services-daemon-actions.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a7aa7bcc80e70c89130b005145766e37/dash_services-daemon-actions.png)

​				**在 Hosts 页面中：** 		

1. ​						登录控制面板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Hosts*。 				

3. ​						从 *Hosts List* 中选择守护进程要在其中执行操作的主机。 				

4. ​						在主机的 *Daemon* 选项卡中，点守护进程。 				

5. ​						使用顶部的下拉菜单来执行 *Start*、*Stop*、*Restart* 或 *Redeploy*。 				

   图 5.2. 管理守护进程

   [![管理守护进程](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a9af0ad6c40e4b179ac700c4b99f4f16/dash_hosts-daemon-actions.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a9af0ad6c40e4b179ac700c4b99f4f16/dash_hosts-daemon-actions.png)

# 第 6 章 监控 Ceph 仪表板上的集群

​			作为存储管理员，您可以使用 Red Hat Ceph Storage Dashboard 根据主机、服务、数据访问方法等来监控集群的特定方面。 	

​			本节涵盖了以下管理任务： 	

- ​					[*在仪表板上监控 Ceph 集群的主机*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-hosts-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*在仪表板上查看和编辑 Ceph 集群的配置*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#viewing-and-editing-the-configuration-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*在仪表板上查看和编辑 Ceph 集群的管理器模块*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#viewing-and-editing-the-manager-modules-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*在控制面板中监控 Ceph 集群的监控器*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-monitors-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*在仪表板中监控 Ceph 集群的服务*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-services-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*监控仪表板上的 Ceph OSD*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-ceph-osds-on-the-dashboard_dash) 			
- ​					[*监控仪表板上的 HAProxy*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-haproxy-on-the-dashboard_dash) 			
- ​					[*在控制面板中，查看 Ceph 集群的 CRUSH map*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#viewing-the-crush-map-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*在仪表板上过滤 Ceph 集群的日志*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#filtering-logs-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*在控制面板中查看 Ceph 集群的集中式日志*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#viewing-centralized-logs-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*在控制面板中监控 Ceph 集群的池。*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-pools-of-the-ceph-cluster-on-the-dashboard_dash) 			
- ​					[*在仪表板中监控 Ceph 文件系统。*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-ceph-file-systems-on-the-dashboard_dash) 			
- ​					[*在控制面板中监控 Ceph 对象网关守护进程。*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-ceph-object-gateway-daemons-on-the-dashboard_dash) 			
- ​					[*监控 Ceph 控制面板中的块设备镜像。*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#monitoring-block-device-images-on-the-ceph-dashboard_dash) 			

## 6.1. 在控制面板中监控 Ceph 集群的主机

​				您可以在 Red Hat Ceph Storage Dashboard 中监控集群的主机。 		

​				以下是主机页面中的不同标签页： 		

- ​						**Devices** - 此选项卡的详情，如设备 ID、健康、设备名称和主机上的守护进程。 				
- ​						**Inventory** - 此选项卡显示连接到所选主机的所有磁盘，以及类型、大小及其他类型。它的详细信息，如设备路径、设备类型、可用、供应商、型号、大小和部署 OSD。 				
- ​						**Daemons** - 此选项卡显示所有已在所选主机上部署的服务，它们是运行的容器，以及它们的当前状态。它具有主机名、守护进程类型、守护进程 ID、容器 ID、容器镜像名称、容器镜像 ID、版本状态和最近刷新的时间等详细信息。 				
- ​						**性能详细信息** - 此选项卡具有部署 OSD 的详细信息，如 OSD 部署、CPU 使用量、网络负载、网络降低率和 OSD 磁盘性能统计信息。 				
- ​						**设备健康状况** - 对于启用了 SMART 的设备，您只能在部署的 OSD 上获取单独的健康状态和 SMART 数据。 				

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						主机添加到存储集群中。 				
- ​						存储集群中部署了所有服务、监控、管理器和 OSD 守护进程。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Hosts*。 				

3. ​						要查看特定主机的详细信息，请单击所在行上的 *Expand/Collapse* 图标。 				

4. ​						您可以通过点对应的标签页来查看 *设备*、*清单*、*守护进程*、*性能详情*和*设备健康状况*等详情。 				

   图 6.1. 监控 Ceph 集群的主机

   ![监控 Ceph 集群的主机](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/8c25859b8fd28c78489d598b0f4ba72e/dash_monitoring-hosts-of-the-ceph-cluster.png)

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat Ceph Storage Administration Guide* 中的 Ceph [*性能计数器*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/administration_guide/#ceph-performance-counters)。 				

## 6.2. 在控制面板中查看和编辑 Ceph 集群的配置

​				您可以在仪表板上查看 Ceph 集群的各种配置选项。您只能编辑一些配置选项。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						所有服务都部署在存储集群中。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中，选择 *Configuration*。 				

3. ​						可选： 您可以使用*搜索*框搜索配置： 				

4. ​						可选： 您可以使用以下过滤器过滤特定配置： 				

   - ​								*Level* - Basic、advanced 或 dev 						
   - ​								*Service* - any、mon、mgr、osd、mds、common、mds_client、rgw 和类似的过滤器。 						
   - ​								*Source* - Any、mon 和类似过滤器 						
   - ​								*Modified* - yes 或 no 						

5. ​						要查看配置的详细信息，请单击所在行上的 *Expand/Collapse* 图标。 				

   图 6.2. 配置选项

   ![配置选项](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/1d9d4d5592f6107051d483de008e39aa/dash_configuration-options.png)

6. ​						要编辑配置，点行并点 *Edit*。 				

   1. ​								在编辑对话框中，编辑所需参数并点 *Update*。 						

7. ​						您会收到成功更新配置的通知。 				

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat Ceph Storage 配置指南中的* Ceph 网络配置章节。 https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/configuration_guide/#ceph-network-configuration 				

## 6.3. 在控制面板中查看和编辑 Ceph 集群的管理器模块

​				管理器模块用于管理模块特定的配置设置。例如，您可以为集群健康启用警报。 		

​				您可以在 Red Hat Ceph Storage 仪表板中查看、启用或禁用集群管理器模块。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				

**查看管理器模块**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中，选择 *Manager Modules*。 				

3. ​						要查看特定管理器模块的详细信息，请单击所在行上的 *Expand/Collapse* 图标。 				

   图 6.3. Manager 模块

   ![Manager 模块](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/71925bd59a7e85121ac30a3c440fffbd/dash_manager-modules.png)

**启用管理器模块**

1. ​						选择行。 				
2. ​						在 *Edit* 下拉菜单中选择 *Enable*。 				

**禁用 manager 模块**

1. ​						选择行。 				
2. ​						在 *Edit* 下拉菜单中选择 *Disable*。 				

**编辑管理器模块**

1. ​						选择行： 				

   注意

   ​							不是所有模块都有可配置参数。如果模块不可配置，则 *Edit* 按钮会被禁用。 					

2. ​						编辑所需的参数并点 *Update*。 				

3. ​						您会收到成功更新该模块的通知。 				

## 6.4. 在控制面板中监控 Ceph 集群的监控

​				您可以在 Red Hat Ceph Storage 仪表板的登录页面上监控 Ceph 监视器的性能。您也可以在 *Monitor* 标签页中查看监视器的详细信息，如状态、仲裁数、打开会话数和性能计数器。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						监控器部署在存储集群中。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Monitors*。 				

3. ​						*Monitor* 概览页面显示有关总体监控状态的信息，以及 *in Quorum* 和 *Not in quorum* Monitor 主机的表。 				

   [![监控 Ceph 集群的监控器](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/11a547e82b6bcc65fb3bf6ae163d890b/dash_monitoring-monitors-of-the-ceph-cluster.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/11a547e82b6bcc65fb3bf6ae163d890b/dash_monitoring-monitors-of-the-ceph-cluster.png)

4. ​						要查看打开的会话数量，请将光标悬停在蓝色点的末尾。 				

5. ​						要查看任何 monitor 的性能计数器，请点其主机名。 				

   - ​								查看监控器的性能计数器： 						

     [![监控性能计数器](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/ca0de461b599d38450b03789d1eedc8c/dash_monitor-performance-counters.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/ca0de461b599d38450b03789d1eedc8c/dash_monitor-performance-counters.png)

**其它资源**

- ​						请参阅 *Red Hat [\*Ceph Storage Operations 指南中的 Ceph\*监视器](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/operations_guide/#ceph-monitors_ops)*  部分。 				
- ​						如需了解更多详细信息，请参阅 *Red Hat Ceph Storage Administration Guide* 中的 Ceph [*性能计数器*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/administration_guide/#ceph-performance-counters)。 				

## 6.5. 在控制面板中监控 Ceph 集群的服务

​				您可以在 Red Hat Ceph Storage Dashboard 中监控集群的服务。您可以查看主机名、守护进程类型、守护进程 ID、容器 ID、容器镜像名称、容器镜像 ID、版本状态以及最后一次刷新的时间等详情。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						主机添加到存储集群中。 				
- ​						所有服务都部署在存储集群中。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Services*。 				

3. ​						要查看特定服务的详细信息，请单击所在行上的 *Expand/Collapse* 图标。 				

   图 6.4. 监控 Ceph 集群的服务

   ![监控 Ceph 集群的服务](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/04b6fb2f69acb4100af63515f624a8b7/dash_monitoring-services-of-the-ceph-cluster.png)

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat Ceph Storage Operations 指南中的* [*Ceph Orchestrators*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/operations_guide/#ceph-orchestrators)。 				

## 6.6. 监控仪表板上的 Ceph OSD

​				您可以在 Red Hat Ceph Storage Dashboard 的登录页面中监控 Ceph OSD 的状态。您还可以在 *OSD* 选项卡中查看主机、状态、设备类、放置组(PG)、大小标志、使用量以及读写操作时间等详情。 		

​				以下是 OSD 页面中的不同标签页： 		

- ​						**Devices** - 此选项卡的详情，如设备 ID、健康状态、生命周期期望、设备名称和主机上的守护进程。 				
- ​						**Attributes (OSD map)** - 此选项卡显示集群地址、心跳、OSD 状态和其他 OSD 属性的详细信息。 				
- ​						**Metadata** - 此选项卡显示 OSD 对象存储、设备、操作系统和内核详细信息的详细信息。 				
- ​						**设备健康状况** - 对于启用了 SMART 的设备，您可以获取单个健康状态和 SMART 数据。 				
- ​						**性能计数器** - 此选项卡提供了在设备上写入的字节数的详细信息。 				
- ​						**性能详细信息** - 此选项卡具有部署 OSD 的详细信息，如 OSD 部署、CPU 使用量、网络负载、网络降低率和 OSD 磁盘性能统计信息。 				

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						主机添加到存储集群中。 				
- ​						所有服务（包括 OSD）都部署在存储集群中。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						从 *Cluster* 下拉菜单中，选择 *OSD*。 				

3. ​						若要查看特定 OSD 的详细信息，可点其行上的 *Expand/Collapse* 图标。 				

   图 6.5. 监控 Ceph 集群的 OSD

   ![监控 Ceph 集群的 OSD](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/fdcf0fff0b0cb235dfa33a71fe3e21b6/dash_monitoring-osds-of-the-ceph-cluster.png)

   ​						您可以通过单击相应标签页来查看其他详细信息，如 *Devices*, *Attributes (OSD map)*, *Metadata*, *Device Health*, *Performance counter*, 和 *Performance Details*。 				

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat Ceph Storage Operations 指南中的* [*Ceph Orchestrators*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/operations_guide/#ceph-orchestrators)。 				

## 6.7. 监控仪表板上的 HAProxy

​				Ceph 对象网关允许您为单个区域分配多个对象网关实例，以便随着负载增加而横向扩展。由于每个对象网关实例都有自己的 IP 地址，因此您可以使用 HAProxy 在 Ceph 对象网关服务器之间平衡负载。 		

​				您可以在仪表板上监控以下 HAProxy 指标： 		

- ​						HTTP 代码的总响应。 				
- ​						请求/响应总数. 				
- ​						连接总数。 				
- ​						传入/传出字节的当前总数。 				

​				您还可以通过运行 `ceph dashboard get-grafana-api-url` 命令获取 Grafana 详情。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						存储仪表板上的管理级别访问权限。 				
- ​						现有 Ceph 对象网关服务，没有 SSL。如果您希望 SSL 服务，则应在 ingress 服务上配置证书，而不是 Ceph 对象网关服务。 				
- ​						使用 Ceph 编排器部署的 Ingress 服务。 				
- ​						监控堆栈组件在控制面板上创建。 				

**流程**

1. ​						登录到 Grafana URL 并选择 *RGW_Overview* 面板： 				

   **语法**

   ​							

   

   ```none
   https://DASHBOARD_URL:3000
   ```

   **示例**

   ​							

   

   ```none
   https://dashboard_url:3000
   ```

2. ​						验证 Grafana URL 上的 HAProxy 指标。 				

3. ​						启动 Ceph 仪表板，并使用您的凭据登录。 				

   **示例**

   ​							

   

   ```none
   https://dashboard_url:8443
   ```

4. ​						在 *Cluster* 下拉菜单中，选择 *Object Gateway*。 				

5. ​						选择 *Daemons*。 				

6. ​						选择 *Overall Performance* 选项卡。 				

**验证**

- ​						验证 Ceph 对象网关 HAProxy 指标： 				

  图 6.6. HAProxy 指标

  [![HAProxy 指标](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a3654307875c782a6003182e43291aa2/dash_haproxy_metrics.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a3654307875c782a6003182e43291aa2/dash_haproxy_metrics.png)

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 对象网关指南中的为 Ceph 对象网关\*配置高可用性](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/#configuring-high-availability-for-the-ceph-object-gateway_rgw)* 。 				

## 6.8. 在控制面板中查看 Ceph 集群的 CRUSH map

​				您可以查看包含 OSD 列表以及 Red Hat Ceph Storage 仪表板上相关信息的 CRUSH map。CRUSH map 和 CRUSH 算法一起确定数据的保存方式和位置。控制面板允许您查看 CRUSH map 的不同方面，包括 OSD 主机、OSD 守护进程、ID  号、设备类等。 		

​				借助 CRUSH map，您可以确定哪些主机上运行一个特定的 OSD ID。如果 OSD 出现问题，这非常有用。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						存储集群中部署的 OSD 守护进程。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						从 *Cluster* 下拉菜单中，选择 *CRUSH Map*。 				

3. ​						若要查看特定 OSD 的详细信息，请点它所在的行。 				

   图 6.7. CRUSH 映射详细视图

   [![CRUSH 映射详细视图](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/bd7da095e135e1076aec0f985f19ccae/dash-crush-map-detail-view.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/bd7da095e135e1076aec0f985f19ccae/dash-crush-map-detail-view.png)

**其它资源**

- ​						有关 CRUSH map 的更多信息，请参阅 *Red Hat Ceph Storage* 策略指南中的 [*CRUSH 管理概述*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/storage_strategies_guide/#crush-admin-overview_strategy)。 				

## 6.9. 在控制面板中过滤 Ceph 集群的日志

​				您可以根据以下标准，查看和过滤 Red Hat Ceph Storage 集群的日志。条件包括 *Priority*, *Keyword*, *Date*, 和 *Time range*. 		

​				您可以将日志下载到系统中，或者将日志复制到剪贴板，以进行进一步分析。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						由于 Ceph Monitor 是最近一次启动，因此已生成了日志条目。 				

注意

​					控制面板日志记录功能仅显示三十最新高级别事件。事件通过 Ceph 监控存储在内存中。重启 monitor 后的条目会消失。如果您需要查看详细或旧的日志，请参阅基于文件的日志。 			

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Logs*。 				

   图 6.8. 集群日志

   [![集群日志](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/31671dd57c68dd818a52b68ed720ee57/dash_cluster-logs.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/31671dd57c68dd818a52b68ed720ee57/dash_cluster-logs.png)

   1. ​								要根据优先级过滤，点`优先级`下拉菜单并选择 *Debug*、*Info*、*Warning*、*Error* 或 *All*。 						
   2. ​								要按关键字过滤，请在 `关键字` 字段中输入文本。 						
   3. ​								要根据日期进行过滤，请点击 `Date` 字段，从菜单中选择日期，或者以 *YYYY-MM-DD* 的形式输入日期。 						
   4. ​								要按时间过滤，请使用 *HH:MM - HH:MM* 格式在 `时间范围`字段中输入范围。小时需要是数字 `0` 到 `23`。 						
   5. ​								要组合过滤器，请设置两个或多个过滤器。 						

3. ​						点 *Download* 图标或 *Copy to Clipboard* 图标下载日志。 				

**其它资源**

- ​						如需更多信息，请参阅 *Red Hat Ceph StorageTroubleshooting Guide* 中的 配置日志章节。 https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/troubleshooting_guide/#configuring-logging 				
- ​						如需更多信息，请参阅 *Red Hat Ceph Storage 故障排除指南中的* [*了解 Ceph 日志*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/troubleshooting_guide/#understanding-ceph-logs_diag) 部分。 				

## 6.10. 在控制面板中查看 Ceph 集群的集中日志

​				Ceph 控制面板允许您查看 Red Hat Ceph Storage 集群中集中空间中的所有客户端的日志，以便有效地监控。这通过使用  Loki （用于存储和查询日志）的日志聚合系统实现，它是一个将本地日志内容发送到私有 Grafana Loki 实例的代理。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						Grafana 被配置并登录到集群中。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Services*。 				

3. ​						在 *Services* 窗口中，从下拉菜单中选择 *+ Create*。 				

4. ​						在 *Create Service* 窗口中，从 *Type* 字段中选择 `loki`，填写剩余的详情，然后点 *Create Service*。 				

5. ​						重复上一步，通过在 *Type* 字段中选择 `promtail` 来创建 `Promtail` 服务。创建成功后，您可以看到在服务列表中运行的 `loki` 和 `promtail` 服务。 				

   图 6.9. 创建 Loki 和 Promtail 服务

   ![创建 Loki 和 Promtail 服务](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3f80d218b65319508d2a0486e0204039/dash_loki-promtail.png)

   注意

   ​							默认情况下，Promtail 服务部署到所有正在运行的主机上。 					

6. ​						要启用记录到文件，从 *Cluster* 下拉菜单中选择 *Configuration*。 				

7. ​						在搜索栏中搜索 `log_to_file`，然后单击 *Edit*。 				

8. ​						在 *Edit log_to_file* 窗口中，将 *global* 设置为 `true`。 				

   图 6.10. 配置日志文件

   [![配置日志文件](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/810ff3a59b95f2cf2761ec55aeb9bd02/dash_loki-promtail-config.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/810ff3a59b95f2cf2761ec55aeb9bd02/dash_loki-promtail-config.png)

9. ​						重复步骤 6 到 8，通过在搜索栏中搜索 ` mon_cluster_log_to_file 文件`，将 *global* 配置为 `true`。 				

   注意

   ​							需要同时配置 `log_to_file` 和 `mon_cluster_log_to_file` 文件。 					

10. ​						导航到 *Cluster* 下的 *Logs*，再单击 *Daemon Logs* 选项卡来查看集中式日志。使用 *Log 浏览器* 选择文件并点击 *Show logs*，以查看该文件的日志。 				

    图 6.11. 查看集中式日志

    [![查看集中式日志](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/76844ac64d7621043b8a10a75b19ee7b/dash_centra-logs.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/76844ac64d7621043b8a10a75b19ee7b/dash_centra-logs.png)

    注意

    ​							如果没有看到日志，则需要登录到 Grafana 并重新载入页面。 					

## 6.11. 在控制面板中监控 Ceph 集群的池

​				您可以在 Red Hat Ceph Storage Dashboard 中查看集群中池的详情、性能详情、配置和整体性能。 		

​				池在 Ceph 存储集群分发和存储数据的方式中发挥着重要作用。如果您在不创建池的情况下部署了集群，Ceph 将使用默认池来存储数据。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						创建池 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在导航栏中，选择*池*。 				

3. ​						查看池列表，它提供了数据保护详情以及池启用的应用程序。在所需详情的鼠标中悬停在 *Usage*, *Read bytes*, 和 *Write bytes* 上。 				

4. ​						要查看有关池的更多信息，请单击所在行上的 *Expand/Collapse* 图标。 				

   图 6.12. 监控池

   [![监控池](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/66bae16f2c8bc5f199fbcbd1d3dd50eb/dash_monitoring-pools.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/66bae16f2c8bc5f199fbcbd1d3dd50eb/dash_monitoring-pools.png)

**其它资源**

- ​						有关池的更多信息，请参阅 *Red Hat Ceph Storage 架构指南中的 Ceph* [*池*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/architecture_guide/#ceph-pools_arch)。 				
- ​						如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建池](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-pools-on-the-ceph-dashboard_dash)*  部分。 				

## 6.12. 监控仪表板中的 Ceph 文件系统

​				您可以使用 Red Hat Ceph Storage 控制面板监控 Ceph 文件系统(CephFS)和相关组件。*文件系统中有四个主要标签页* ： 		

- ​						*详情* - 查看存储服务器(MDS)及其数字，以及任何备用守护进程、池及其用法，以及性能计数器。 				
- ​						*Client* - 查看已挂载文件系统的客户端列表。 				
- ​						*Directories* - V查看目录列表。 				
- ​						*性能* - 查看文件系统的性能。 				

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						MDS 服务至少部署在其中一个主机上。 				
- ​						已安装 Ceph 文件系统。 				

**流程**

1. ​						登录控制面板。 				

2. ​						在导航栏中点 *Filesystems*。 				

3. ​						要查看有关文件系统的更多信息，请点行中的 *Expand/Collapse* 图标。 				

   图 6.13. 监控 Ceph 文件系统

   [![监控 Ceph 文件系统](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a5677e07a35c71ebbf12939cc00f5448/dash_monitoring-ceph-file-systems.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a5677e07a35c71ebbf12939cc00f5448/dash_monitoring-ceph-file-systems.png)

**其它资源**

- ​						如需更多信息，请参阅 [*文件系统指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/file_system_guide/)。 				

## 6.13. 在控制面板中监控 Ceph 对象网关守护进程

​				您可以使用 Red Hat Ceph Storage 控制面板监控 Ceph 对象网关守护进程。您可以查看 Ceph 对象网关守护进程的详情、性能计数器和性能详情。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						在存储集群中至少配置一个 Ceph 对象网关守护进程。 				

**流程**

1. ​						登录控制面板。 				
2. ​						在导航栏中，单击 *Object Gateway*。 				
3. ​						若要查看关于 Ceph 对象网关守护进程的更多信息，请单击所在行上的 *Expand/Collapse* 图标。如果您配置了多个 Ceph 对象网关守护进程，请单击 *Sync Performance* 选项卡并查看多站点性能计数器。 				

**其它资源**

- ​						有关更多信息，请参阅 [*Red Hat Ceph Storage Ceph 对象网关指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/)。 				

## 6.14. 监控 Ceph 仪表板上的块设备镜像

​				您可以使用 Red Hat Ceph Storage 控制面板监控和管理块设备镜像。您可以查看镜像的详情、快照、配置详情和性能详情。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						创建启用了 *rbd* 应用的池。 				
- ​						已创建一个镜像。 				

**流程**

1. ​						登录控制面板。 				

2. ​						在导航栏中，单击 *Block*。 				

3. ​						要查看有关镜像的更多信息，请点其行上的 *Expand/Collapse* 图标。 				

   图 6.14. 监控块设备镜像

   ![监控块设备镜像](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/7ccb2dd0b1f7e7b473b80be49d0b64c0/dash_monitoring-block-device-images.png)

**其它资源**

- ​						如需了解更多详细信息，请参阅 *Red Hat Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建镜像部分*。 https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-images-on-the-ceph-dashboard_dash 				

# 第 7 章 在 Ceph 仪表板上管理警报

​			作为存储管理员，您可以查看警报详情并在 Red Hat Ceph Storage 仪表板中为它们创建静默。这包括以下预定义警报： 	

- ​					CephadmDaemonFailed 			
- ​					CephadmPaused 			
- ​					CephadmUpgradeFailed 			
- ​					CephDaemonCrash 			
- ​					CephDeviceFailurePredicted 			
- ​					CephDeviceFailurePredictionTooHigh 			
- ​					CephDeviceFailureRelocationIncomplete 			
- ​					CephFilesystemDamaged 			
- ​					CephFilesystemDegraded 			
- ​					CephFilesystemFailureNoStandby 			
- ​					CephFilesystemInsufficientStandby 			
- ​					CephFilesystemMDSRanksLow 			
- ​					CephFilesystemOffline 			
- ​					CephFilesystemReadOnly 			
- ​					CephHealthError 			
- ​					CephHealthWarning 			
- ​					CephMgrModuleCrash 			
- ​					CephMgrPrometheusModuleInactive 			
- ​					CephMonClockSkew 			
- ​					CephMonDiskspaceCritical 			
- ​					CephMonDiskspaceLow 			
- ​					CephMonDown 			
- ​					CephMonDownQuorumAtRisk 			
- ​					CephNodeDiskspaceWarning 			
- ​					CephNodeInconsistentMTU 			
- ​					CephNodeNetworkPacketDrops 			
- ​					CephNodeNetworkPacketErrors 			
- ​					CephNodeRootFilesystemFull 			
- ​					CephObjectMissing 			
- ​					CephOSDBackfillFull 			
- ​					CephOSDDown 			
- ​					CephOSDDownHigh 			
- ​					CephOSDFlapping 			
- ​					CephOSDFull 			
- ​					CephOSDHostDown 			
- ​					CephOSDInternalDiskSizeMismatch 			
- ​					CephOSDNearFull 			
- ​					CephOSDReadErrors 			
- ​					CephOSDTimeoutsClusterNetwork 			
- ​					CephOSDTimeoutsPublicNetwork 			
- ​					CephOSDTooManyRepairs 			
- ​					CephPGBackfillAtRisk 			
- ​					CephPGImbalance 			
- ​					CephPGNotDeepScrubbed 			
- ​					CephPGNotScrubbed 			
- ​					CephPGRecoveryAtRisk 			
- ​					CephPGsDamaged 			
- ​					CephPGsHighPerOSD 			
- ​					CephPGsInactive 			
- ​					CephPGsUnclean 			
- ​					CephPGUnavilableBlockingIO 			
- ​					CephPoolBackfillFull 			
- ​					CephPoolFull 			
- ​					CephPoolGrowthWarning 			
- ​					CephPoolNearFull 			
- ​					CephSlowOps 			
- ​					PrometheusJobMissing 			

图 7.1. 预定义的警报

![预定义的警报](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/8419dec113f84eed0dc080b0f8b2bcf3/dash_osds-pre-defined-alerts.png)

​			您还可以使用简单网络管理协议(SNMP)陷阱来监控警报。 	

## 7.1. 启用监控堆栈

​				您可以使用命令行界面手动启用 Red Hat Ceph Storage 集群的监控堆栈，如 Prometheus、Alertmanager 和 Grafana。 		

​				您可以使用 Prometheus 和 Alertmanager API 来管理警报和静默。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						对所有主机的根级别访问权限。 				

**流程**

1. ​						登录 `cephadm` shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						为监控堆栈设置 API： 				

   - ​								指定 Alertmanager 服务器的主机和端口： 						

     **语法**

     ​									

     

     ```none
     ceph dashboard set-alertmanager-api-host 'ALERTMANAGER_API_HOST:PORT'
     ```

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# ceph dashboard set-alertmanager-api-host 'http://10.0.0.101:9093'
     Option ALERTMANAGER_API_HOST updated
     ```

   - ​								要查看配置的警报，请将 URL 配置为 Prometheus API。使用此 API 时，Ceph 控制面板 UI 会验证新静默是否与对应的警报匹配。 						

     **语法**

     ​									

     

     ```none
     ceph dashboard set-prometheus-api-host 'PROMETHEUS_API_HOST:PORT'
     ```

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# ceph dashboard set-prometheus-api-host 'http://10.0.0.101:9095'
     Option PROMETHEUS_API_HOST updated
     ```

     ​								设置主机后，刷新浏览器的仪表板窗口。 						

   - ​								指定 Grafana 服务器的主机和端口： 						

     **语法**

     ​									

     

     ```none
     ceph dashboard set-grafana-api-url 'GRAFANA_API_URL:PORT'
     ```

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# ceph dashboard set-grafana-api-url 'http://10.0.0.101:3000'
     Option GRAFANA_API_URL updated
     ```

3. ​						获取 Prometheus、Alertmanager 和 Grafana API 主机详情： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard get-alertmanager-api-host
   http://10.0.0.101:9093
   [ceph: root@host01 /]# ceph dashboard get-prometheus-api-host
   http://10.0.0.101:9095
   [ceph: root@host01 /]# ceph dashboard get-grafana-api-url
   http://10.0.0.101:3000
   ```

4. ​						可选： 如果您在 Prometheus、Alertmanager 或 Grafana 设置中使用自签名证书，请在仪表板中禁用证书验证，这样可避免拒绝由未知证书颁发机构(CA)签名的证书导致的连接，或者与主机名不匹配。 				

   - ​								对于 Prometheus： 						

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# ceph dashboard set-prometheus-api-ssl-verify False
     ```

   - ​								对于 Alertmanager： 						

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# ceph dashboard set-alertmanager-api-ssl-verify False
     ```

   - ​								对于 Grafana： 						

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# ceph dashboard set-grafana-api-ssl-verify False
     ```

5. ​						获取 Prometheus、Alertmanager 和 Grafana 的自签名证书验证设置详情： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard get-prometheus-api-ssl-verify
   [ceph: root@host01 /]# ceph dashboard get-alertmanager-api-ssl-verify
   [ceph: root@host01 /]# ceph dashboard get-grafana-api-ssl-verify
   ```

6. ​						可选：如果仪表板没有反映更改，则必须禁用并启用仪表板： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph mgr module disable dashboard
   [ceph: root@host01 /]# ceph mgr module enable dashboard
   ```

**其它资源**

- ​						请参阅 *Red Hat Ceph Storage 安装指南中的* [*Bootstrap 命令选项*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/installation_guide#bootstrap-command-options_install) 部分。 				
- ​						请参阅 [*Red Hat Ceph Storage*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/installation_guide#red-hat-ceph-storage-installation) *安装指南中的 Red Hat Ceph Storage 安装章节*。 				
- ​						请参阅 *Red Hat [\*Ceph Storage Operations Guide\*中的使用 Ceph Orchestrator 部署监控堆栈](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/operations_guide/#deploying-the-monitoring-stack-using-the-ceph-orchestrator_ops)*  部分。 				

## 7.2. 配置 Grafana 证书

​				`cephadm` 使用 ceph 键/值存储中定义的证书部署 Grafana。如果没有指定证书，`cephadm` 会在部署 Grafana 服务过程中生成一个自签名证书。 		

​				您可以使用 `ceph config-key set` 命令配置自定义证书。 		

**前提条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				

**流程**

1. ​						登录 `cephadm` shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						为 Grafana 配置自定义证书： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph config-key set mgr/cephadm/grafana_key -i $PWD/key.pem
   [ceph: root@host01 /]# ceph config-key set mgr/cephadm/grafana_crt -i $PWD/certificate.pem
   ```

3. ​						如果已经部署了 Grafana，则运行 `reconfig` 以更新配置： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph orch reconfig grafana
   ```

4. ​						每次添加新证书时，请按照以下步骤操作： 				

   1. ​								创建新目录 						

      **示例**

      ​									

      

      ```none
      [root@host01 ~]# mkdir /root/internalca
      [root@host01 ~]# cd /root/internalca
      ```

   2. ​								生成密钥： 						

      **示例**

      ​									

      

      ```none
      [root@host01 internalca]# openssl ecparam -genkey -name secp384r1 -out $(date +%F).key
      ```

   3. ​								查看密钥： 						

      **示例**

      ​									

      

      ```none
      [root@host01 internalca]# openssl ec -text -in $(date +%F).key | less
      ```

   4. ​								发出请求： 						

      **示例**

      ​									

      

      ```none
      [root@host01 internalca]# umask 077; openssl req -config openssl-san.cnf -new -sha256 -key $(date +%F).key -out $(date +%F).csr
      ```

   5. ​								在发送签名前查看请求： 						

      **示例**

      ​									

      

      ```none
      [root@host01 internalca]# openssl req -text -in $(date +%F).csr | less
      ```

   6. ​								作为 CA 签名： 						

      **示例**

      ​									

      

      ```none
      [root@host01 internalca]# openssl ca -extensions v3_req -in $(date +%F).csr -out $(date +%F).crt -extfile openssl-san.cnf
      ```

   7. ​								检查签名的证书： 						

      **示例**

      ​									

      

      ```none
      [root@host01 internalca]# openssl x509 -text -in $(date +%F).crt -noout | less
      ```

**其它资源**

- ​						如需了解更多详细信息，[*请参阅使用共享系统证书*](https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/8/html/system_design_guide/using-shared-system-certificates_system-design-guide)。 				

## 7.3. 添加 Alertmanager Webhook

​				您可以向现有 Alertmanager 配置添加新 webhook，以接收有关存储集群运行状况的实时警报。您必须启用传入的 webhook，以允许将消息异步到第三方应用程序中。 		

​				例如，如果一个 OSD 在 Red Hat Ceph Storage 集群中停机，您可以将 Alertmanager 配置为在 Google chat 上发送通知。 		

**前提条件**

- ​						正在运行的 Red Hat Ceph Storage 集群启用了监控堆栈组件。 				
- ​						在接收第三方应用程序上配置的传入 Webhook。 				

**流程**

1. ​						登录 `cephadm` shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						将 Alertmanager 配置为使用 Webhook 进行通知： 				

   **语法**

   ​							

   

   ```none
   service_type: alertmanager
   spec:
     user_data:
       default_webhook_urls:
       - "_URLS_"
   ```

   ​						`default_webhook_urls` 是添加到默认接收器 `webhook_configs` 配置中的额外 URL 列表。 				

   **示例**

   ​							

   

   ```none
   service_type: alertmanager
   spec:
     user_data:
       webhook_configs:
       - url: 'http:127.0.0.10:8080'
   ```

3. ​						更新 Alertmanager 配置： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]#  ceph orch reconfig alertmanager
   ```

**验证**

- ​						从 Alertmanager 到 Gchat 的通知示例： 				

  **示例**

  ​							

- ```none
  using: https://chat.googleapis.com/v1/spaces/(xx- space identifyer -xx)/messages
  posting: {'status': 'resolved', 'labels': {'alertname': 'PrometheusTargetMissing', 'instance': 'postgres-exporter.host03.chest
  response: 200
  response: {
  "name": "spaces/(xx- space identifyer -xx)/messages/3PYDBOsIofE.3PYDBOsIofE",
  "sender": {
  "name": "users/114022495153014004089",
  "displayName": "monitoring",
  "avatarUrl": "",
  "email": "",
  "domainId": "",
  "type": "BOT",
  "isAnonymous": false,
  "caaEnabled": false
  },
  "text": "Prometheus target missing (instance postgres-exporter.cluster.local:9187)\n\nA Prometheus target has disappeared. An e
  "cards": [],
  "annotations": [],
  "thread": {
  "name": "spaces/(xx- space identifyer -xx)/threads/3PYDBOsIofE"
  },
  "space": {
  "name": "spaces/(xx- space identifyer -xx)",
  "type": "ROOM",
  "singleUserBotDm": false,
  "threaded": false,
  "displayName": "_privmon",
  "legacyGroupChat": false
  },
  "fallbackText": "",
  "argumentText": "Prometheus target missing (instance postgres-exporter.cluster.local:9187)\n\nA Prometheus target has disappea
  "attachment": [],
  "createTime": "2022-06-06T06:17:33.805375Z",
  "lastUpdateTime": "2022-06-06T06:17:33.805375Z"
  ```

## 7.4. 在 Ceph 仪表板上查看警报

​				触发警报后，您可以在 Red Hat Ceph Storage 控制面板查看它。您可以编辑 *Manager 模块* 设置，以便在触发警报时触发警报。 		

注意

​					Red Hat Ceph Storage 6 集群不支持 SSL。 			

**前提条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						配置了简单邮件传输协议(SMTP)。 				
- ​						触发警报。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在仪表板上自定义 *alerts* 模块，以获取存储集群的电子邮件警报： 				

   1. ​								在导航菜单中点 *Cluster*。 						

   2. ​								选择 *Manager 模块*。 						

   3. ​								选择 *alerts* 模块。 						

   4. ​								在 *Edit* 下拉菜单中，选择 *Edit*。 						

   5. ​								在 *Edit Manager 模块*窗口中，更新所需参数并点 *Update*。 						

      注意

      ​									不要选择 `smtp_ssl` 参数。 							

      图 7.2. 为警报编辑 Manager 模块

      [![为警报编辑 Manager 模块](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/91c9db16a74507dfad706e8ded898c43/dash-alert-manager-module-window.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/91c9db16a74507dfad706e8ded898c43/dash-alert-manager-module-window.png)

3. ​						在导航菜单中点 *Cluster*。 				

4. ​						从下拉菜单中选择 *Monitoring*。 				

5. ​						要查看警报的详细信息，请单击其所在行上的 *Expand/Collapse* 图标。 				

   图 7.3. 查看警报

   [![查看警报](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/fa0e89eeb7902708ef4e12b9e41cce2b/dash-viewing-alerts.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/fa0e89eeb7902708ef4e12b9e41cce2b/dash-viewing-alerts.png)

6. ​						要查看警报的来源，请单击其行，然后单击 **Source**。 				

**其他资源**

- ​						有关配置 SMTP 的详情 [*，请参阅使用 Ceph Manager 警报模块*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#using-the-ceph-manager-alerts-module_dash)。 				

## 7.5. 在 Ceph 仪表板上创建静默

​				您可以在 Red Hat Ceph Storage 仪表板中针对指定时间为警报创建静默。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						触发警报。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在导航菜单中点 *Cluster*。 				

3. ​						从下拉菜单中选择 *Monitoring*。 				

4. ​						要为警报创建静默，请选择它所在的行。 				

5. ​						点 *+Create Silence*。 				

6. ​						在 *Create Silence* 窗口中，为 *Duration* 添加详情并点击 *Create Silence*。 				

   图 7.4. Create Silence

   [![Create Silence](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/9f2a657aa52f00049bc212a1976356ab/dash-creating-silence.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/9f2a657aa52f00049bc212a1976356ab/dash-creating-silence.png)

7. ​						您会收到一个成功创建静默的通知。 				

## 7.6. 在 Ceph 仪表板上重新创建静默

​				您可以在 Red Hat Ceph Storage Dashboard 上的静默中重新创建静默。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						触发警报。 				
- ​						为警报创建的静默。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在导航菜单中点 *Cluster*。 				

3. ​						从下拉菜单中选择 *Monitoring*。 				

4. ​						点 *Silences* 选项卡。 				

5. ​						要重新创建已过期的静默，请点击它的行。 				

6. ​						点 *Recreate* 按钮。 				

7. ​						在 *Recreate Silence* 窗口中，添加详情并点 *Recreate Silence*。 				

   图 7.5. 重新创建静默

   [![重新创建静默](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/14a476cbdf541333c6484efa0b911867/dash-re-creating-silence.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/14a476cbdf541333c6484efa0b911867/dash-re-creating-silence.png)

8. ​						您会收到一个通知，让静默被成功重新创建。 				

## 7.7. 在 Ceph 仪表板上编辑静默

​				您可以编辑活跃的静默，例如在 Red Hat Ceph Storage 仪表板中扩展它处于活跃状态的时间。如果静默已到期，可以重新创建静默或为警报创建新静默。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						触发警报。 				
- ​						为警报创建的静默。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在导航菜单中点 *Cluster*。 				

3. ​						从下拉菜单中选择 *Monitoring*。 				

4. ​						点 *Silences* 选项卡。 				

5. ​						要编辑静默，请点击它的行。 				

6. ​						在 *Edit* 下拉菜单中，选择 *Edit*。 				

7. ​						在 *Edit Silence* 窗口中，更新详情并点 *Edit Silence*。 				

   图 7.6. 编辑静默

   [![Edit Silence](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/4dba2a74e89f3f217dd57e7e504ad7c3/dash-editing-silence.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/4dba2a74e89f3f217dd57e7e504ad7c3/dash-editing-silence.png)

8. ​						您会收到成功更新静默的通知。 				

## 7.8. 在 Ceph 仪表板中将静默设置为过期

​				您可以使静默到期，以便在 Red Hat Ceph Storage 仪表板中不隐藏匹配的警报。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						触发警报。 				
- ​						为警报创建的静默。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在导航菜单中点 *Cluster*。 				

3. ​						从下拉菜单中选择 *Monitoring*。 				

4. ​						点 *Silences* 选项卡。 				

5. ​						要使静默到期，请点击它的行。 				

6. ​						在 *Edit* 下拉菜单中，选择 *Expire*。 				

7. ​						在 *Expire Silence* 对话框中，选择 *Yes, I am sure*，然后单击 *Expire Silence*。 				

   图 7.7. 过期的静默

   ![过期的静默](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3d0e080d5cdfadc77467da580188b8f2/dash-expiring-silence.png)

8. ​						您会收到静默成功过期的通知。 				

**其它资源**

- ​						有关更多信息，请参阅 [*Red Hat Ceph StorageTroubleshooting 指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/troubleshooting_guide/)。 				

# 第 8 章 在 Ceph 仪表板上管理 NFS Ganesha 导出

​			作为存储管理员，您可以管理将 Ceph 对象网关用作 Red Hat Ceph Storage 仪表板上的后备存储的 NFS Ganesha 导出。您可以在仪表板上部署并配置、编辑和删除 NFS ganesha 守护进程。 	

​			控制面板管理 Ceph 群集上 RADOS 对象中存储的 NFS-Ganesha 配置文件。NFS-Ganesha 必须将其配置的一部分存储在 Ceph 集群中。 	

## 8.1. 在 Ceph 控制面板中配置 NFS Ganesha 守护进程

​				在配置 Ceph 对象网关并使用 命令行界面为 NFS-Ganesha 启用专用的池后，您可以在控制面板上配置 NFS Ganesha。 		

注意

​					Red Hat Ceph Storage 5 仅支持 NFSv4 协议。 			

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						已安装 Ceph 对象网关。 				
- ​						Ceph 对象网关登录凭据添加到控制面板中。 				
- ​						启用专用池并标记带有 `nfs` 标签的自定义池。 				
- ​						Ceph 控制面板中至少具有 `ganesha-manager` 级别的访问权限。 				

**流程**

1. ​						登录到 Cephadm shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						创建 RADOS 池、命名空间并启用 `rgw` ： 				

   **语法**

   ​							

   

   ```none
   ceph osd pool create POOL_NAME _
   ceph osd pool application enable POOL_NAME freeform/rgw/rbd/cephfs/nfs
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph osd pool create nfs-ganesha
   [ceph: root@host01 /]# ceph osd pool application enable nfs-ganesha rgw
   ```

3. ​						在命令行界面中使用放置规格部署 NFS-Ganesha 网关： 				

   **语法**

   ​							

   

   ```none
   ceph orch apply nfs SERVICE_ID --placement="NUMBER_OF_DAEMONS HOST_NAME_1 HOST_NAME_2 HOST_NAME_3"
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph orch apply nfs foo --placement="2 host01 host02"
   ```

   ​						这会部署一个 NFS-Ganesha 集群 `nfsganesha`，并在 `host01` 和 `host02` 上有一个守护进程。 				

4. ​						使用命名空间和 service_ID 更新 `ganesha-clusters-rados-pool-namespace` 参数： 				

   **语法**

   ​							

   

   ```none
   ceph dashboard set-ganesha-clusters-rados-pool-namespace POOL_NAME/SERVICE_ID
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard set-ganesha-clusters-rados-pool-namespace nfs-ganesha/foo
   ```

5. ​						在仪表板登录页面上，单击 *NFS*。 				

6. ​						选择 *Create*。 				

7. ​						在 *Create NFS 导出* 窗口中，设置以下参数并点 *Create NFS export* ： 				

   1. ​								集群 - 集群的名称。 						

   2. ​								守护进程 - 您可以选择所有守护进程。 						

   3. ​								存储后端 - 您可以选择 Object Gateway。 						

   4. ​								Object Gateway User - 选择创建的用户。在本例中，它是 test_user。 						

   5. ​								Path - 任何目录。 						

   6. ​								NFS 协议 - 默认选择 NFSv4。 						

   7. ​								Pseudo - root 路径 						

   8. ​								访问类型 - 支持的访问类型是 RO、RW 和 NONE。 						

   9. ​								Squash 						

   10. ​								传输协议 						

   11. ​								客户端 						

       [![创建 NFS 导出窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/fd8bee6a3266644947f262a19dcf0162/dash_create-nfs-export.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/fd8bee6a3266644947f262a19dcf0162/dash_create-nfs-export.png)

8. ​						验证 NFS 守护进程是否已配置： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph -s
   ```

9. ​						作为 root 用户，检查 NFS-service 是否活跃并在运行： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# systemctl list-units | grep nfs
   ```

10. ​						挂载 NFS 导出并执行几个 I/O 操作。 				

11. ​						NFS 服务启动后，在 NFS-RGW 容器中，注释掉 `etc/ganesha/ganesha.conf` 文件中的 `dir_chunk=0` 参数。重启 NFS-Ganesha 服务。这允许在 NFS 挂载上正确列出。 				

**验证**

- ​						您可以在 Ceph 对象网关的 bucket 下查看 NFS 守护进程。 				

  ![NFS 存储桶](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/ec93da4d16750b8d9a468304d2ff2fa2/dash_nfs-bucket.png)

**其它资源**

- ​						有关在仪表板中添加对象网关登录凭证的更多信息，请参阅 *Red Hat Ceph Storage Dashboard 指南中的* [*手动将对象网关登录凭证添加到仪表板*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-ceph-object-gateway-login-credentials-to-the-dashboard_dash) 部分。 				
- ​						有关在控制面板上创建对象网关用户的更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在仪表板上创建 Ceph\*对象网关用户](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-users-on-the-dashboard_dash)*  部分。 				
- ​						有关在控制面板上创建对象网关存储桶的更多信息，请参阅 *Red Hat [\*Ceph\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-buckets-on-the-dashboard_dash) Storage 仪表板指南中的在仪表板上创建 Ceph 对象网关存储桶* 部分。 				
- ​						如需有关系统角色的更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板上管理角色\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#management-of-roles-on-the-ceph-dashboard) 部分*。 				

## 8.2. 在 Ceph 控制面板中使用 CephFS 配置 NFS 导出

​				在配置 Ceph 文件系统(CephFS)后，您可以使用命令行界面在 Ceph 仪表板中创建、编辑和删除 NFS 导出。您可以通过 NFS 协议导出 CephFS 命名空间。 		

​				您需要创建一个 NFS 集群，为所有 NFS Ganesha 守护进程创建通用恢复池，基于 *CLUSTER_ID* 的新用户，以及通用 NFS Ganesha 配置 RADOS 对象。 		

注意

​					Red Hat Ceph Storage 5 仅支持 NFSv4 协议。 			

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						对 bootstrap 启动主机的 root 级别访问权限。 				
- ​						Ceph 控制面板中至少具有 `ganesha-manager` 级别的访问权限。 				

**流程**

1. ​						登录到 `cephadm` shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						在后端中创建 CephFS 存储： 				

   **语法**

   ​							

   

   ```none
   ceph fs volume create CEPH_FILE_SYSTEM
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph fs volume create cephfs
   ```

3. ​						启用 Ceph Manager NFS 模块： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph mgr module enable nfs
   ```

4. ​						创建 NFS Ganesha 集群： 				

   **语法**

   ​							

   

   ```none
   ceph nfs cluster create NFS_CLUSTER_NAME "HOST_NAME_PLACEMENT_LIST"
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph nfs cluster create nfs-cephfs host02
   NFS Cluster Created Successfully
   ```

5. ​						获取仪表板 URL： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph mgr services
   {
       "dashboard": "https://10.00.00.11:8443/",
       "prometheus": "http://10.00.00.11:9283/"
   }
   ```

6. ​						使用您的凭据登录 Ceph 仪表板。 				

7. ​						在仪表板登录页面上，单击 *NFS*。 				

8. ​						点 *Create*。 				

9. ​						在 *Create NFS 导出* 窗口中，设置以下参数并点 *Create NFS export* ： 				

   1. ​								集群 - 集群的名称。 						

   2. ​								守护进程 - 您可以选择所有守护进程。 						

   3. ​								存储后端 - 您可以选择 CephFS。 						

   4. ​								CephFS User ID - 选择创建 NFS 集群的服务。 						

   5. ​								CephFS Name - 提供用户名。 						

   6. ​								CephFS Path - 任何目录。 						

   7. ​								NFS 协议 - 默认选择 NFSv4。 						

   8. ​								Pseudo - root 路径 						

   9. ​								访问类型 - 支持的访问类型是 RO、RW 和 NONE。 						

   10. ​								Squash - 选择 squash 类型。 						

   11. ​								传输协议 - 选择 UDP 或 TCP 协议。 						

   12. ​								客户端 						

       图 8.1. CephFS NFS 导出窗口

       [![创建 CephFS NFS 导出窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/0c7f8cb96136eb13baf1e6efe7175562/dash_create-cephfs-nfs-export.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/0c7f8cb96136eb13baf1e6efe7175562/dash_create-cephfs-nfs-export.png)

10. ​						在客户端主机上以 root 用户身份创建一个目录并挂载 NFS 导出： 				

    **语法**

    ​							

    

    ```none
    mkdir -p /mnt/nfs/
    mount -t nfs -o port=2049 HOSTNAME:EXPORT_NAME _MOUNT_DIRECTORY_
    ```

    **示例**

    ​							

    

    ```none
    [root@ client ~]# mkdir -p /mnt/nfs/
    [root@ client ~]# mount -t nfs -o port=2049 host02:/export1 /mnt/nfs/
    ```

**验证**

- ​						验证 NFS 守护进程是否已配置： 				

  **示例**

  ​							

  

  ```none
  [ceph: root@host01 /]# ceph -s
  ```

**其它资源**

- ​						如需了解更多详细信息 [*，请参阅 \*Red Hat Ceph Storage Operations 指南中的使用 Ceph\* Orchestrator 创建 NFS-Ganesha 集群部分*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/operations_guide/#creating-the-nfs-ganesha-cluster-using-the-ceph-orchestrator_ops)。 				

## 8.3. 在 Ceph 控制面板中编辑 NFS Ganesha 守护进程

​				您可以在 Red Hat Ceph Storage 仪表板上编辑 NFS Ganesha 守护进程。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						Ceph 控制面板中至少具有 `ganesha-manager` 级别的访问权限。 				
- ​						控制面板中配置的 NFS Ganesha 守护进程。 				

**流程**

1. ​						在控制面板中，单击 *NFS*。 				

2. ​						点需要编辑的行。 				

3. ​						在 *Edit* 下拉菜单中，点 *Edit*。 				

4. ​						在 *Edit NFS 导出*窗口中，编辑所需参数并点 *Edit NFS 导出*。 				

   [![编辑 NFS 导出窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/9379340b9031911b58559951527677af/dash_edit-nfs-export.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/9379340b9031911b58559951527677af/dash_edit-nfs-export.png)

**验证**

- ​						您将收到通知，说明 NFS ganesha 已被成功更新。 				

**其它资源**

- ​						有关配置 NFS Ganesha 的更多信息，请参阅 *Red Hat Ceph Storage Dashboard* 指南中的 [*在 Ceph 仪表板上配置 NFS Ganesga 守护进程*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#configuring-nfs-ganesha-daemons-on-the-ceph-dashboard_dash)。 				
- ​						有关在仪表板中添加对象网关登录凭证的更多信息，请参阅 *Red Hat [\*Ceph Storage Dashboard\*指南中的手动将 Ceph 对象网关登录凭证添加到仪表板](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-ceph-object-gateway-login-credentials-to-the-dashboard_dash)*  部分。 				
- ​						有关在控制面板上创建对象网关用户的更多信息，请参阅 *Red Hat Ceph Storage 仪表板指南中的在* [*仪表板上*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-users-on-the-dashboard_dash) 创建对象网关用户部分。 				
- ​						有关在控制面板上创建对象网关存储桶的更多信息，请参阅 *Red Hat [\*Ceph\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-buckets-on-the-dashboard_dash) Storage Dashboard* 指南中的在仪表板上创建 Ceph 对象网关存储桶部分。 				
- ​						如需有关系统角色的更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板上管理角色\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#management-of-roles-on-the-ceph-dashboard) 部分*。 				

## 8.4. 删除 Ceph 仪表板上的 NFS Ganesha 守护进程

​				Ceph 仪表板允许您删除 NFS Ganesha 守护进程。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						Ceph 控制面板中至少具有 `ganesha-manager` 级别的访问权限。 				
- ​						控制面板中配置的 NFS Ganesha 守护进程。 				

**流程**

1. ​						在控制面板中，单击 *NFS*。 				

2. ​						点需要删除的行。 				

3. ​						在 *Edit* 下拉菜单中点 *Delete*。 				

4. ​						在 *删除 NFS 导出*对话框中，选中 *Yes, I am sure* 并点 *Delete NFS export*。 				

   ![删除 NFS 导出窗口](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/693442a3913c3b86c0adb04b132742c4/dash_delete-nfs-export.png)

**验证**

- ​						所选行将被成功删除。 				

**其它资源**

- ​						有关配置 NFS Ganesha 的更多信息，请参阅 *Red Hat Ceph Storage Dashboard* 指南中的 [*在 Ceph 仪表板上配置 NFS Ganesga 守护进程*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#configuring-nfs-ganesha-daemons-on-the-ceph-dashboard_dash)。 				
- ​						有关在仪表板中添加对象网关登录凭证的更多信息，请参阅 *Red Hat [\*Ceph Storage Dashboard\*指南中的手动将 Ceph 对象网关登录凭证添加到仪表板](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-ceph-object-gateway-login-credentials-to-the-dashboard_dash)*  部分。 				
- ​						有关在控制面板上创建对象网关用户的更多信息，请参阅 *Red Hat Ceph Storage 仪表板指南中的在* [*仪表板上*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-users-on-the-dashboard_dash) 创建对象网关用户部分。 				
- ​						有关在控制面板上创建对象网关存储桶的更多信息，请参阅 *Red Hat [\*Ceph\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-buckets-on-the-dashboard_dash) Storage Dashboard* 指南中的在仪表板上创建 Ceph 对象网关存储桶部分。 				
- ​						如需有关系统角色的更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板上管理角色\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#management-of-roles-on-the-ceph-dashboard) 部分*。 				

# 第 9 章 在 Ceph 仪表板上管理池

​			作为存储管理员，您可以在 Red Hat Ceph Storage 仪表板上创建、编辑和删除池。 	

​			本节涵盖了以下管理任务： 	

- ​					[*在 Ceph 控制面板创建池*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#creating-pools-on-the-ceph-dashboard_dash) 			
- ​					[*在 Ceph 仪表板上编辑池*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#editing-pools-on-the-ceph-dashboard_dash) 			
- ​					[*删除 Ceph 仪表板上的池*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#deleting-pools-on-the-ceph-dashboard_dash) 			

## 9.1. 在 Ceph 仪表板上创建池

​				当您在没有创建池的情况下部署存储集群时，Ceph 将使用默认池来存储数据。您可以在 Red Hat Ceph Storage 仪表板中创建一个池来对存储对象进行逻辑分区。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				

**流程**

1. ​						登录控制面板。 				

2. ​						在导航菜单中点 *Pools*。 				

3. ​						点击 *Create*。 				

4. ​						在 *Create Pool* 窗口中设置以下参数： 				

   图 9.1. 创建池

   [![创建池](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/44ea6d3c7b88140159576eb105d64076/dash_creating-pools.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/44ea6d3c7b88140159576eb105d64076/dash_creating-pools.png)

   1. ​								设置池的名称，然后选择池类型。 						
   2. ​								选择 replicated 或 Erasure Coded(EC)池类型。 						
   3. ​								设置放置组(PG)号。 						
   4. ​								可选：如果使用复制池类型，请设置复制的大小。 						
   5. ​								可选：如果使用 EC 池类型，请配置以下附加设置。 						
   6. ​								可选： 要查看当前所选 EC 配置集的设置，请点问号。 						
   7. ​								可选：点加号符号添加新 EC 配置集。 						
   8. ​								可选：点击铅笔图标为池选择应用程序。 						
   9. ​								可选：设置 CRUSH 规则（如果适用）。 						
   10. ​								可选：如果需要压缩，请选择 *passive*, *aggressive*, 或 *force*。 						
   11. ​								可选：设置配额。 						
   12. ​								可选：设置服务质量配置。 						

5. ​						点 *Create Pool*。 				

6. ​						您会收到成功创建池的通知。 				

**其它资源**

- ​						有关更多信息，请参阅 *Red Hat [\*Ceph Storage 架构指南中的 Ceph\*池](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/architecture_guide/#ceph-pools_arch)*  部分以了解更多详细信息。 				

## 9.2. 在 Ceph 仪表板中编辑池

​				您可以编辑 Red Hat Ceph Storage 仪表板中的池。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						已创建一个池。 				

**流程**

1. ​						登录控制面板。 				

2. ​						在导航菜单中点 *Pools*。 				

3. ​						要编辑池，请单击其行。 				

4. ​						在 *Edit* 下拉菜单中，选择 *Edit*。 				

5. ​						在 *Edit Pool* 窗口中，编辑所需参数并点 *Edit Pool* ： 				

   图 9.2. 编辑池

   [![编辑池](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/40c7ac194d81efce1e3701ed2137baf0/dash_editing-pools.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/40c7ac194d81efce1e3701ed2137baf0/dash_editing-pools.png)

6. ​						您会收到成功创建池的通知。 				

**其它资源**

- ​						如需更多信息，请参阅 *Red Hat Ceph Storage 架构指南中的* Ceph [*池*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/architecture_guide/#ceph-pools_arch)。 				
- ​						有关压缩模式的更多信息，请参阅 *Red Hat Ceph Storage 策略指南中的池* [*值*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/storage_strategies_guide/#pool-values_strategy)。 				

## 9.3. 删除 Ceph 仪表板上的池

​				您可以删除 Red Hat Ceph Storage 仪表板中的池。在 Manager 模块中，确保将 `mon_allow_pool_delete` 的值设为 `True`。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						已创建一个池。 				

**流程**

1. ​						登录控制面板。 				

2. ​						在导航栏上，在 *Cluster* 下拉菜单中选择 *Configuration*。 				

3. ​						在 *Level* 下拉菜单中选择 **Advanced**: 				

4. ​						搜索 `mon_allow_pool_delete`，单击 Edit 				

5. ​						将所有值设为 `true` ： 				

   图 9.3. 配置以删除池

   [![编辑配置以删除池](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/7fbaad428b078c58c574d7880b3dc7a8/dash_configuration-pool-delete.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/7fbaad428b078c58c574d7880b3dc7a8/dash_configuration-pool-delete.png)

6. ​						在导航栏中点 *Pools* ： 				

7. ​						要删除池，请点击其行： 				

8. ​						在 *Edit* 下拉菜单中选择 *Delete*。 				

9. ​						在 *Delete Pool* 窗口中，单击 *Yes, I am sure* 框，然后单击 *Delete Pool* 以保存设置： 				

   图 9.4. 删除池

   ![删除池](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/d01c0723622069faba480dc473132a99/dash_delete-pools.png)

**其它资源**

- ​						如需更多信息，请参阅 *Red Hat Ceph Storage 架构指南中的* Ceph [*池*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/architecture_guide/#ceph-pools_arch)。 				
- ​						有关压缩模式的更多信息，请参阅 *Red Hat Ceph Storage 策略指南中的池* [*值*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/storage_strategies_guide/#pool-values_strategy)。 				

# 第 10 章 管理 Ceph 仪表板上的主机

​			作为存储管理员，您可以在 Red Hat Ceph Storage Dashboard 中为主机启用或禁用维护模式。维护模式可确保关闭主机来执行维护活动，不会损害集群。 	

​			您还可以使用 Red Hat Ceph Storage Dashboard 中的 *Start Drain* 和 *Remove* 选项删除主机。 	

​			本节涵盖了以下管理任务： 	

- ​					[*进入维护模式*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#entering-maintenance-mode_dash) 			
- ​					[*退出维护模式*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#exiting-maintenance-mode_dash) 			
- ​					[*使用 Ceph 控制面板删除主机*。](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/index#removing-hosts-using-the-ceph-dashboard_dash) 			

**先决条件**

- ​					一个正在运行的 Red Hat Ceph Storage 集群。 			
- ​					已安装仪表板。 			
- ​					主机、Ceph 监控和 Ceph 管理器守护进程添加到存储集群中。 			

## 10.1. 进入维护模式

​				在 Red Hat Ceph Storage Dashboard 上关机之前，您可以进入主机进入维护模式。如果维护模式成功启用，则主机将会脱机，且执行维护活动的任何错误。如果维护模式失败，这表明失败的原因和在关闭主机前需要执行的操作。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						所有其他预备性检查都由 Ceph 在内部执行，并且 Ceph 内部获取任何可能的错误。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Hosts*。 				

3. ​						从列表中选择一个主机。 				

4. ​						在 *Edit* 下拉菜单中点 *Enter Maintenance*。 				

   图 10.1. 进入维护模式

   [![进入维护模式](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/ca2e46fe109ff0da02825f1afc831433/dash_hosts-enter-maintenance.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/ca2e46fe109ff0da02825f1afc831433/dash_hosts-enter-maintenance.png)

   注意

   ​							当主机进入维护时，所有守护进程都会被停止。您可以在主机的 *Daemons* 选项卡下检查守护进程的状态。 					

**验证**

1. ​						您会收到一个通知，主机成功移到维护中，且 *maintenance* 标签会出现在 **Status** 列中。 				

注意

​					如果维护模式失败，您会收到指示失败原因的通知。 			

## 10.2. 退出维护模式

​				要重启主机，您可以在 Red Hat Ceph Storage Dashboard 上移出维护模式。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						所有其他预备性检查都由 Ceph 在内部执行，并且 Ceph 内部获取任何可能的错误。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Hosts*。 				

3. ​						从 *Hosts* 类别中选择维护中的主机。 				

   注意

   ​							您可以通过检查 **Status** 列中的 *Maintenance* 标签来识别处于维护状态的主机。 					

4. ​						在 *Edit* 下拉菜单中点 *Exit Maintenance*。 				

   图 10.2. 退出维护模式

   [![退出维护模式](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/8adcc5d55bd7f1349bbaf8f16659d24c/dash_hosts-exit-maintenance.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/8adcc5d55bd7f1349bbaf8f16659d24c/dash_hosts-exit-maintenance.png)

   ​						退出维护模式后，您需要默认在主机上创建所需的服务，并且 node-exporter 会被部署。 				

**验证**

1. ​						您会收到一个通知，主机已成功移出维护，维护标签已从 Status 列中删除。 				

## 10.3. 使用 Ceph 仪表板删除主机

​				要从 Ceph 集群中删除主机，您可以在 Red Hat Ceph Storage Dashboard 中使用 *Start Drain* 和 *Remove* 选项。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						所有其他预备性检查都由 Ceph 在内部执行，并且 Ceph 内部获取任何可能的错误。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Hosts*。 				

3. ​						在 *Hosts* 列表中，选择您要删除的主机。 				

4. ​						在 *Edit* 下拉菜单中选择 *Start Drain*。 				

   图 10.3. 选择 Start Drain 选项

   [![选择 Start Drain 选项](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/632b0e01f29d276d4d27ada427703677/dash_hosts-start-drain.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/632b0e01f29d276d4d27ada427703677/dash_hosts-start-drain.png)

   ​						这个选项排空主机中的所有守护进程。 				

   注意

   ​							`_no_schedule` 标签自动应用到主机，这会阻止在此主机上部署守护进程。 					

   1. ​								可选： 要停止从主机排空守护进程，请点击 *Edit* 下拉菜单中选择 *Stop Drain* 选项。 						

5. ​						检查所有守护进程是否已从主机中删除。 				

   1. ​								单击所在行上的 *Expand*/*Collapse* 图标 						

   2. ​								选择 *Daemons*。不应列出守护进程。 						

      图 10.4. 检查主机守护进程的状态

      [![检查主机守护进程的状态](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/39ec06fecc0c13995c81b1b705923844/dash_hosts-daemons.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/39ec06fecc0c13995c81b1b705923844/dash_hosts-daemons.png)

      重要

      ​									在所有守护进程都移除后，可以从集群中安全地删除主机。 							

6. ​						删除主机。 				

   1. ​								在 *Edit* 下拉菜单中选择 *Remove*。 						

      图 10.5. 删除主机

      [![删除主机](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/07ba9f50f6499b4fae92dbade813d3c4/dash_hosts-remove.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/07ba9f50f6499b4fae92dbade813d3c4/dash_hosts-remove.png)

   2. ​								在 *Remove Host* 对话框中，选中 **Yes, I am sure.** 并点 **Remove Host**。 						

      ![主机对话框](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3aaae0d5c4fc6ef812f3dbaf11ebe886/dash_hosts-dialog-box.png)

**验证**

1. ​						从 *Hosts* 列表中成功删除主机后，您会收到通知。 				

# 第 11 章 在控制面板中管理 Ceph OSD

​			作为存储管理员，您可以在 Red Hat Ceph Storage 控制面板中监控和管理 OSD。 	

​			Red Hat Ceph Storage 仪表板的一些功能有： 	

- ​					列出 OSD、其状态、统计信息、属性、元数据、设备运行状况、性能计数器和性能详情。 			
- ​					将 OSD 关机标记为 down，即丢失、清除、重新加权、清理、深度清理、删除和选择 profile，以调整回填活动。 			
- ​					列出与 OSD 关联的所有驱动器。 			
- ​					设置并更改 OSD 的设备类。 			
- ​					在新的驱动器和主机上部署 OSD。 			

**先决条件**

- ​					正在运行的 Red Hat Ceph Storage 集群 			
- ​					在 Red Hat Ceph Storage 仪表板上的 `cluster-manager` 访问级别 			

## 11.1. 在 Ceph 仪表板上管理 OSD

​				您可以在 Red Hat Ceph Storage Dashboard 上对 Ceph OSD 执行以下操作： 		

- ​						创建新 OSD。 				
- ​						编辑 OSD 的设备类。 				
- ​						将标记标记为 *No Up*,*No Down*,*No In*，或 *No Out*。 				
- ​						刮除和深度刮除 OSD。 				
- ​						重新加权 OSD。 				
- ​						将 OSD 标记为 *Out*, *In*, *Down*, 或 *Lost*。 				
- ​						清除 OSD。 				
- ​						销毁 OSD。 				
- ​						删除 OSD。 				

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						主机、监控和管理器守护进程添加到存储集群中。 				

**流程**

1. ​						登录到仪表板。 				
2. ​						从 *Cluster* 下拉菜单中，选择 *OSD*。 				

**创建 OSD**

1. ​						要创建 OSD，点 *Create*。 				

   图 11.1. 为 OSD 添加设备

   [![为 OSD 添加设备](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/23ed575890f33cedc6692a4070a99d73/dash_osds-add-device.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/23ed575890f33cedc6692a4070a99d73/dash_osds-add-device.png)

   注意

   ​							确定您有可用的主机和几个可用的设备。您可以在 *Cluster* 下拉菜单的*物理磁盘*中检查可用设备。 					

   1. ​								在 *Create OSDs* 窗口中，从 *Deployment* 选项中选择以下选项之一： 						
      - ​										**Cost/Capacity-optimized** ：集群使用所有可用的 HDD 部署。 								
      - ​										**Throughput-optimized** ：最低设备用于存储数据，使用更快速的设备来存储日志/设备。 								
      - ​										**IOPS-optmized** ：所有可用的 NVME 均用于部署 OSD。 								
   2. ​								在 *Advanced* 模式中，您可以点 *+Add* 添加主要、WAL 和 DB 设备。 						
      - ​										**主设备** ：主存储设备包含所有 OSD 数据。 								
      - ​										**WAL 设备** ： Write-Ahead-Log 设备用于 BlueStore 的内部日志，且仅在 WAL 设备比主设备快时使用。例如：NVMEs 或 SSD。 								
      - ​										**DB 设备** ：数据库设备用于存储 BlueStore 的内部元数据，且仅在 DB 设备比主设备更快时使用。例如，*NVMEs* 或 *SSDs*)。 								
   3. ​								如果要为安全起见加密您的数据，在*功能*下，选择*加密*。 						
   4. ​								点 *Preview* 按钮，然后在 OSD Creation Preview 对话框中单击 *Create*。 						
   5. ​								在 *OSD Creation Preview* 对话框中，单击 *Create*。 						

2. ​						您将获得该 OSD 已成功创建的通知。 				

3. ​						OSD 状态从 *in* 和 *down* 变为 *in* 和 *up*。 				

**编辑 OSD**

1. ​						要编辑 OSD，选择行。 				

   1. ​								在 *Edit* 下拉菜单中选择 *Edit*。 						

   2. ​								编辑设备类。 						

   3. ​								单击 *Edit OSD*。 						

      图 11.2. 编辑 OSD

      ![编辑 OSD](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/b3e851e9b2a018e5315755c56a7c7cc2/dash_osds-edit-osd.png)

   4. ​								您会收到成功更新 OSD 的通知。 						

**标记 OSD 的标记**

1. ​						要标记 OSD 的标志，请选择行。 				

   1. ​								在 *Edit* 下拉菜单中，选择 *Flags*。 						

   2. ​								将标记标记为 *No Up*, No Down ,*No Down*,*No In*, 或 *No Out*。 						

   3. ​								点 *Update*。 						

      图 11.3. OSD 的标记

      ![OSD 的标记](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a5031320ab6264c5b089a4c5ea95d43a/dash_osds-marking-flags.png)

   4. ​								您会看到一个通知，说明 OSD 的标志已成功更新。 						

**刮除 OSD**

1. ​						要刮除 OSD，请选择行。 				

   1. ​								在 *Edit* 下拉菜单中，选择 *Scrub*。 						

   2. ​								在 *OSD Scrub* 对话框中，单击 *Update*。 						

      图 11.4. 清理 OSD

      ![清理 OSD](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/c1f867b7aeb49ccde6a63129670ee53d/dash_osds-scrubbing-flags.png)

   3. ​								您将获得一个成功启动 OSD 刮除的通知。 						

**深度刮除 OSD**

1. ​						要深度刮除 OSD，请选择行。 				

   1. ​								在 *Edit* 下拉菜单中，选择 *Deep scrub*。 						

   2. ​								在 *OSD Deep Scrub* 对话框中，单击 *Update*。 						

      图 11.5. 深度刮除 OSD

      ![深度刮除 OSD](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/176aa48cfa4e4c059077bff7bb03272d/dash_osds-deep-scrubbing-flags.png)

   3. ​								您将获得一个成功启动 OSD 的深度刮除的通知。 						

**重新加权 OSD**

1. ​						要重新加权 OSD，请选择行。 				

   1. ​								在 *Edit* 下拉菜单中选择 *Reweight*。 						

   2. ​								在 *Reweight OSD* 对话框中，输入零和一之间的值。 						

   3. ​								点 *Reweight*。 						

      图 11.6. 重新加权 OSD

      ![重新加权 OSD](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/752ddc00e05a7e0a00c864d5b9fbfa93/dash_osds-reweighting-osds.png)

**标记 OSD Out**

1. ​						要标记 OSD，请选择行。 				

   1. ​								从 *Edit* 下拉菜单，选择 *Mark Out*。 						

   2. ​								在 *Mark OSD out* 对话框中，点 *Mark Out*。 						

      图 11.7. 标记 OSDs out

      ![标记 OSDs out](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/53a954b64063bd80de8f5bf7bce83374/dash_osds-marking-osds-out.png)

   3. ​								OSD 的状态将更改为 *out*。 						

**标记 OSD In**

1. ​						要将 OSD 标记为 in，可选择处于 *out* 状态的 OSD 行。 				

   1. ​								在 *Edit* 下拉菜单中选择 *Mark In*。 						

   2. ​								在对话框中的 *Mark OSD 中*，点 *Mark In*。 						

      图 11.8. 将 OSD 标记为 in

      ![将 OSD 标记为 in](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/96ae3f8b9fbc51fff6237feee706a1ab/dash_osds-marking-osds-in.png)

   3. ​								OSD 的状态将变为 *in*。 						

**标记 OSD 故障**

1. ​						要标记 OSD 停机，请选择行。 				

   1. ​								在 *Edit* 下拉菜单中，选择 *Mark Down*。 						

   2. ​								在 *Mark OSD down* 对话框中，点 *Mark Down*。 						

      图 11.9. 标记 OSD 停机

      ![标记 OSD 停机](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/93636ab555bdd9ad37f13c12a6ef5601/dash_osds-marking-osds-down.png)

   3. ​								OSD 的状态将更改为 *down*。 						

**标记 OSD 为 Lost**

1. ​						要标记丢失的 OSD，可选择 OSD 处于 *out* 和 *down* 状态。 				

   1. ​								在 *Edit* 下拉菜单中，选择 *Mark Lost*。 						

   2. ​								在 *Mark OSD Lost* 对话框中，选中 *Yes, I am sure* 选项，然后点 *Mark Lost*。 						

      图 11.10. 标记 OSD 为 Lost

      ![标记 OSD lost](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a54c255f994e3fc5026b3cda16bd7bcc/dash_osds-marking-osds-lost.png)

**清除 OSD**

1. ​						要清除 OSD，可选择处于 *down* 状态的 OSD。 				

   1. ​								在 *Edit* 下拉菜单中选择 *Purge*。 						

   2. ​								在 *Purge OSD* 对话框中，选中 *Yes, I am sure* 选项，然后点 *Purge OSD*。 						

      图 11.11. 清除 OSD

      ![清除 OSD](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/aa6f886a75e4c09dc70ebe53392c7b04/dash_osds-purge-osds.png)

   3. ​								所有标志都已重置，并且 OSD *in* 和 *up* 状态。 						

**销毁 OSD**

1. ​						若要销毁 OSD，可选择处于 *down* 状态的 OSD。 				

   1. ​								在 *Edit* 下拉菜单中选择 *Destroy*。 						

   2. ​								在 *Destroy OSD* 对话框中，选中 *Yes, I am sure*，再点 *Destroy OSD*。 						

      图 11.12. 销毁 OSD

      ![销毁 OSD](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/c7670f3596623bcd9baeb7ea09c374d7/dash_osds-destroy-osds.png)

   3. ​								OSD 的状态变为 *destroyed*。 						

**删除 OSD**

1. ​						若要删除 OSD，可选择 OSD 处于 *down* 状态。 				

   1. ​								在 *Edit* 下拉菜单中选择 *Delete*。 						

   2. ​								在 *Destroy OSD* 对话框中，选中 *Yes*，再单击 *Delete OSD*。 						

      注意

      ​									当需要替换失败的 OSD 时，可以保留 OSD_ID。 							

      图 11.13. 删除 OSD

      ![删除 OSD](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/7d0867d96db23b36002e1ded99d459fc/dash_osds-delete-osds.png)

## 11.2. 替换 Ceph 仪表板上的故障 OSD

​				您可以将 Red Hat Ceph Storage 集群中的故障 OSD 替换为仪表板上访问的 `cluster-manager` 级别。控制面板中的这一功能的亮点之一是，在替换故障 OSD 时可以保留 OSD ID。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						至少需要 `cluster-manager` 级别访问 Ceph 控制面板。 				
- ​						至少一个 OSD 为 `down` 				

**流程**

1. ​						在仪表板中，您可以使用以下方法识别失败的 OSD： 				

   - ​								仪表板 AlertManager 弹出通知。 						

   - ​								仪表板登录页面，显示 *HEALTH_WARN* 状态。 						

   - ​								显示故障 OSD 的仪表板登录页面。 						

   - ​								显示故障 OSD 的仪表板 OSD 页面。 						

     [![OSD 的健康状况](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/5642d70c9e94e6ff7620f7b4f0e59fa9/dash_osds-health-status.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/5642d70c9e94e6ff7620f7b4f0e59fa9/dash_osds-health-status.png)

     ​								在本例中，您可以看到其中一个 OSD 在仪表板的登录页面上停机。 						

     ​								除了物理驱动器上，您还可以查看其中一个 OSD 停机时的 LED 光盘。 						

2. ​						点 *OSD*。 				

3. ​						选择 `out` 和 `down` OSD： 				

   1. ​								在 *Edit* 下拉菜单中选择 *Flags* 并选择 *No Up* 并点 *Update*。 						
   2. ​								在 *Edit* 下拉菜单中选择 *Delete*。 						
   3. ​								在 *Delete OSD* 对话框中，选择 *Preserve OSD ID for replacement* 和 *Yes, I am sure* 复选框。 						
   4. ​								点 *Delete OSD*。 						
   5. ​								等待 OSD 的状态更改为 `out` 和 `destroyed` 状态。 						

4. ​						可选： 如果要更改整个集群的 *No Up* Flag，在 *Cluster-wide 配置* 下拉菜单中选择 *Flags*。 				

   1. ​								在*集群范围的 OSD 标记*对话框中，选择 *No Up* 并点 Update。 						

5. ​						可选：如果 OSD 由于硬盘失败而停机，请替换物理驱动器： 				

   - ​								如果驱动器支持热插拔，请将失败的驱动器替换为新驱动器。 						

   - ​								如果驱动器不可热插拔并且主机包含多个 OSD，您可能需要关闭整个主机并替换物理驱动器。考虑防止集群回填。详情请参阅 *Red Hat Ceph Storage 故障排除指南中的停止和启动* [*重新平衡*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/troubleshooting_guide/#stopping-and-starting-rebalancing_diag) 章节。 						

   - ​								当驱动器出现在 `/dev/` 目录下时，请注意驱动器路径。 						

   - ​								如果要手动添加 OSD，找到 OSD 驱动器并格式化磁盘。 						

   - ​								如果新磁盘有数据，则 zap 磁盘： 						

     **语法**

     ​									

     

     ```none
     ceph orch device zap HOST_NAME PATH --force
     ```

     **示例**

     ​									

     

     ```none
     ceph orch device zap ceph-adm2 /dev/sdc --force
     ```

6. ​						在 *Create* 下拉菜单中选择 *Create*。 				

7. ​						在 *Create OSD* 窗口中，点主设备的 *+Add*。 				

   1. ​								在 *主要设备* 对话框中，从 *Hostname* 下拉列表中选择一个过滤器。从 *Any* 下拉列表中，选择对应的选项。 						

      注意

      ​									您必须首先选择 Hostname，然后至少一个过滤器来添加设备。 							

      ​								例如，从 *Hostname* 列表中选择 `Type` 和 *Any* 列表中，选择 `hdd`。选择 *Vendor* 和 from *any* 列表中，选择 `ATA` 						

      [![为 OSD 添加设备](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/23ed575890f33cedc6692a4070a99d73/dash_osds-add-device.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/23ed575890f33cedc6692a4070a99d73/dash_osds-add-device.png)

   2. ​								点击 *Add*。 						

   3. ​								在 *Create OSD 窗口* 中，点 *Preview* 按钮。 						

   4. ​								在 *OSD Creation Preview* 对话框中，单击 *Create*。 						

   5. ​								您将获得该 OSD 创建的通知。OSD 将处于 `out` 状态和 `down` 状态。 						

8. ​						选择新创建的具有 *out* 和 *down* 状态的 OSD。 				

   1. ​								在 *Edit* 下拉菜单中，选择 *Mark-in*。 						
   2. ​								在 *Mark OSD in* 窗口中，选择 *Mark in*。 						
   3. ​								在 *Edit* 下拉菜单中，选择 *Flags*。 						
   4. ​								取消选择 *No Up* 并点 *Update*。 						

9. ​						可选： 如果您在集群范围的配置前更改了 *No Up* Flag，在 *集群范围的配置*菜单中选择 *Flags*。 				

   1. ​								在*集群范围的 OSD 标记*对话框中，取消选择 *No Up* 并点 *Update*。 						

**验证**

1. ​						验证已销毁的 OSD 是否在设备上创建，并且 OSD ID 已被保留。 				

   [![OSD 已创建](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/e27612a94441ead38e8b9e50e98c14e9/dash_osds-create-verification.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/e27612a94441ead38e8b9e50e98c14e9/dash_osds-create-verification.png)

**其它资源**

- ​						有关故障 OSD 的更多信息，请参阅 *Red Hat Ceph Storage 故障排除指南中的 [\*故障 OSD\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/troubleshooting_guide/#down-osds_diag) 部分*。 				
- ​						如需了解更多帮助，请参阅  *[\*Red Hat Ceph Storage 故障排除指南中的红帽对服务的支持\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/troubleshooting_guide/#contacting-red-hat-support-for-service) 部分*。 				
- ​						如需有关系统角色的更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板上管理角色\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#management-of-roles-on-the-ceph-dashboard) 部分*。 				

# 第 12 章 使用控制面板管理 Ceph 对象网关

​			作为存储管理员，仪表板的 Ceph 对象网关功能允许您管理和监控 Ceph 对象网关。 	

​			您还可以使用控制面板创建使用安全套接字层(SSL)的 Ceph 对象网关服务。 	

​			例如，借助监控功能，您可以查看网关守护进程（如其区域名称）或 GET 和 PUT 速率的性能图形的详细信息。通过管理功能，您可以查看、创建和编辑用户和存储桶。 	

​			Ceph 对象网关功能在用户功能和 bucket 功能之间划分。 	

## 12.1. 手动将 Ceph 对象网关登录凭据添加到仪表板中

​				Red Hat Ceph Storage 控制面板可以管理 Ceph 对象网关，也称为 RADOS 网关或 RGW。使用 `cephadm` 部署 Ceph 对象网关时，会自动配置控制面板使用的 Ceph 对象网关凭据。您也可以使用 命令行界面手动将 Ceph 对象网关凭据强制到 Ceph 控制面板。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						已安装 Ceph 对象网关。 				

**流程**

1. ​						登录到 Cephadm shell： 				

   **示例**

   ​							

   

   ```none
   [root@host01 ~]# cephadm shell
   ```

2. ​						手动设置凭证： 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard set-rgw-credentials
   ```

   ​						这会为系统中的每个域创建一个 Ceph 对象网关用户，其具有 UID `dashboard`。 				

3. ​						可选：如果您在 Ceph Object Gateway `admin` API 中配置了自定义 admin 资源，则必须设置 admin 资源： 				

   **语法**

   ​							

   

   ```none
   ceph dashboard set-rgw-api-admin-resource RGW_API_ADMIN_RESOURCE
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard set-rgw-api-admin-resource admin
   Option RGW_API_ADMIN_RESOURCE updated
   ```

4. ​						可选： 如果您将 HTTPS 与自签名证书搭配使用，请在仪表板中禁用证书验证以避免拒绝的连接。 				

   ​						如果证书由未知证书颁发机构签名，或者所使用的主机名与证书中的主机名不匹配，则拒绝的连接可能会发生。 				

   **语法**

   ​							

   

   ```none
   ceph dashboard set-rgw-api-ssl-verify false
   ```

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard set-rgw-api-ssl-verify False
   Option RGW_API_SSL_VERIFY updated
   ```

5. ​						可选：如果对象网关需要很长时间来处理请求，并且仪表板运行超时，您可以设置超时值： 				

   **语法**

   ​							

   

   ```none
   ceph dashboard set-rest-requests-timeout _TIME_IN_SECONDS_
   ```

   ​						默认值为 45 秒。 				

   **示例**

   ​							

   

   ```none
   [ceph: root@host01 /]# ceph dashboard set-rest-requests-timeout 240
   ```

## 12.2. 使用控制面板通过 SSL 创建 Ceph 对象网关服务

​				安装 Red Hat Ceph Storage 集群后，您可以使用以下两种方法使用 SSL 创建 Ceph 对象网关服务： 		

- ​						使用命令行界面。 				
- ​						使用控制面板. 				

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						来自认证机构(CA)的 SSL 密钥。 				

注意

​					从与网关主机名匹配的 CA 获取 SSL 证书。红帽建议从带有 subject alternate name 字段和通配符的 CA 获取证书，用于 S3-style 子域。 			

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Services*。 				

3. ​						点 *+Create*。 				

4. ​						在 *Create Service* 窗口中，选择 `rgw` service。 				

5. ​						选择 *SSL* 并以 `.pem` 格式上传 *证书*。 				

   图 12.1. 创建 Ceph 对象网关服务

   [![创建 Ceph 对象网关服务](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/1b286443ad374ece42ff2e743530987d/dash_creating-rgw-service-on-the-dashboard.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/1b286443ad374ece42ff2e743530987d/dash_creating-rgw-service-on-the-dashboard.png)

6. ​						点 *Create Service*。 				

7. ​						检查 Ceph 对象网关服务已启动且正在运行。 				

**其它资源**

- ​						请参阅 *Red Hat Ceph Storage Object Gateway 指南中的 [\*为 Beast 配置 SSL\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/#configuring-ssl-for-beast_rgw) 部分*。 				

## 12.3. 在控制面板中为 Ceph 对象网关配置高可用性

​				`ingress` 服务为 Ceph 对象网关提供高可用性端点。您可以使用 Ceph 控制面板创建和配置 `ingress` 服务。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						最少两个 Ceph 对象网关守护进程在不同主机上运行。 				
- ​						已安装仪表板。 				
- ​						正在运行的 `rgw` 服务。 				

**流程**

1. ​						登录到仪表板。 				

2. ​						在 *Cluster* 下拉菜单中选择 *Services*。 				

3. ​						点击 *Create*。 				

4. ​						在 *Create Service* 窗口中，选择 `ingress` 服务。 				

5. ​						选择后端服务并编辑所需的参数。 				

   图 12.2. 创建 入口 服务

   ![创建 'ingress' 服务](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/5dfef3842924cab4d79f69bba162a1d4/dash_creating-ingress-service-on-the-dashboard.png)

6. ​						点 *Create Service*。 				

7. ​						您会收到成功创建 `入口` 服务的通知。 				

**其它资源**

- ​						有关 `入口` 服务的更多信息 [*，请参阅 Ceph 对象网关的高可用性*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/#high-availability-for-the-ceph-object-gateway)。 				

## 12.4. 在控制面板中管理 Ceph 对象网关用户

​				作为存储管理员，Red Hat Ceph Storage 控制面板可以查看和管理 Ceph 对象网关用户。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						已安装 Ceph 对象网关。 				
- ​						对象网关登录凭据添加到仪表板中。 				

### 12.4.1. 在控制面板中创建 Ceph 对象网关用户

​					在使用 CLI 设置凭据后，您可以在 Red Hat Ceph Storage 上创建 Ceph 对象网关用户。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							已安装 Ceph 对象网关。 					
- ​							对象网关登录凭据添加到仪表板中。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，单击 *Object Gateway*。 					

3. ​							点 *Users*，然后点 *Create*。 					

4. ​							在 *Create User* 窗口中，设置以下参数： 					

   1. ​									设置用户名、全名，并根据需要编辑最大存储桶数。 							
   2. ​									可选：设置电子邮件地址或暂停状态。 							
   3. ​									可选：通过取消选中 *Auto-generate key* 来设置自定义 access key 和 secret key。 							
   4. ​									可选：设置用户配额。 							
   5. ​									在 *User quota* 下选中 *Enabled*。 							
   6. ​									取消选择 *Unlimited size* 或 *Unlimited objects*。 							
   7. ​									输入 *Max. size* 或 *Max. objects* 所需的值。 							
   8. ​									可选：设置存储桶配额。 							
   9. ​									在 *Bucket 配额*下选中 *Enabled*。 							
   10. ​									取消选择 *Unlimited size* 或 *Unlimited objects*: 							
   11. ​									输入 *Max. size* 或 *Max. objects* 所需的值： 							

5. ​							点*创建用户*。 					

   图 12.3. 创建 Ceph 对象网关用户

   [![Ceph 对象网关创建用户](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2730ffaad9e35554f14b9f2f3a3254b8/dash_ceph-object-gateway-create-user.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2730ffaad9e35554f14b9f2f3a3254b8/dash_ceph-object-gateway-create-user.png)

6. ​							您收到用户创建成功的通知。 					

**其它资源**

- ​							如需更多信息，请参阅 Red Hat [*Ceph Storage Dashboard 指南中的手动将 Ceph 对象网关登录凭证添加到仪表板*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-ceph-object-gateway-login-credentials-to-the-dashboard_dash) 部分。 					
- ​							如需更多信息，请参阅 [*Red Hat Ceph Storage 对象网关指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/)。 					

### 12.4.2. 在控制面板中创建 Ceph 对象网关子用户

​					子用户与 S3 接口用户关联。您可以在 Red Hat Ceph Storage 仪表板中为特定的 Ceph 对象网关用户创建子用户。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							已安装 Ceph 对象网关。 					
- ​							对象网关登录凭据添加到仪表板中。 					
- ​							创建对象网关用户。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，单击 *Object Gateway*。 					

3. ​							点 *Users*。 					

4. ​							点用户行来选择该用户。 					

5. ​							在 *Edit* 下拉菜单中选择 *Edit*。 					

6. ​							在 *Edit User* 窗口中，单击 *+Create Subuser*。 					

7. ​							在 *Create Subuser* 对话框中，输入用户名并选择适当的权限。 					

8. ​							选中 *Auto-generate secret* 框，然后单击 *Create Subuser*。 					

   图 12.4. 创建 Ceph 对象网关子用户

   ![Ceph 对象网关创建子用户](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/94e5c7976c218bf0779fd9aa86ae68a3/dash_ceph-object-gateway-create-subuser.png)

   注意

   ​								通过点 *Auto-generate-secret* 复选框，对象网关的 secret 键会自动生成。 						

9. ​							在 *Edit User* 窗口中，点 *Edit user* 按钮 					

10. ​							您会收到成功更新用户的通知。 					

### 12.4.3. 在控制面板中编辑 Ceph 对象网关用户

​					在使用 CLI 设置凭据后，您可以编辑 Red Hat Ceph Storage 上的 Ceph 对象网关用户。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							已安装 Ceph 对象网关。 					
- ​							对象网关登录凭据添加到仪表板中。 					
- ​							创建了 Ceph 对象网关用户。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，单击 *Object Gateway*。 					

3. ​							点 *Users*。 					

4. ​							要编辑用户功能，请点击其行。 					

5. ​							在 *Edit* 下拉菜单中选择 *Edit*。 					

6. ​							在 *Edit User* 窗口中，编辑所需参数。 					

7. ​							点 *Edit User*。 					

   图 12.5. 编辑 Ceph 对象网关用户

   [![Ceph 对象网关编辑用户](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/7f3d565228ebcd53ae7ecec4d09eb179/dash_ceph-object-gateway-edit-user.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/7f3d565228ebcd53ae7ecec4d09eb179/dash_ceph-object-gateway-edit-user.png)

8. ​							您会收到成功更新用户的通知。 					

**其它资源**

- ​							如需更多信息，请参阅 Red Hat [*Ceph Storage Dashboard 指南中的手动将 Ceph 对象网关登录凭证添加到仪表板*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-ceph-object-gateway-login-credentials-to-the-dashboard_dash) 部分。 					
- ​							如需更多信息，请参阅 [*Red Hat Ceph Storage 对象网关指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/)。 					

### 12.4.4. 在仪表板中删除 Ceph 对象网关用户

​					在使用 CLI 设置凭据后，您可以删除 Red Hat Ceph Storage 上的 Ceph 对象网关用户。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							已安装 Ceph 对象网关。 					
- ​							对象网关登录凭据添加到仪表板中。 					
- ​							创建了 Ceph 对象网关用户。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，单击 *Object Gateway*。 					

3. ​							点 *Users*。 					

4. ​							若要删除该用户，请点其行。 					

5. ​							在 *Edit* 下拉菜单中选择 *Delete*。 					

6. ​							在 *Edit User* 窗口中，编辑所需参数。 					

7. ​							在 *Delete user* 对话框中，单击 *Yes, I am sure* 框，然后单击 *Delete User* 以保存设置： 					

   图 12.6. 删除 Ceph 对象网关用户

   ![Ceph 对象网关删除用户](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/5110ecd44d3f944fbbc5abbabafae416/dash_ceph-object-gateway-delete-user.png)

**其它资源**

- ​							如需更多信息，请参阅 Red Hat [*Ceph Storage Dashboard 指南中的手动将 Ceph 对象网关登录凭证添加到仪表板*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-ceph-object-gateway-login-credentials-to-the-dashboard_dash) 部分。 					
- ​							如需更多信息，请参阅 [*Red Hat Ceph Storage 对象网关指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/)。 					

## 12.5. 在控制面板中管理 Ceph 对象网关 bucket

​				作为存储管理员，Red Hat Ceph Storage 控制面板可以查看和管理 Ceph 对象网关 bucket。 		

**先决条件**

- ​						一个正在运行的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						已安装 Ceph 对象网关。 				
- ​						至少创建一个 Ceph 对象网关用户。 				
- ​						对象网关登录凭据添加到仪表板中。 				

### 12.5.1. 在控制面板中创建 Ceph 对象网关存储桶

​					在使用 CLI 设置凭据后，您可以在 Red Hat Ceph Storage 上创建 Ceph 对象网关存储桶。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							已安装 Ceph 对象网关。 					
- ​							对象网关登录凭据添加到仪表板中。 					
- ​							对象网关用户已创建且不暂停。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，单击 *Object Gateway*。 					

3. ​							点 *Buckets*，然后点 *Create*。 					

4. ​							在 *Create Bucket* 窗口中，输入 *Name* 的值并选择一个没有暂停的用户。选择放置目标。 					

   图 12.7. 创建 Ceph 对象网关存储桶

   [![Ceph 对象网关创建存储桶](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2c5398d8108cd6700c58091a1e049872/dash_ceph-object-gateway-create-bucket.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/2c5398d8108cd6700c58091a1e049872/dash_ceph-object-gateway-create-bucket.png)

   注意

   ​								创建时选择了存储桶的放置目标，且无法修改。 						

5. ​							可选：为存储桶中的对象启用*锁定*。只能在创建存储桶时启用锁定。启用锁定后，还必须选择锁定模式、*合规性*或*监管*以及锁定保留周期（以天或年为单位）。 					

6. ​							可选：启用 *Security* 来加密存储桶中的对象。要在存储桶上启用加密，您需要为 SSE-S3 设置配置值。 					

   1. ​									要设置配置值，将光标悬停在问号上，然后单击 *Click here*。 							

   2. ​									在 *Update RGW Encryption Configuration* 窗口中，选择 `SSE-S3` 作为 *Encryption Type*，提供所需的详情，然后点 *Submit*。 							

      图 12.8. 加密存储桶中的对象

      ![Ceph 对象网关加密对象](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/1d3b81e305dd792a02dc07c5fa0e5dda/dash_ceph-object-gateway-encrypt-object.png)

      注意

      ​										在使用 `SSE-S3` 加密类型时，Ceph 管理用户存储在密码库中的加密密钥。 								

7. ​							点 *Create bucket*。 					

8. ​							您将获得一个成功创建存储桶的通知。 					

### 12.5.2. 在控制面板中编辑 Ceph 对象网关存储桶

​					在使用 CLI 设置凭据后，您可以编辑 Red Hat Ceph Storage 上的 Ceph 对象网关存储桶。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							已安装 Ceph 对象网关。 					
- ​							对象网关登录凭据添加到仪表板中。 					
- ​							对象网关用户已创建且不暂停。 					
- ​							创建 Ceph 对象网关 bucket。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，单击 *Object Gateway*。 					

3. ​							点 *Buckets*。 					

4. ​							要编辑存储桶，请点击它所在的行。 					

5. ​							从 *Edit* 下拉菜单中选择 *Edit*。 					

6. ​							在 *Edit bucket* 窗口中，从下拉菜单选择该用户来编辑*所有者*。 					

   图 12.9. 编辑 Ceph 对象网关存储桶

   [![Ceph 对象网关编辑存储桶](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/941737967704321ef770012be8779f0e/dash_ceph-object-gateway-edit-bucket.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/941737967704321ef770012be8779f0e/dash_ceph-object-gateway-edit-bucket.png)

   1. ​									可选：启用 *Versioning*，如果要为现有存储桶中的所有对象启用版本控制状态。 							

      - ​											要启用版本控制，您必须是存储桶的所有者。 									
      - ​											如果在创建存储桶的过程中启用了*锁定*，则无法禁用版本控制。 									
      - ​											添加到存储桶的所有对象都将接收唯一的版本 ID。 									
      - ​											如果存储桶中没有设置 versioning 状态，则存储桶将没有版本控制状态。 									

   2. ​									可选：为 *Multi-Factor Authentication*. 选中 *Delete enabled*。多因素身份验证(MFA)确保在删除特定存储桶上的对象时，需要使用一次性密码(OTP)。为 *Token Serial Number* 和 *Token PIN* 输入一个值。 							

      注意

      ​										bucket 必须配置有版本控制和 MFA，才能通过 S3 API 进行。 								

7. ​							点 *Edit Bucket*。 					

8. ​							您会收到成功更新存储桶的通知。 					

### 12.5.3. 删除仪表板上的 Ceph 对象网关存储桶

​					在使用 CLI 设置凭据后，您可以删除 Red Hat Ceph Storage 上的 Ceph 对象网关存储桶。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							已安装 Ceph 对象网关。 					
- ​							对象网关登录凭据添加到仪表板中。 					
- ​							对象网关用户已创建且不暂停。 					
- ​							创建 Ceph 对象网关 bucket。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，单击 *Object Gateway*。 					

3. ​							点 *Buckets*。 					

4. ​							要删除存储桶，可点它的行。 					

5. ​							从 *Edit* 下拉菜单中选择 *Delete*。 					

6. ​							在 *Delete Bucket* 对话框中，点击 *Yes, I am sure* 框，然后单击 *Delete bucket* 以保存设置： 					

   图 12.10. 删除 Ceph 对象网关存储桶

   ![Ceph 对象网关删除存储桶](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/cb67f6e7df36bd0c7c5236f85808f533/dash_ceph-object-gateway-delete-bucket.png)

## 12.6. 在 Ceph 仪表板上监控多站点对象网关配置

​				Red Hat Ceph Storage 仪表板支持监控多站点对象网关配置中某个区域的用户和 bucket。例如，如果在主站点的区域中创建了用户和存储桶，您可以在次要站点的二级区域中监控这些用户和 bucket。 		

**先决条件**

- ​						至少在运行两个站点上部署的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						多站点对象网关是在主站点和从属站点上配置的。 				
- ​						主站点和次要站点的对象网关登录凭据添加到仪表板中。 				
- ​						在主站点上创建对象网关用户。 				
- ​						对象网关 bucket 在主站点创建。 				

**流程**

1. ​						在二级站点的 Dashboard 登录页面中，在垂直菜单栏中点击 *Object Gateway* 下拉列表。 				

2. ​						选择 *Buckets*。 				

3. ​						您可以在为主站点上的对象网关用户创建的二级登录页面上看到这些对象网关存储桶。 				

   图 12.11. 多站点对象网关监控

   [![多站点对象网关监控](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f688ec6bbf3e31edebed507c44a214f5/dash_multisite-object-gateway-monitoring.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f688ec6bbf3e31edebed507c44a214f5/dash_multisite-object-gateway-monitoring.png)

**其它资源**

- ​						有关配置多站点的更多信息，请参阅 *Red Hat Ceph Storage Object Gateway* [*指南中的多站点配置和管理*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/#multisite-configuration-and-administration) 部分。 				
- ​						有关在仪表板中添加对象网关登录凭证的更多信息，请参阅 *Red Hat [\*Ceph Storage Dashboard\*指南中的手动将 Ceph 对象网关登录凭证添加到仪表板](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-ceph-object-gateway-login-credentials-to-the-dashboard_dash)*  部分。 				
- ​						有关在控制面板上创建对象网关用户的更多信息，请参阅 *Red Hat [\*Ceph Storage Dashboard\*指南中的在仪表板上创建 Ceph 对象网关用户](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-users-on-the-dashboard_dash)*  部分。 				
- ​						有关在控制面板上创建对象网关存储桶的更多信息，请参阅 *Red Hat [\*Ceph\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-buckets-on-the-dashboard_dash) Storage Dashboard* 指南中的在仪表板上创建 Ceph 对象网关存储桶部分。 				

## 12.7. 在 Ceph 仪表板上管理多站点对象配置的存储桶

​				作为存储管理员，您可以在 Red Hat Ceph Storage Dashboard  的另一个区中编辑一个区域的存储桶。但是，您可以删除主站点中的次要站点的存储桶。您不能删除其他站点中主站点的 master  区域的存储桶。例如，如果在二级站点的区域中创建存储桶，您可以在主站点的 master zone 中编辑和删除这些存储桶。 		

**先决条件**

- ​						至少在运行两个站点上部署的 Red Hat Ceph Storage 集群。 				
- ​						已安装仪表板。 				
- ​						多站点对象网关是在主站点和从属站点上配置的。 				
- ​						主站点和次要站点的对象网关登录凭据添加到仪表板中。 				
- ​						在主站点上创建对象网关用户。 				
- ​						对象网关 bucket 在主站点创建。 				
- ​						Ceph 控制面板中至少具有 `rgw-manager` 的访问权限级别。 				

### 12.7.1. 监控多站点对象的存储桶

​					在控制面板中监控 bucket 的多站点同步状态。您可以从 **Object Storage → Overview** 页面中的 **Multi-site sync status** 卡查看源区域和同步状态。 			

​					多站点同步状态分为两个部分： 			

- 主源区域

  ​								显示 Ceph 对象网关连接到的默认域、zonegroup 和区域。 						

- 源区

  ​								查看元数据同步状态和数据同步信息进度。当您点状态时，会显示分片同步的分类。同步状态显示 **Last Synced** 时间戳，与当前时间相关的最后一次同步发生的时间。同步完成后，这会显示为 **Up to Date**。当无法捕获同步状态时，其状态显示为 `Syncing`。``但是，`Last sync` 显示同步的天数。通过单击 `Syncing`，它会显示有关未同步的分片的详细信息。 						

### 12.7.2. 在 Ceph 仪表板上编辑多站点对象网关配置的存储桶

​					您可以在多站点对象网关配置中，在 Red Hat Ceph Storage Dashboard 的另一个区中编辑和更新一个区域的存储桶详情。您可以使用控制面板的此功能编辑存储桶的所有者、版本、多因素身份验证和锁定功能。 			

**先决条件**

- ​							至少在运行两个站点上部署的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							多站点对象网关是在主站点和从属站点上配置的。 					
- ​							主站点和次要站点的对象网关登录凭据添加到仪表板中。 					
- ​							在主站点上创建对象网关用户。 					
- ​							对象网关 bucket 在主站点创建。 					
- ​							Ceph 控制面板中至少具有 `rgw-manager` 的访问权限级别。 					

**流程**

1. ​							在二级站点的 Dashboard 登录页面中，在垂直菜单栏中点击 *Object Gateway* 下拉列表。 					

2. ​							选择 *Buckets*。 					

3. ​							您可以在为主站点上的对象网关用户创建的二级登录页面上看到这些对象网关存储桶。 					

   图 12.12. 监控对象网关监控

   [![多站点对象网关监控](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f688ec6bbf3e31edebed507c44a214f5/dash_multisite-object-gateway-monitoring.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f688ec6bbf3e31edebed507c44a214f5/dash_multisite-object-gateway-monitoring.png)

4. ​							点您要编辑的存储桶行。 					

5. ​							在 *Edit* 下拉菜单中选择 *Edit*。 					

6. ​							在 *Edit Bucket* 窗口中，编辑所需的参数并点 *Edit Bucket*。 					

   图 12.13. 编辑多站点中的存储桶

   [![编辑多站点中的存储桶](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/8d7a72f698e1ac01bcd66e51774b6c4b/dash_multisite-object-gateway-edit-buckets.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/8d7a72f698e1ac01bcd66e51774b6c4b/dash_multisite-object-gateway-edit-buckets.png)

**验证**

- ​							您将收到成功更新存储桶的通知。 					

**其它资源**

- ​							有关在仪表板中添加对象网关登录凭证的更多信息，请参阅 *Red Hat [\*Ceph Storage Dashboard\*指南中的手动将 Ceph 对象网关登录凭证添加到 Ceph 仪表板](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-ceph-object-gateway-login-credentials-to-the-dashboard_dash)*  部分。 					
- ​							有关在控制面板上创建对象网关用户的更多信息，请参阅 *Red Hat [\*Ceph Storage Dashboard\*指南中的 Ceph 仪表板上创建 Ceph 对象网关用户](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-users-on-the-dashboard_dash)*  部分。 					
- ​							有关在控制面板上创建对象网关存储桶的更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-ceph-object-gateway-buckets-on-the-dashboard_dash) Ceph 对象网关存储桶* 部分。 					
- ​							如需有关系统角色的更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板上管理角色\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#management-of-roles-on-the-ceph-dashboard) 部分*。 					

### 12.7.3. 在 Ceph 仪表板上删除多站点对象网关配置的存储桶

​					您可以在多站点对象网关配置中，在 Red Hat Ceph Storage Dashboard 上的主站点中删除二级站点的存储桶。 			

​					重要信息：红帽不推荐从二级站点中删除主站点的存储桶。 			

**先决条件**

- ​							至少在运行两个站点上部署的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							多站点对象网关是在主站点和从属站点上配置的。 					
- ​							主站点和次要站点的对象网关登录凭据添加到仪表板中。 					
- ​							在主站点上创建对象网关用户。 					
- ​							对象网关 bucket 在主站点创建。 					
- ​							Ceph 控制面板中至少具有 `rgw-manager` 的访问权限级别。 					

**流程**

1. ​							在主要站点的 Dashboard 登录页面中，单击垂直菜单栏中的 *Object Gateway* 下拉列表。 					
2. ​							选择 *Buckets*。 					
3. ​							您可以在此处看到二级站点中的这些对象网关存储桶。 					
4. ​							点您要删除的存储桶行。 					
5. ​							在 *Edit* 下拉菜单中选择 *Delete*。 					
6. ​							在 *Delete Bucket* 对话框中，选择 *Yes, I am sure*，再单击 *Delete Bucket* 复选框。 					

**验证**

- ​							所选存储桶所在的行被成功删除。 					

**其它资源**

- ​							有关配置多站点的更多信息，请参阅 *Red Hat Ceph Storage Object Gateway* [*指南中的多站点配置和管理*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/object_gateway_guide/#multisite-configuration-and-administration) 部分。 					
- ​							有关在仪表板中添加对象网关登录凭证的更多信息，请参阅 *Red Hat Ceph Storage Dashboard* 指南中的 [*手动将对象网关登录凭证添加到 Ceph 仪表板*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#manually-adding-object-gateway-login-credentials-to-the-ceph-dashboard_dash) 部分。 					
- ​							有关在控制面板上创建对象网关用户的更多信息，请参阅 *Red Hat Ceph Storage Dashboard* 指南中的 [*Ceph 仪表板上创建对象网关用户*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-object-gateway-users-on-the-ceph-dashboard_dash) 部分。 					
- ​							有关在控制面板上创建对象网关存储桶的更多信息，请参阅 *Red Hat Ceph Storage Dashboard* 指南中的 [*Ceph 仪表板上创建对象网关存储桶*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-object-gateway-buckets-on-the-ceph-dashboard_dash) 部分。 					
- ​							如需有关系统角色的更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的 Ceph 仪表板上的系统角色\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#system-roles-on-the-ceph-dashboard_dash) 部分*。 					

## 12.8. 在 Ceph 仪表板上配置多站点对象网关

​				您可以在 Red Hat Ceph Storage Dashboard 上配置 Ceph 对象网关多站点。 		

**先决条件**

- ​						在两个站点上部署的 Red Hat Ceph Storage 集群。 				
- ​						在两个站点上至少安装了一个 Ceph 对象网关服务。 				

**流程**

1. ​						在两个站点上启用 Ceph 对象网关模块，以启用导入/导出功能。 				

   1. ​								在仪表板登录页面上，单击 *Object Gateway*，然后单击 *Multisite*。 						
   2. ​								在 *Information* 框中，单击 *Enable RGW Module*。 						

2. ​						在主站点仪表板上，创建一个默认的 realm、zonegroup 和 zone。 				

   1. ​								从 *Create Realm* 下拉菜单中，选择 *Create Realm*。 						

   2. ​								在 *Create Realm* 对话框中，提供 realm 名称，然后选择 *Default*。 						

   3. ​								单击 *Create Realm*。 						

   4. ​								从 *Create Realm* 下拉菜单中，选择 Create *Zonegroup*。 						

   5. ​								在 *Create Zonegroup* 对话框中，提供 zonegroup 名称，即 Ceph 对象网关端点，然后选择 *Default*。 						

   6. ​								单击 *Create Zonegroup*。 						

   7. ​								从 *Create Realm* 下拉菜单中，选择 *Create Zone*。 						

   8. ​								在 *Create Zone* 对话框中，提供 *Zone Name*，选择 *Default*，并提供主站点的 Ceph 对象网关端点。对于用户，为用户提供系统特权的 access 和 secret key。 						

      注意

      ​									在创建区时，红帽建议提供仪表板默认用户 `dashboard` 的访问密钥和 secret 密钥。 							

3. ​						创建区域后，您将收到一个警告，以重新启动 Ceph 对象网关服务。 				

   1. ​								点 *Cluster*，然后点 *Services*。 						
   2. ​								选择 Ceph 对象网关服务行。 						
   3. ​								选择 *Hostname* 下的行。 						
   4. ​								在 *Start* 下拉菜单中选择 *Restart*。 						

4. ​						当您单击 *Object Gateway* 时，您会收到"对象网关服务未配置"的错误。这个程序错误是一个已知问题。请参阅 [BZ#2231072](https://bugzilla.redhat.com/show_bug.cgi?id=2231072)。 				

   1. ​								作为临时解决方案，请在命令行界面中设置 Ceph 对象网关凭证。 						

      **语法**

      ​									

      

      ```none
      ceph dashboard set-rgw-credentials
      RGW credentials configured
      ```

   2. ​								单击 *Object Gateway*，以验证您可以通过控制面板上访问 Ceph 对象网关。 						

5. ​						在主站点上创建复制用户。您可以使用以下两个选项： 				

   - ​								使用 CLI 创建用户： 						

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# radosgw-admin user create --uid="uid" --display-name="displayname" --system
     ```

   - ​								从仪表板创建用户，并通过 CLI 修改用户： 						

     **示例**

     ​									

     

     ```none
     [ceph: root@host01 /]# radosgw-admin user modify --uid="uid" --system
     ```

6. ​						在 *Object Gateway* 下，单击 *Users*，再单击上一步中创建的用户行。 				

   1. ​								复制 *Access Key* 和 *Secret Key*。 						
   2. ​								在 *Object Gateway* 下，单击 *Multisite*，然后选择 区域。 						
   3. ​								点编辑图标，粘贴之前复制的访问密钥和 secret 密钥。 						
   4. ​								单击 *Edit Zone*。 						

7. ​						单击 *Export*。 				

   1. ​								在 *Export Multi-site Realm Token* 对话框中复制令牌。 						
   2. ​								关闭对话框。 						

8. ​						在次要站点仪表板上，在 *Object Gateway* 下点 *Multisite*。 				

9. ​						点 *Import* 从主区导入令牌。 				

10. ​						在 *Import Multi-site Token* 对话框中，在 *Zone* details 下粘贴之前复制的令牌，并提供二级区域名称。 				

    1. ​								在 *Service* details 下，选择创建新 Ceph 对象网关服务的放置和端口。 						
    2. ​								点 *Import*。 						

11. ​						导入令牌后，您会收到重启 Ceph 对象网关服务的警告。 				

    1. ​								单击 *Cluster*，然后单击 *Services*。 						
    2. ​								选择 Ceph 对象网关服务行。 						
    3. ​								选择 *Hostname* 下的行。您可以看到在次要站点上配置 Ceph 对象网关。 						
    4. ​								在 *Start* 下拉菜单中选择 *Restart*。 						

12. ​						您需要等待一些时间将用户同步到次要站点。使用以下命令验证同步是否已完成： 				

    **示例**

    ​							

    

    ```none
    [ceph: root@host01 /]# radosgw-admin sync status
    [ceph: root@host01 /]# radosgw-admin user list
    ```

13. ​						在辅助站点仪表板上，在 *Object Gateway* 下收到一个错误，"对象网关服务没有被配置"。这个程序错误是一个已知问题。请参阅 [BZ#2231072](https://bugzilla.redhat.com/show_bug.cgi?id=2231072)。 				

    1. ​								作为临时解决方案，请在命令行界面中设置 Ceph 对象网关凭证。 						

       **语法**

       ​									

       

       ```none
       ceph dashboard set-rgw-credentials
       RGW credentials configured
       ```

    2. ​								单击 *Object Gateway*，以验证您可以通过控制面板上访问 Ceph 对象网关。 						

14. ​						在主站点的 *多站点同步状态* 下，您会收到错误。这是因为在 second zone 上，您可以看到端点是主机名，而不是 IP 地址。在配置多站点时，这个程序错误是一个已知问题。请参阅 [BZ#2242994](https://bugzilla.redhat.com/show_bug.cgi?id=2242994)。 				

    1. ​								作为临时解决方案，在第二个站点（在 *Object Gateway* 下），点 *Multisite*，然后选择 second zone。 						
    2. ​								编辑端点以反映 IP 地址。 						
    3. ​								单击 *Edit Zone*。 						

15. ​						在主站点和次要站点仪表板的 *Object Gateway* 下，您可以看到 Multisite *Sync 状态*。 				

    [![多站点同步状态](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3fd8bd78e55f789aac4d482e68d7aca6/dash_multi-site-sync-status.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3fd8bd78e55f789aac4d482e68d7aca6/dash_multi-site-sync-status.png)

**验证**

- ​						在主站点上创建用户。您会看到用户与二级站点同步。 				

# 第 13 章 使用 Ceph 仪表板管理块设备

​			作为存储管理员，您可以在 Red Hat Ceph Storage 仪表板中管理和监控块设备镜像。这个功能在通用镜像功能和镜像功能之间划分。例如，您可以创建新镜像，查看集群中镜像的镜像状态，以及设置镜像的 IOPS 限制。 	

## 13.1. 在 Ceph 仪表板上管理块设备镜像

​				作为存储管理员，您可以使用 Red Hat Ceph Storage 仪表板创建、编辑、复制、清除和删除镜像。 		

​				您还可以使用 Ceph 控制面板创建、克隆、复制、回滚和删除镜像的快照。 		

### 13.1.1. 在 Ceph 仪表板上创建镜像

​					您可以在 Red Hat Ceph Storage 仪表板中创建块设备镜像。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					

**流程**

1. ​							登录控制面板。 					

2. ​							在导航菜单中点 *Block* 下拉菜单。 					

3. ​							选择*镜像*。 					

4. ​							点击 *Create*。 					

5. ​							在 *Create RBD* 窗口中，输入参数。 					

6. ​							可选：点 *Advanced* 并设置参数。 					

7. ​							点 *Create RBD*。 					

8. ​							创建块设备镜像。 					

   图 13.1. 创建块设备镜像

   [![创建块设备镜像](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/63cab4e0f7ca316e56b662c317019a5f/dash_images-create-image.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/63cab4e0f7ca316e56b662c317019a5f/dash_images-create-image.png)

9. ​							您会收到成功创建镜像的通知。 					

**其它资源**

- ​							有关镜像的更多信息，请参阅 [*Red Hat Ceph Storage 块设备指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/)。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建池](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-pools-on-the-ceph-dashboard_dash)*  部分。 					

### 13.1.2. 在 Ceph 仪表板上创建命名空间

​					您可以在 Red Hat Ceph Storage 仪表板中为块设备镜像创建命名空间。 			

​					创建命名空间后，您可以为这些命名空间授予用户访问权限。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block* 下拉菜单。 					

3. ​							选择*镜像*。 					

4. ​							要创建命名空间，在 *Namespaces* 选项卡中点 *Create*。 					

5. ​							在 *Create Namespace* 窗口中，选择池并为命名空间输入一个名称。 					

6. ​							点击 *Create*。 					

   图 13.2. 创建命名空间

   ![创建命名空间](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/51f56a72abfbaf6911dd3698853f9ec8/dash_images-create-namespace.png)

7. ​							您会看到一个成功创建命名空间的通知。 					

**其它资源**

- ​							如需了解更多详细信息，请参阅知识库文章[*隔离命名空间中的 Segregate Block device 镜像*](https://access.redhat.com/solutions/4872331)。 					

### 13.1.3. 在 Ceph 仪表板上编辑镜像

​					您可以在 Red Hat Ceph Storage 仪表板上编辑块设备镜像。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，点 *Block* 下拉菜单。 					

3. ​							选择*镜像*。 					

4. ​							要编辑镜像，请点其行。 					

5. ​							在 *Edit* 下拉菜单中，选择 *Edit*。 					

6. ​							在 *Edit RBD* 窗口中，编辑所需的参数，再点 *Edit RBD*。 					

   图 13.3. 编辑块设备镜像

   [![编辑块设备镜像](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/670dc87d5d014b9777fac0bbd14ef32f/dash_images-edit-image.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/670dc87d5d014b9777fac0bbd14ef32f/dash_images-edit-image.png)

7. ​							您会收到成功更新镜像的通知。 					

**其它资源**

- ​							有关镜像的更多信息，请参阅 [*Red Hat Ceph Storage 块设备指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/)。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建池](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-pools-on-the-ceph-dashboard_dash)*  部分。 					

### 13.1.4. 在 Ceph 仪表板上复制镜像

​					您可以在 Red Hat Ceph Storage 仪表板中复制块设备镜像。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，点 *Block* 下拉菜单。 					

3. ​							选择*镜像*。 					

4. ​							要复制镜像，请点击其行。 					

5. ​							在 *Edit* 下拉菜单中，选择 *Copy*。 					

6. ​							在 *Copy RBD* 窗口中，设置所需的参数，再点 *Copy RBD*。 					

   图 13.4. 复制块设备镜像

   [![复制块设备镜像](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f626c5e8ccdcee0330191730e2848a18/dash_images-copy-image.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f626c5e8ccdcee0330191730e2848a18/dash_images-copy-image.png)

7. ​							您会收到成功复制镜像的通知。 					

**其它资源**

- ​							有关镜像的更多信息，请参阅 [*Red Hat Ceph Storage 块设备指南*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/)。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中创建池](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-pools-on-the-ceph-dashboard_dash)*  部分。 					

### 13.1.5. 将镜像移到 Ceph 控制面板的垃圾箱

​					您可以将块设备镜像移到回收站，然后才能在 Red Hat Ceph Storage 仪表板中删除。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							从下拉菜单中选择 *Images*。 					

4. ​							要将镜像移动到回收站，请点其行。 					

5. ​							在 *Edit* 下拉菜单中选择 *Move to Trash*。 					

6. ​							在 *Moving a images to trash* 窗口中，编辑镜像需要保护的日期，然后点 *Move*。 					

   图 13.5. 将镜像移动到回收站

   ![将镜像移动到回收站](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/f36e1e23700f81266307e91b84386f8e/dash_images-moving-image-to-trash.png)

7. ​							您会得到一个成功迁移到垃圾箱的通知。 					

### 13.1.6. 在 Ceph 仪表板上清除垃圾箱

​					您可以使用 Red Hat Ceph Storage 控制面板清除垃圾箱。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							镜像被回收。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中，点 *Block* ： 					

3. ​							选择*镜像*。 					

4. ​							在 *Trash* 选项卡中，单击 *Purge Trash*。 					

5. ​							在 *Purge Trash* 窗口中，选择池，然后单击*清除垃圾箱*。 					

   图 13.6. 清除垃圾箱

   ![清除垃圾箱](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/7ba10f36774e0b1db9b473cd5c84e5f8/dash_image-purge-trash.png)

6. ​							您会收到一个通知，提示回收站中的池被成功清除。 					

**其它资源**

- ​							如需了解更多详细信息 [*，请参阅 \*Red Hat Ceph Storage 块设备指南中的\* 清除*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#purging-the-block-device-snapshots_block) 块设备快照部分。 					

### 13.1.7. 在 Ceph 仪表板中从回收中恢复镜像

​					您可以恢复已回收的镜像，并在 Red Hat Ceph Storage Dashboard 上有到期日期。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							镜像被回收。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block* ： 					

3. ​							选择*镜像*。 					

4. ​							要从 *Trash* 选项卡中恢复镜像，点其行： 					

5. ​							在 *Restore* 下拉列表中选择 *Restore*。 					

6. ​							在 *Restore Image* 窗口中，输入镜像的新名称，然后点 *Restore*。 					

   图 13.7. 从回收站中恢复镜像

   ![从回收站中恢复镜像](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/eb819a59f949a6cc8c4b63d6e084b64a/dash_image-restore-images-from-trash.png)

7. ​							您会收到成功恢复镜像的通知。 					

**其它资源**

- ​							如需有关在 RBD [*池中创建镜像的*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-images-on-the-ceph-dashboard_dash) 更多详细信息，请参阅 *Red Hat Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建镜像部分*。 					

### 13.1.8. 删除 Ceph 仪表板中的镜像

​					您可以在 Ceph Dashboard 上从集群中删除镜像。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中点 *Block* 					

3. ​							选择*镜像*。 					

4. ​							要删除镜像，请选择行。 					

5. ​							在 *Edit* 下拉菜单中，选择 *Delete*。 					

6. ​							在 *Delete RBD* 对话框中，单击 *Yes, I am sure* 框，然后单击 *Delete RBD* 以保存设置。 					

   图 13.8. 删除镜像

   ![删除镜像](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/c29d71844223b3cef366f8ce708a55a5/dash_image-deleting-images.png)

7. ​							您会收到成功删除镜像的通知。 					

**其它资源**

- ​							有关在 RBD 池中创建镜像的更多详细信息，请参阅 *Red Hat Ceph Storage Dashboard Guide* 中的 [*Moving images to trash on the Ceph dashboard*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#moving-images-to-trash-on-the-ceph-dashboard_dash) 部分。 					

### 13.1.9. 删除 Ceph 仪表板上的命名空间。

​					您可以在 Red Hat Ceph Storage Dashboard 中删除镜像的命名空间。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							在池中创建一个命名空间。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航栏中点 *Block* 					

3. ​							选择*镜像*。 					

4. ​							要删除命名空间，在 *Namespaces* 选项卡中点其行。 					

5. ​							点击 *Delete*。 					

6. ​							在 *Delete Namespace* 对话框中，点 *Yes, I am sure* 框，然后点击 *Delete Namespace* 保存设置： 					

   图 13.9. 删除命名空间

   ![删除命名空间](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/80c0baedf07e93f2c61366ab254b3f55/dash_image-deleting-namespaces.png)

7. ​							您会收到成功删除命名空间的通知。 					

### 13.1.10. 在 Ceph 仪表板中创建镜像快照

​					您可以在 Red Hat Ceph Storage Dashboard 上获取 Ceph 块设备镜像的快照。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							选择*镜像*。 					

4. ​							要生成镜像的快照，请在 *Images* 选项卡中点其行，然后点 *Snapshots* 选项卡。 					

5. ​							在 *Create* 下拉菜单中选择 *Create*。 					

6. ​							在 *Create RBD Snapshot* 对话框中，输入名称，再点 *Create RBD Snapshot* ： 					

   图 13.10. 创建镜像快照

   ![创建镜像快照](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/15a3e1a99181a028db6cf3a3d0192f19/dash_images-snapshot-create.png)

7. ​							您会收到成功创建快照的通知。 					

**其它资源**

- ​							有关 [*创建快照的更多信息，请参阅 \*Red Hat Ceph Storage 块设备指南中的\* 创建块设备快照*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#creating-a-block-device-snapshot_block) 部分。 					
- ​							有关创建 RBD [*池的更多详细信息，*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-pools-on-the-ceph-dashboard_dash) 请参阅 *Red Hat Ceph Storage Dashboard 指南中的* 在 Ceph 仪表板中创建池部分。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建镜像部分*。 https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-images-on-the-ceph-dashboard_dash 					

### 13.1.11. 在 Ceph 仪表板中重命名镜像的快照

​					您可以在 Red Hat Ceph Storage Dashboard 上重命名 Ceph 块设备镜像的快照。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							创建镜像的快照。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							选择*镜像*。 					

4. ​							要重命名镜像的快照，请在 *Images* 选项卡中点击其行，然后单击 *Snapshots* 选项卡。 					

5. ​							在 *Rename* 下拉列表中选择 *Rename*。 					

6. ​							在 *Rename RBD Snapshot* 对话框中，输入名称，再点 *Rename RBD Snapshot* ： 					

   图 13.11. 重命名镜像快照

   ![重命名镜像快照](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/48cb1f72b38e14f72df064fde72dce55/dash_images-snapshot-rename.png)

**其它资源**

- ​							如需更多信息 [*，请参阅 \*Red Hat Ceph Storage 块设备指南中的\*重命名*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#renaming-a-block-device-snapshot_block) 块设备快照部分。 					
- ​							有关创建 RBD [*池的更多详细信息，*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-pools-on-the-ceph-dashboard_dash) 请参阅 *Red Hat Ceph Storage Dashboard 指南中的* 在 Ceph 仪表板中创建池部分。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建镜像部分*。 https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-images-on-the-ceph-dashboard_dash 					

### 13.1.12. 保护 Ceph 仪表板上的镜像快照

​					您可以在 Red Hat Ceph Storage Dashboard 上保护 Ceph 块设备镜像的快照。 			

​					当您需要克隆快照时，需要这样做。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							创建镜像的快照。 					

**流程**

1. ​							登录到仪表板。 					
2. ​							在导航菜单中点 *Block*。 					
3. ​							选择*镜像*。 					
4. ​							要保护镜像的快照，请在 *Images* 选项卡中点击其行，然后点 *Snapshots* 选项卡。 					
5. ​							在 *Rename* 下拉列表中选择 *Protect*。 					
6. ​							快照的*状态*从 *UNPROTECTED* 变为 *PROTECTED*。 					

**其它资源**

- ​							如需更多信息 [*，*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#protecting-a-block-device-snapshot_block) 请参阅 *Red Hat Ceph Storage 块设备指南中的保护块设备快照部分*。 					

### 13.1.13. 在 Ceph 仪表板中克隆镜像的快照

​					您可以在 Red Hat Ceph Storage Dashboard 上克隆镜像的快照。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							镜像的快照会被创建和保护。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							选择*镜像*。 					

4. ​							要保护镜像的快照，请在 *Images* 选项卡中点击其行，然后点 *Snapshots* 选项卡。 					

5. ​							在 *Rename* 下拉菜单中选择 *Clone*。 					

6. ​							在 *Clone RBD* 窗口中，编辑参数，再点 *Clone RBD*。 					

   图 13.12. 克隆镜像的快照

   [![克隆镜像的快照](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/d80c04194548b67f1eede97f38dc9ca7/dash_images-snapshot-clone.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/d80c04194548b67f1eede97f38dc9ca7/dash_images-snapshot-clone.png)

7. ​							您会收到成功克隆快照的通知。您可以在 *Images* 选项卡中搜索克隆的镜像。 					

**其它资源**

- ​							如需更多信息 [*，*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#protecting-a-block-device-snapshot_block) 请参阅 *Red Hat Ceph Storage 块设备指南中的保护块设备快照部分*。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage Dashboard 指南中的\*保护镜像快照](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#protecting-snapshots-of-images-on-the-ceph-dashboard_dash)*  部分。 					

### 13.1.14. 在 Ceph 仪表板中复制镜像的快照

​					您可以在 Red Hat Ceph Storage Dashboard 上复制镜像的快照。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							创建镜像的快照。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							选择*镜像*。 					

4. ​							要保护镜像的快照，请在 *Images* 选项卡中点击其行，然后点 *Snapshots* 选项卡。 					

5. ​							在 *Rename* 下拉菜单中选择 *Copy*。 					

6. ​							在 *Copy RBD* 窗口中，输入参数并点 *Copy RBD* 按钮： 					

   图 13.13. 复制镜像快照

   [![复制镜像快照](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/fb9f048013d9a88a12360fe71779eedb/dash_images-snapshot-copy.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/fb9f048013d9a88a12360fe71779eedb/dash_images-snapshot-copy.png)

7. ​							您会收到成功复制快照的通知。您可以在 *Images* 选项卡中搜索复制的镜像。 					

**其它资源**

- ​							有关创建 RBD [*池的更多详细信息，*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-pools-on-the-ceph-dashboard_dash) 请参阅 *Red Hat Ceph Storage Dashboard 指南中的* 在 Ceph 仪表板中创建池部分。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建镜像部分*。 https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-images-on-the-ceph-dashboard_dash 					

### 13.1.15. 在 Ceph 仪表板中取消保护镜像的快照

​					您可以在 Red Hat Ceph Storage Dashboard 上取消保护 Ceph 块设备镜像的快照。 			

​					当您需要删除快照时需要这样做。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							镜像的快照会被创建和保护。 					

**流程**

1. ​							登录到仪表板。 					
2. ​							在导航菜单中点 *Block*。 					
3. ​							选择*镜像*。 					
4. ​							要取消保护镜像的快照，在 *Images* 选项卡中单击其行，然后点 *Snapshots* 选项卡。 					
5. ​							在 *Rename* 下拉菜单中选择 *UnProtect*。 					
6. ​							快照的*状态*从 *PROTECTED* 变为 *UNPROTECTED*。 					

**其它资源**

- ​							如需更多信息，请参阅 *Red Hat Ceph Storage 块设备指南中的* [*取消保护块设备快照*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#unprotecting-a-block-device-snapshot_block) 部分。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage Dashboard 指南中的\*保护镜像快照](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#protecting-snapshots-of-images-on-the-ceph-dashboard_dash)*  部分。 					

### 13.1.16. 在 Ceph 仪表板上回滚镜像快照

​					您可以在 Red Hat Ceph Storage Dashboard 上回滚 Ceph  块设备镜像的快照。将镜像回滚到快照意味着使用快照中的数据覆盖镜像的当前版本。执行回滚所需的时间会随着镜像大小的增加而增加。从快照克隆要快于将镜像回滚到快照，而这是返回到预先存在的状态的首选方法。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							创建镜像的快照。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							选择*镜像*。 					

4. ​							要回滚镜像的快照，请在 *Images* 选项卡中点击其行，然后点 *Snapshots* 选项卡。 					

5. ​							在 *Rename* 下拉列表中选择 *Rollback*。 					

6. ​							在 *RBD 快照回滚*对话框中，点 *Rollback*。 					

   图 13.14. 镜像的回滚快照

   ![镜像的回滚快照](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/72c82f44ecba55dc51b646ad33285755/dash_images-snapshot-rollback.png)

**其它资源**

- ​							如需更多信息，请参阅 *Red Hat Ceph Storage 块设备指南中的* [*Rolling a block device snapshot*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#rolling-back-a-block-device-snapshot_block) 部分。 					
- ​							有关创建 RBD [*池的更多详细信息，*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-pools-on-the-ceph-dashboard_dash) 请参阅 *Red Hat Ceph Storage Dashboard 指南中的* 在 Ceph 仪表板中创建池部分。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat Ceph Storage 仪表板指南中的在 Ceph 仪表板中创建镜像部分*。 https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#creating-images-on-the-ceph-dashboard_dash 					

### 13.1.17. 删除 Ceph 仪表板中的镜像快照

​					您可以删除 Red Hat Ceph Storage Dashboard 上的 Ceph 块设备镜像的快照。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							创建镜像的快照并未受保护。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							选择*镜像*。 					

4. ​							要生成镜像的快照，请在 *Images* 选项卡中点其行，然后点 *Snapshots* 选项卡。 					

5. ​							在 *Rename* 下拉菜单中选择 *Delete* ： 					

   图 13.15. 删除镜像快照

   ![删除镜像快照](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3da2257d00ac33559c1f0d92589d3cbb/dash_images-snapshot-delete.png)

6. ​							您会收到成功删除快照的通知。 					

**其它资源**

- ​							如需更多信息 [*，请参阅 \*Red Hat Ceph Storage 块设备指南中的\* 删除*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#deleting-a-block-device-snapshot_block) 块设备快照部分。 					
- ​							如需了解更多详细信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph\*仪表板中的取消保护快照部分](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#unprotecting-snapshots-of-images-on-the-ceph-dashboard_dash)* 。 					

## 13.2. 在 Ceph 仪表板上管理镜像功能

​				作为存储管理员，您可以在 Red Hat Ceph Storage Dashboard 上管理和监控块设备的镜像功能。 		

​				您可以通过在存储集群间镜像数据镜像，为 Ceph 块设备添加另一层冗余性。了解和使用 Ceph 块设备镜像功能可帮助您防止数据丢失，如站点故障。镜像 Ceph 块设备有两种配置，单向镜像或双向镜像，您可以在池和单个镜像上配置镜像功能。 		

### 13.2.1. Ceph 仪表板上的镜像视图

​					您可以在 Red Hat Ceph Storage Dashboard 上查看块设备镜像。 			

​					您可以查看守护进程、站点详情、池以及为块设备镜像配置的镜像。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							配置了镜像(mirror)。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							点 *Mirroring*。 					

   图 13.16. 查看块设备的镜像

   [![查看块设备的镜像](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/030f3441f4b00aee9ef8d6bd88440f46/dash_mirroring-view.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/030f3441f4b00aee9ef8d6bd88440f46/dash_mirroring-view.png)

**其它资源**

- ​							如需有关镜像的更多信息，请参阅 *Red Hat [\*Ceph Storage 块设备指南中的镜像 Ceph 块设备\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#mirroring-ceph-block-devices) 部分*。 					

### 13.2.2. 在 Ceph 仪表板上编辑池模式

​					您可以编辑镜像功能的整体状态模式，其中包括 Red Hat Ceph Storage 仪表板中的池和镜像。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							配置了镜像(mirror)。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							点 *Mirroring*。 					

4. ​							在*池*选项卡中，点您要删除的对等点。 					

5. ​							在 *Edit Mode* 下拉菜单中，选择 *Edit Mode*。 					

6. ​							在 *Edit pool mirror mode* 窗口中，从下拉菜单中选择模式，然后单击 *Update* ： 					

   图 13.17. 在镜像(mirror)中编辑模式

   ![在镜像(mirror)中编辑模式](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a0f2f4fe9383004056f92f8852c14f6b/dash_mirroring-edit-mode.png)

7. ​							您会收到成功更新池的通知。 					

**其它资源**

- ​							如需更多信息，请参阅 *Red Hat Ceph Storage 块设备指南中的* Ceph 块设备镜像部分。 https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#ceph-block-device-mirroring_block 					

### 13.2.3. 在 Ceph 仪表板上为镜像添加对等功能

​					您可以为 `rbd-daemon` 镜像添加存储集群 peer，以便在 Red Hat Ceph Storage Dashboard 上发现其对等存储集群。 			

**先决条件**

- ​							两个正常运行的 Red Hat Ceph Storage 集群。 					
- ​							仪表板安装在两个集群上。 					
- ​							在两个集群中都启用了 *rbd* 应用来创建具有相同名称的池。 					

注意

​						确保为镜像启用了镜像创建的池。 				

**流程**

​						**站点 A** 				

1. ​							登录控制面板。 					

2. ​							在导航菜单中点 *Block* 下拉菜单，然后点 *Mirroring*。 					

3. ​							点 *Create Bootstrap Token*。 					

   图 13.18. 创建 bootstrap 令牌

   ![创建 bootstrap 令牌](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/95972a465d4c511c5b32f1693f0df658/dash_create-bootstrap-token.png)

   1. ​									对于提供的站点名称，选择要为其生成令牌的池。 							
   2. ​									为新令牌点 *Generate*。 							
   3. ​									点 *Copy* 图标将令牌复制到剪贴板。 							
   4. ​									点 *Close*。 							

4. ​							启用池镜像模式。 					

   1. ​									选择池。 							

   2. ​									*单击编辑模式*。 							

   3. ​									在 *Edit pool mirror mode* 窗口中，从下拉菜单中选择 *Image*。 							

   4. ​									点 *Update*。 							

      图 13.19. 编辑池镜像模式

      [![编辑池镜像模式](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/485e70abe0bd71017781a7851204c025/dash_edit-pool-mirror-mode.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/485e70abe0bd71017781a7851204c025/dash_edit-pool-mirror-mode.png)

​					**Site B** 			

1. ​							登录控制面板。 					

2. ​							在导航菜单中点 *Block* 下拉菜单，然后点 *Mirroring*。 					

3. ​							在 *Create Bootstrap 令牌* 下拉菜单中，选择 *Import Bootstrap Token*。 					

4. ​							在 *Import Bootstrap Token* 窗口中，选择方向，并粘贴之前从站点 A 复制的令牌。 					

   图 13.20. 导入 bootstrap 令牌

   ![创建 bootstrap 令牌](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/d0780b9bb69394b1b2708dd19fcb3b16/dash_import-bootstrap-token.png)

5. ​							单击 *Submit*。 					

   ​							添加 peer，镜像会在站点 B 的集群中镜像。 					

6. ​							验证池的健康状况处于 *OK* 状态。 					

   - ​									*在导航菜单中*，在 *Block* 下选择 *Mirroring*。池的健康状态是 *OK*。 							

​					**站点 A** 			

1. ​							创建启用了 *镜像的镜像*。 					

   1. ​									在 *Navigation* 菜单中点 *Block* 下拉菜单。 							

   2. ​									点 *Images*。 							

   3. ​									点击 *Create*。 							

   4. ​									在 *Create RBD* 窗口中，提供 *Name*,*Size* 和 enable *Mirroring*。 							

      注意

      ​										您可以选择 *Journal* 或 *Snapshot*。 								

   5. ​									点 *Create RBD*。 							

      图 13.21. 创建镜像镜像

      [![创建镜像镜像](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3b5826de5c7b48392b6a622b73a6139b/dash_create-mirroring-image.png)](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/3b5826de5c7b48392b6a622b73a6139b/dash_create-mirroring-image.png)

2. ​							验证镜像在两个站点都可用。 					

   - ​									*在导航菜单中*，在 *Block* 下选择 *Images*。站点 A 中的镜像是主要的，而站点 B 中的镜像是 `次要` 的。`` 							

**其它资源**

- ​							如需更多信息，请参阅 *Red Hat Ceph Storage 块设备指南中的* [*使用命令行界面配置双向镜像*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/block_device_guide/#configuring-ceph-block-device-mirroring-using-the-command-line-interface_two-way) 部分。 					

### 13.2.4. 在 Ceph 仪表板上编辑镜像中的对等功能

​					您可以编辑 `rbd-daemon` 镜像的存储集群对等点，以便在 Red Hat Ceph Storage Dashboard 中发现其对等存储集群。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							配置了镜像(mirror)。 					
- ​							添加了对等点。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							点 *Mirroring*。 					

4. ​							*在池* 选项卡中，点您要编辑的对等点。 					

5. ​							在 *Edit Mode* 下拉菜单中，选择 *Edit peer*。 					

6. ​							在 *Edit pool mirror peer* 窗口中，编辑参数，然后点 *Submit* ： 					

   图 13.22. 编辑镜像中的 peer

   ![编辑镜像中的 peer](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/a777f61cfcfa980f79e36c493444e839/dash_mirroring-edit-peer.png)

7. ​							您会收到一个成功更新对等的通知。 					

**其它资源**

- ​							如需更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板中添加对等\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#adding-peer-in-mirroring-on-the-ceph-dashboard_dash) 镜像部分*。 					

### 13.2.5. 删除 Ceph 仪表板上的镜像中的对等点

​					您可以编辑'rbd-daemon' mirror 的存储集群，以便在 Red Hat Ceph Storage Dashboard 中发现其对等存储集群。 			

**先决条件**

- ​							一个正在运行的 Red Hat Ceph Storage 集群。 					
- ​							已安装仪表板。 					
- ​							创建启用了 *rbd* 应用的池。 					
- ​							已创建一个镜像。 					
- ​							配置了镜像(mirror)。 					
- ​							添加了对等点。 					

**流程**

1. ​							登录到仪表板。 					

2. ​							在导航菜单中点 *Block*。 					

3. ​							点 *Mirroring*。 					

4. ​							在*池*选项卡中，点您要删除的对等点。 					

5. ​							在 *Edit Mode* 下拉菜单中，选择 *Delete peer*。 					

6. ​							在 *Delete mirror peer* 对话框中，点 *Yes, I am sure* box，然后点 *Delete mirror peer* 保存设置： 					

   图 13.23. 删除镜像中的 peer

   ![删除镜像中的 peer](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/dcd494e48b860aa7d99dee8c666c919a/dash_mirroring-delete-peer.png)

7. ​							您收到成功删除对等的通知。 					

**其它资源**

- ​							如需更多信息，请参阅 *Red Hat [\*Ceph Storage 仪表板指南中的在 Ceph 仪表板中添加对等\*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/dashboard_guide/#adding-peer-in-mirroring-on-the-ceph-dashboard_dash) 镜像部分*。 					

# 第 14 章 激活和停用遥测

​			激活遥测模块，以帮助 Ceph 开发人员了解如何使用 Ceph 以及用户可能遇到的问题。这有助于提高仪表板体验。激活遥测模块会将有关集群的匿名数据发回到 Ceph 开发人员。 	

​			[在公共遥测仪表板上](https://telemetry-public.ceph.com/) 查看发送到 Ceph 开发人员的遥测数据。这允许社区轻松查看报告集群数量、其总容量和 OSD 数量以及版本分布趋势的摘要统计。 	

​			遥测报告分为多个频道，每种频道都有不同类型的信息。假设启用了 telemetry，您可以打开和关闭单个频道。如果遥测关闭，则每个通道设置无效。 	

- 基本的

  ​						提供有关集群的基本信息。 				

- crash

  ​						提供有关守护进程崩溃的信息。 				

- 设备

  ​						提供有关设备指标的信息。 				

- Ident

  ​						提供用户提供的有关集群的标识信息。 				

- perf

  ​						提供集群的各种性能指标。 				

​			数据报告包含有助于开发人员更好地了解 Ceph 的使用方式的信息。数据包括集群部署、Ceph 版本、主机的分发和其他参数的计数器和统计信息。 	

重要

​				数据报告不包含池名称、对象名称、对象内容、主机名或设备序列号等任何敏感数据。 		

注意

​				遥测也可以使用 API 进行管理。有关更多信息，请参阅 *Red Hat Ceph Storage Developer Guide* 中的 [*Telemetry*](https://access.redhat.com/documentation/zh-cn/red_hat_ceph_storage/7/html-single/developer_guide/#telemetry) 章节。 		

**流程**

1. ​					使用以下方法之一激活 telemetry 模块： 			

   - ​							从 Ceph 仪表板内的横幅。 					

     ![激活遥测横幅](https://access.redhat.com/webassets/avalon/d/Red_Hat_Ceph_Storage-7-Dashboard_Guide-zh-CN/images/679756734bd2c5b09a71d2008388123e/dash_telemetry-banner.png)

   - ​							进入 **Settings→Telemetry 配置**。 					

2. ​					选择应启用遥测的每个频道。 			

   注意

   ​						有关每种频道类型的详细信息，请点频道旁边的 **More Info**。 				

3. ​					为集群完成 **联系信息**。输入联系人、Ceph 集群描述和组织。 			

4. ​					可选：完成 **Advanced Settings** 字段选项。 			

   - Interval（间隔）

     ​								将间隔设置为 hour。模块编译并发送每小时间隔的新报告。默认间隔为 24 小时。 						

   - Proxy

     ​								如果集群无法直接连接到配置的遥测端点，则使用它来配置 HTTP 或 HTTPs 代理服务器。使用以下格式添加服务器： 						 							`https://10.0.0.1:8080` 或 `https://ceph::8080` 						 							默认端点为 `telemetry.ceph.com`。 						

5. ​					点击 **Next**。这会在启用遥测前显示 **Telemetry 报告预览**。 			

6. ​					查看 **报告预览**。 			

   注意

   ​						该报告可以在本地下载并保存，或复制到剪贴板中。 				

7. ​					选择 **I agree to my telemetry data is submitted in the Community Data License Agreement**。 			

8. ​					单击 **Update** 来启用 telemetry 模块。 			

   ​					此时会显示以下信息，确认遥测激活： 			

   

   ```none
   The Telemetry module has been configured and activated successfully
   ```

## 14.1. 停用遥测

​				要取消激活遥测模块，请转至 **Settings→Telemetry 配置**，然后点 **Deactivate**。 		

# 法律通告

​		Copyright © 2024 Red Hat, Inc. 

​		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license  ("CC-BY-SA"). An explanation of CC-BY-SA is available at http://creativecommons.org/licenses/by-sa/3.0/. In accordance with CC-BY-SA, if you distribute this document or an  adaptation of it, you must provide the URL for the original version. 

​		Red Hat, as the licensor of this document, waives the right to  enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law. 

​		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat  logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are  trademarks of Red Hat, Inc., registered in the United States and other  countries. 

​		Linux® is the registered trademark of Linus Torvalds in the United States and other countries. 

​		Java® is a registered trademark of Oracle and/or its affiliates. 

​		XFS® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries. 

​		MySQL® is a registered trademark of MySQL AB in the United States, the European Union and other c