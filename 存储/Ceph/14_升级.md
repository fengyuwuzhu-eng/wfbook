# 升级

[TOC]

## 概述

> **危险 !!!**
>
> DATE: 01 NOV 2021.
>
> 不要从旧版本升级到 PACIFIC 。
>
> 最近发现的 bug (https://tracker.ceph.com/issues/53062) 可能导致数据损坏。对于更新到 Pacific 的集群，在 OMAP 格式转换过程中发生此错误。新群集不受此错误影响。
>
> 此 bug 的触发因素是 BlueStore 的修复/快速修复功能。此 bug 可以通过两种已知方式触发：
>
> 1. 通过 ceph-bluestore-tool 手动，或
>
> 2. 如果`bluestore_fsck_quick_fix_on_mount` 被设置为 true ，OSD 将自动执行。.
>
> Ceph v16.2.7 中预计将提供此 bug 的修复程序。
>
> 不要设置 `bluestore_quick_fix_on_mount` 为 true 。如果当前配置中其设置为 true ，请立即将其设置为 false 。
>
> 不要运行 `ceph-bluestore-tool` 的 repair/quick-fix 命令。

Cephadm 可以安全地将 Ceph 从一个错误修复版本升级到下一个版本。例如，您可以从 v15.2.0（第一个 Octopus 版本）升级到下一个点版本 v15.2.1 。

自动化升级过程遵循 Ceph 最佳实践。例如：

- 升级顺序从 MGR 、MON 开始，然后是其他守护程序。
- 只有在 Ceph 指示集群将保持可用后，每个守护进程才会重新启动。only after Ceph indicates that the cluster will remain available.

> **Note：**
>
> 升级期间，Ceph 集群的健康状态可能会切换到`HEALTH_WARNING`  。
>
> 如果群集的主机处于离线状态，则会暂停升级。

## 开始升级

> **Note：**
>
> [Staggered Upgrade](https://docs.ceph.com/en/latest/cephadm/upgrade/#staggered-upgrade) of the mons/mgrs may be necessary to have access to this new feature.要访问此新功能，可能需要对 mon / mgr 进行交错升级。
>
> 默认情况下，Cephadm 将 max_mds 减少到1。这可能会对大规模 CephFS 部署造成破坏，因为集群无法快速将活动 mds 减少到 1，而且单个活动 mds 即使在短时间内也无法轻松处理所有客户端的负载。因此，要在不减少 max_mds 的情况下升级MDS，可以在启动升级之前将 fail_fs 选项设置为 true（默认值为 false）：
>
> ```bash
> ceph config set mgr mgr/orchestrator/fail_fs true
> ```
>
> 这将：
>
> 1. 使 CephFS 文件系统失效，使活动的 MDS 守护程序进入 up:standby 状态。
> 2. 安全升级 MDS 守护程序。
> 3. Bring CephFS filesystems back up，将活动 MDS 守护程序的状态从up:standby 变为 up:active 。

在使用 cephadm 升级 Ceph 之前，请通过运行以下命令验证所有主机当前是否联机以及集群是否正常：

```bash
ceph -s
```

要升级（或降级）到特定版本，请运行以下命令：

```bash
ceph orch upgrade start --ceph-version <version>
```

例如，要升级到v16.2.6，请运行以下命令：

```bash
ceph orch upgrade start --ceph-version 16.2.6
```

> **Note：**
>
> 从 v16.2.6 版本开始，不再使用 Docker Hub  registry ，因此如果使用 Docker ，则必须将其指向 quay.io  registry 中的 image ：
>
> ```bash
> ceph orch upgrade start --image quay.io/ceph/ceph:v16.2.6
> ```

升级存储集群:

```bash
# RHEL
ceph orch upgrade start --image IMAGE_NAME
```

## 监控升级

通过运行以下命令，确定（1）是否正在升级，以及（2）群集正在升级到哪个版本：

```bash
ceph orch upgrade status
```

### 在 Ceph 升级期间查看进度条

在升级过程中，ceph状态输出中会显示一个进度条。它看起来像这样：

```bash
ceph -s

[...]
  progress:
    Upgrade to docker.io/ceph/ceph:v15.2.1 (00h 20m 12s)
      [=======.....................] (time remaining: 01h 43m 31s)
```

### 在升级期间查看 cephadm 日志

运行以下命令查看 cephadm 日志：

```bash
ceph -W cephadm
```

## 取消升级

可以在任何时候取消升级：

```bash
ceph orch upgrade stop
```

## 升级后操作

由于新版本基于 cephadm ，升级完成后，用户必须将 cephadm 包（如果用户不使用`cephadm shell`，则为 ceph-common 包）更新为与新版本兼容的版本。

## 潜在的问题

升级过程中可能会出现一些健康警报。

### UPGRADE_NO_STANDBY_MGR

此警报（`UPGRADE_NO_STANDBY_MGR`）表示 Ceph 未检测到活动的备用 MGR 守护程序。为了继续升级，Ceph 需要一个活动的备用 MGR 守护进程（在本文中，您可以将其视为“第二个 MGR ”）。

您可以通过运行以下命令确保 Cephadm 配置为运行 2 个（或更多）MGR ：

```bash
ceph orch apply mgr 2  # or more
```

通过运行以下命令，可以检查现有 MGR 守护程序的状态：

```bash
ceph orch ps --daemon-type mgr
```

如果现有的 MGR 守护程序已停止，可以尝试通过运行以下命令重新启动它：

```bash
ceph orch daemon restart <name>
```

### UPGRADE_FAILED_PULL

此警报（`UPGRADE_FAILED_PULL`）表示 Ceph 无法提取目标版本的容器映像。如果指定的版本或容器映像不存在（例如 “1.2.3” ），或者集群中的一个或多个主机无法访问容器 registry ，则可能会发生这种情况。

要取消现有升级并指定其他目标版本，请运行以下命令：

```bash
ceph orch upgrade stop
ceph orch upgrade start --ceph-version <version>
```

## 使用自定义容器镜像

对于大多数用户来说，升级只需要指定要升级到的 Ceph 版本号就可以了。在这种情况下，cephadm 通过将 `container_image_base` 配置选项（默认值： `docker.io/ceph/ceph`）与`vX.Y.Z` 标记结合起来，找到要使用的特定 Ceph 容器镜像。

但如果您需要的话，可以升级到任意的容器映像。例如，以下命令升级到开发版本：

```bash
ceph orch upgrade start --image quay.io/ceph-ci/ceph:recent-git-branch-name
```

## 交错升级

一些用户可能更喜欢分阶段升级组件，而不是一次升级所有组件。The upgrade command, starting in 16.2.10 and 17.2.1 allows parameters to limit which daemons are upgraded by a single upgrade command.从 16.2.11 和 17.2.1 开始的升级命令允许参数限制通过单个升级命令升级哪些守护程序。The options in include `daemon_types`, `services`, `hosts` and `limit`. 中的选项包括守护程序类型、服务、主机和限制。`daemon_types` takes a comma-separated list of daemon types and will only upgrade daemons of those types. `services` is mutually exclusive with `daemon_types`, only takes services of one type at a time (e.g. can’t provide an OSD and RGW service at the same time), and will only upgrade daemons belonging to those services. `hosts` can be combined with `daemon_types` or `services` or provided on its own. The `hosts` parameter follows the same format as the command line options for [Daemon Placement](https://docs.ceph.com/en/latest/cephadm/services/#orchestrator-cli-placement-spec). `limit` takes an integer > 0 and provides a numerical limit on the number of daemons cephadm will upgrade. `limit` can be combined with any of the other parameters. For example, if you specify to upgrade daemons of type osd on host Host1 with `limit` set to 3, cephadm will upgrade (up to) 3 osd daemons on Host1.

守护程序类型采用逗号分隔的守护程序类型列表，并且只会升级这些类型的守护程序。服务与守护程序类型互斥，一次只能接受一种类型的服务（例如，不能同时提供OSD和RGW服务），并且只能升级属于这些服务的守护程序。主机可以与守护程序类型或服务组合，也可以单独提供。hosts参数的格式与Daemon  Placement的命令行选项相同。limit采用大于0的整数，并提供cephadm将升级的守护进程数量的数字限制。极限可以与任何其他参数组合。例如，如果指定在主机Host1上升级osd类型的守护程序，并将限制设置为3，则cephadm将在主机1上升级（最多）3个osd守护程序。

示例：指定守护程序类型和主机

```bash
ceph orch upgrade start --image <image-name> --daemon-types mgr,mon --hosts host1,host2
```

示例：指定服务和使用限制

```bash
ceph orch upgrade start --image <image-name> --services rgw.example1,rgw.example2 --limit 2
```

> Note

Cephadm strictly enforces an order to the upgrade of daemons that is still present in staggered upgrade scenarios. The current upgrade ordering is `mgr -> mon -> crash -> osd -> mds -> rgw -> rbd-mirror -> cephfs-mirror -> iscsi -> nfs`. If you specify parameters that would upgrade daemons out of order, the upgrade command will block and note which daemons will be missed if you proceed.

Cephadm严格执行在交错升级场景中仍然存在的守护进程升级命令。当前的升级顺序是mgr->mon->crash->osd->mds->rgw->rbd-mirror->cephfs-mirror->iscsi->nfs。如果您指定的参数会使守护程序无序升级，升级命令将阻止并注意如果继续，将错过哪些守护程序。

Note

Upgrade commands with limiting parameters will validate the options before beginning the upgrade, which may require pulling the new container image. Do not be surprised if the upgrade start command takes a while to return when limiting parameters are provided.带有限制参数的升级命令将在开始升级之前验证选项，这可能需要拉动新的容器映像。当提供限制参数时，如果升级开始命令需要一段时间才能返回，请不要感到惊讶。

Note

In staggered upgrade scenarios (when a limiting parameter is provided) monitoring stack daemons including Prometheus and node-exporter are refreshed after the Manager daemons have been upgraded. Do not be surprised if Manager upgrades thus take longer than expected. Note that the versions of monitoring stack daemons may not change between Ceph releases, in which case they are only redeployed.在交错升级场景中（当提供限制参数时），包括Prometheus和节点导出器在内的监视堆栈守护程序在Manager守护程序升级后被刷新。如果Manager升级所需的时间比预期的长，请不要感到惊讶。请注意，监视堆栈守护程序的版本可能不会在Ceph版本之间发生变化，在这种情况下，它们只会重新部署。

### Upgrading to a version that supports staggered upgrade from one that doesn’t

While upgrading from a version that already supports staggered upgrades the process simply requires providing the necessary arguments. However, if you wish to upgrade to a version that supports staggered upgrade from one that does not, there is a workaround. It requires first manually upgrading the Manager daemons and then passing the limiting parameters as usual.

当从已经支持交错升级的版本升级时，该过程只需要提供必要的参数。但是，如果您希望从不支持交错升级的版本升级到支持交错升级版本，则有一种解决方法。它需要首先手动升级Manager守护程序，然后像往常一样传递限制参数。

> **Warning：**
>
> 在尝试此过程之前，请确保有多个正在运行的 MGR 守护程序。

To start with, determine which Manager is your active one and which are standby. This can be done in a variety of ways such as looking at the `ceph -s` output. Then, manually upgrade each standby mgr daemon with:

首先，确定哪个管理器是您的活动管理器，哪个管理器处于待机状态。这可以通过多种方式实现，例如查看ceph-s输出。然后，使用以下命令手动升级每个备用mgr守护程序：

```bash
ceph orch daemon redeploy mgr.example1.abcdef --image <new-image-name>
```

> **Note：**
>
> If you are on a very early version of cephadm (early Octopus) the `orch daemon redeploy` command may not have the `--image` flag. In that case, you must manually set the Manager container image `ceph config set mgr container_image <new-image-name>` and then redeploy the Manager `ceph orch daemon redeploy mgr.example1.abcdef`
>
> 如果您使用的是非常早期的cephadm（早期章鱼）版本，那么orch守护程序重新部署命令可能没有--image标志。在这种情况下，您必须手动设置Manager容器映像ceph-config set mgr容器映像＜new image name＞，然后重新部署Manager ceph-orch守护程序redeploy  mgr.example1.abcdef

At this point, a Manager fail over should allow us to have the active Manager be one running the new version.此时，管理器故障切换应该允许我们让活动的管理器运行新版本。

```bash
ceph mgr fail
```

验证活动的 MGR 现在是运行新版本的 MGR 。要完成 MGR 升级，请执行以下操作：

```bash
ceph orch upgrade start --image <new-image-name> --daemon-types mgr
```

You should now have all your Manager daemons on the new version and be able to specify the limiting parameters for the rest of the upgrade.

现在，您应该在新版本上安装了所有Manager守护程序，并且能够为升级的其余部分指定限制参数。

​        

作为存储管理员，可以使用 `cephadm` Orchestrator 升级 Ceph 。 	

自动化升级流程遵循 Ceph 最佳实践。例如： 	

- 升级顺序从MGR、MON开始，然后是其他守护进程。 			
- 只有在 Ceph 指示集群可用后，每一守护进程才会重新启动。 			

存储集群健康状态可能会在升级过程中切换到 `HEALTH_WARNING`。升级完成后，健康状态应该切回到 HEALTH_OK。 		

升级成功后，不会收到消息。运行 `ceph versions` 和 `ceph orch ps` 命令，以验证新的镜像 ID 和存储集群的版本。

## 暂停升级

```bash
ceph orch upgrade pause
```

## 恢复暂停的升级

```bash
ceph orch upgrade resume
```



## 推荐升级步骤

MON

OSD
MDS

RADOSGW

## Other

Red Hat Ceph Storage 5 还包括一个健康检查功能，如果它检测到存储集群中的任何守护进程正在运行多个版本的 RHCS，它会返回 DAEMON_OLD_VERSION 警告。当守护进程继续运行多个版本的红帽 Ceph 存储，超过 `mon_warn_older_version_delay` 选项中设置的时间值时，会触发警告。默认情况下，`mon_warn_older_version_delay` 选项设置为 1 周。此设置允许大多数升级进行，而不会看到警告。如果升级过程暂停了较长的时间，您可以屏蔽健康警告： 	

```bash
ceph health mute DAEMON_OLD_VERSION --sticky
```
升级完成后，取消健康警告： 			

```bash
ceph health unmute DAEMON_OLD_VERSION
```