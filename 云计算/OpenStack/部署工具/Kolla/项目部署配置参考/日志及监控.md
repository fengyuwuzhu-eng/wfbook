# Logging and monitoring 日志记录和监视

​        version 版本              



This section describes configuration for the different logging and monitoring services available in kolla.
本节介绍 kolla 中可用的不同日志记录和监视服务的配置。

- [Central Logging 中央日志记录](https://docs.openstack.org/kolla-ansible/latest/reference/logging-and-monitoring/central-logging-guide.html)
- [Grafana 格拉法纳](https://docs.openstack.org/kolla-ansible/latest/reference/logging-and-monitoring/grafana-guide.html)
- [InfluxDB - Time Series Database
  InfluxDB - 时序数据库](https://docs.openstack.org/kolla-ansible/latest/reference/logging-and-monitoring/influxdb-guide.html)
- [OSprofiler - Cross-project profiling
  OSprofiler - 跨项目分析](https://docs.openstack.org/kolla-ansible/latest/reference/logging-and-monitoring/osprofiler-guide.html)
- [Prometheus - Monitoring System & Time Series Database
  Prometheus - 监控系统和时间序列数据库](https://docs.openstack.org/kolla-ansible/latest/reference/logging-and-monitoring/prometheus-guide.html)

# Central Logging 中央日志记录

​        version 版本              





An OpenStack deployment generates vast amounts of log data. In order to successfully monitor this and use it to diagnose problems, the standard “ssh and grep” solution quickly becomes unmanageable.
OpenStack 部署会生成大量日志数据。为了成功监控并使用它来诊断问题，标准的“ssh 和 grep”解决方案很快就会变得难以管理。

## Preparation and deployment 准备和部署 ¶

Modify the configuration file `/etc/kolla/globals.yml` and change the following:
修改配置文件 `/etc/kolla/globals.yml` 并更改以下内容：

```
enable_central_logging: "yes"
```

## OpenSearch

Kolla deploys OpenSearch to store, organize and make logs easily accessible.
Kolla 部署 OpenSearch 来存储、组织日志并使其易于访问。

By default OpenSearch is deployed on port `9200`.
默认情况下，OpenSearch 部署在端口 `9200` 上。



 

Note 注意



OpenSearch stores a lot of logs, so if you are running centralized logging, remember to give `/var/lib/docker` adequate space.
OpenSearch 存储了大量日志，因此如果您运行的是集中式日志记录，请记住提供 `/var/lib/docker` 足够的空间。

Alternatively it is possible to use a local directory instead of the volume `opensearch` to store the data of OpenSearch. The path can be set via the variable `opensearch_datadir_volume`.
或者，可以使用本地目录而不是卷 `opensearch` 来存储 OpenSearch 的数据。可以通过变量 `opensearch_datadir_volume` 来设置路径。

### Applying log retention policies 应用日志保留策略 ¶

To stop your disks filling up, the Index State Management plugin for OpenSearch can be used to define log retention policies. A default retention policy is applied to all indicies which match the `opensearch_log_index_prefix`. This policy first closes old indicies, and then eventually deletes them. It can be customised via the following variables:
要阻止磁盘填满，可以使用 OpenSearch 的索引状态管理插件来定义日志保留策略。默认保留策略将应用于与 匹配的所有 `opensearch_log_index_prefix` 指示。此策略首先关闭旧指示，然后最终删除它们。它可以通过以下变量进行自定义：

- `opensearch_apply_log_retention_policy`
- `opensearch_soft_retention_period_days`
- `opensearch_hard_retention_period_days`

By default the soft and hard retention periods are 30 and 60 days respectively. If you are upgrading from ElasticSearch, and have previously configured `elasticsearch_curator_soft_retention_period_days` or `elasticsearch_curator_hard_retention_period_days`, those variables will be used instead of the defaults. You should migrate your configuration to use the new variable names before the Caracal release.
默认情况下，软保留期和硬保留期分别为 30 天和 60 天。如果您是从 ElasticSearch 升级的，并且之前配置 `elasticsearch_curator_soft_retention_period_days` 了 或 `elasticsearch_curator_hard_retention_period_days` ，则将使用这些变量而不是默认变量。您应该在 Caracal 发布之前迁移配置以使用新的变量名称。

Advanced users may wish to customise the retention policy, which is possible by overriding `opensearch_retention_policy` with a valid policy. See the [Index Management plugin documentation](https://opensearch.org/docs/latest/im-plugin/index/) for further details.
高级用户可能希望自定义保留策略，这可以通过使用有效策略进行覆盖 `opensearch_retention_policy` 来实现。有关更多详细信息，请参阅索引管理插件文档。

### Updating log retention policies 更新日志保留策略 ¶

By design, Kolla Ansible will NOT update an existing retention policy in OpenSearch. This is to prevent policy changes that may have been made via the OpenSearch Dashboards UI, or external tooling, from being wiped out.
根据设计，Kolla Ansible 不会更新 OpenSearch 中的现有保留策略。这是为了防止可能通过 OpenSearch 控制面板 UI 或外部工具进行的策略更改被清除。

There are three options for modifying an existing policy:
有三个选项可用于修改现有策略：

1. Via the OpenSearch Dashboards UI. See the [Index Management plugin documentation](https://opensearch.org/docs/latest/im-plugin/index/) for further details.
2. 通过 OpenSearch 控制面板 UI。有关更多详细信息，请参阅索引管理插件文档。

1. Via the OpenSearch API using external tooling.
   通过使用外部工具的 OpenSearch API。
2. By manually removing the existing policy via the OpenSearch Dashboards UI (or API), before re-applying the updated policy with Kolla Ansible.
   通过 OpenSearch 控制面板 UI（或 API）手动删除现有策略，然后再使用 Kolla Ansible 重新应用更新的策略。

## OpenSearch Dashboards OpenSearch 控制面板 ¶

Kolla deploys OpenSearch dashboards to allow operators to search and visualise logs in a centralised manner.
Kolla 部署了 OpenSearch 控制面板，使操作员能够以集中的方式搜索和可视化日志。

After a successful deployment, OpenSearch Dashboards can be accessed using a browser on `<kolla_internal_fqdn>:5601` or `<kolla_external_fqdn>:5601`.
成功部署后，可以使用 或 `<kolla_external_fqdn>:5601` 上的 `<kolla_internal_fqdn>:5601` 浏览器访问 OpenSearch 控制面板。

The default username is `opensearch`, the password can be located under `<opensearch_dashboards_password>` in `/etc/kolla/passwords.yml`.
默认用户名是 `opensearch` ，密码可以位于 `<opensearch_dashboards_password>` in `/etc/kolla/passwords.yml` 下。

If you want to prevent OpenSearch Dashboards being exposed on the external VIP, you can set `enable_opensearch_dashboards_external` to `false` in `/etc/kolla/globals.yml`.
如果要防止 OpenSearch 控制面板在外部 VIP 上公开，则可以在 `false` 中 `/etc/kolla/globals.yml` 设置为 `enable_opensearch_dashboards_external` 。

### First Login 首次登录 ¶

When OpenSearch Dashboards is opened for the first time, it requires creating a default index pattern. To view, analyse and search logs, at least one index pattern has to be created. To match indices stored in OpenSearch, we suggest using the following configuration:
首次打开 OpenSearch 控制面板时，需要创建默认索引模式。要查看、分析和搜索日志，必须至少创建一个索引模式。要匹配存储在 OpenSearch 中的索引，我们建议使用以下配置：

1. Index pattern - flog-* 索引模式 - flog-*
2. Time Filter field name - @timestamp
   时间筛选器字段名称 - @timestamp
3. Expand index pattern when searching [DEPRECATED] - not checked
   搜索 [DEPRECATED] 时展开索引模式 - 未选中
4. Use event times to create index names [DEPRECATED] - not checked
   使用事件时间创建索引名称 [已弃用] - 未选中

After setting parameters, one can create an index with the *Create* button.
设置参数后，可以使用“创建”按钮创建索引。

### Search logs - Discover tab 搜索日志 - 发现选项卡 ¶

Operators can create and store searches based on various fields from logs, for example, “show all logs marked with ERROR on nova-compute”.
操作员可以根据日志中的各种字段创建和存储搜索，例如，“在 nova-compute 上显示所有标记为 ERROR 的日志”。

To do this, click the `Discover` tab. Fields from the logs can be filtered by hovering over entries from the left hand side, and clicking `add` or `remove`. Add the following fields:
为此，请单击选项卡 `Discover` 。可以通过将鼠标悬停在左侧的条目上，然后单击 `add` 或 `remove` 来过滤日志中的字段。添加以下字段：

- Hostname 主机名
- Payload 有效载荷
- severity_label
- programname 程序名称

This yields an easy to read list of all log events from each node in the deployment within the last 15 minutes. A “tail like” functionality can be achieved by clicking the clock icon in the top right hand corner of the screen, and selecting `Auto-refresh`.
这将生成一个易于阅读的列表，其中包含过去 15 分钟内部署中每个节点的所有日志事件。可以通过单击屏幕右上角的时钟图标并选择 `Auto-refresh` 来实现“尾巴状”功能。

Logs can also be filtered down further. To use the above example, type `programname:nova-compute` in the search bar. Click the drop-down arrow from one of the results, then the small magnifying glass icon from beside the programname field. This should now show a list of all events from nova-compute services across the cluster.
日志也可以进一步过滤。若要使用上述示例，请在搜索栏中键入 `programname:nova-compute` 。单击其中一个结果中的下拉箭头，然后单击程序名称字段旁边的小放大镜图标。现在，这应该显示来自整个集群的 nova-compute 服务的所有事件的列表。

The current search can also be saved by clicking the `Save Search` icon available from the menu on the right hand side.
也可以通过单击右侧菜单中的 `Save Search` 图标来保存当前搜索。

### Example: using OpenSearch Dashboards to diagnose a common failure 示例：使用 OpenSearch 控制面板诊断常见故障 ¶

The following example demonstrates how OpenSearch can be used to diagnose a common OpenStack problem, where an instance fails to launch with the error ‘No valid host was found’.
以下示例演示了如何使用 OpenSearch 来诊断常见的 OpenStack 问题，即实例无法启动并显示错误“未找到有效主机”。

First, re-run the server creation with `--debug`:
首先，使用以下命令 `--debug` 重新运行服务器创建：

```
openstack --debug server create --image cirros --flavor m1.tiny \
--key-name mykey --nic net-id=00af016f-dffe-4e3c-a9b8-ec52ccd8ea65 \
demo1
```

In this output, look for the key `X-Compute-Request-Id`. This is a unique identifier that can be used to track the request through the system. An example ID looks like this:
在此输出中，查找键 `X-Compute-Request-Id` 。这是一个唯一标识符，可用于通过系统跟踪请求。示例 ID 如下所示：

```
X-Compute-Request-Id: req-c076b50a-6a22-48bf-8810-b9f41176a6d5
```

Taking the value of `X-Compute-Request-Id`, enter the value into the OpenSearch Dashboards search bar, minus the leading `req-`. Assuming some basic filters have been added as shown in the previous section, OpenSearch Dashboards should now show the path this request made through the OpenStack deployment, starting at a `nova-api` on a control node, through the `nova-scheduler`, `nova-conductor`, and finally `nova-compute`. Inspecting the `Payload` of the entries marked `ERROR` should quickly lead to the source of the problem.
取值 `X-Compute-Request-Id` ，在 OpenSearch 控制面板搜索栏中输入该值，减去前导 `req-` 。假设已添加一些基本筛选器，如上一节所示，OpenSearch 控制面板现在应显示此请求通过 OpenStack 部署发出的路径，从控制节点上的 开始 `nova-api` ，到 `nova-scheduler` 、 `nova-conductor` ，最后 `nova-compute` 是 。检查标记 `Payload`  `ERROR` 的条目应该会很快找到问题的根源。

While some knowledge is still required of how Nova works in this instance, it can still be seen how OpenSearch Dashboards helps in tracing this data, particularly in a large scale deployment scenario.
虽然在这种情况下仍然需要了解 Nova 的工作原理，但仍然可以看到 OpenSearch 控制面板如何帮助跟踪这些数据，尤其是在大规模部署场景中。

### Visualize data - Visualize tab 可视化数据 - 可视化选项卡 ¶

In the visualization tab a wide range of charts is available. If any visualization has not been saved yet, after choosing this tab *Create a new visualization* panel is opened. If a visualization has already been saved, after choosing this tab, lately modified visualization is opened. In this case, one can create a new visualization by choosing *add visualization* option in the menu on the right. In order to create new visualization, one of the available options has to be chosen (pie chart, area chart). Each visualization can be created from a saved or a new search. After choosing any kind of search, a design panel is opened. In this panel, a chart can be generated and previewed. In the menu on the left, metrics for a chart can be chosen. The chart can be generated by pressing a green arrow on the top of the left-side menu.
在可视化选项卡中，提供了各种图表。如果尚未保存任何可视化效果，则在选择此选项卡后，将打开“创建新的可视化效果”面板。如果已保存可视化效果，则在选择此选项卡后，将打开最近修改的可视化效果。在这种情况下，可以通过选择右侧菜单中的“添加可视化”选项来创建新的可视化效果。为了创建新的可视化效果，必须选择其中一个可用选项（饼图、面积图）。每个可视化效果都可以从已保存的搜索或新的搜索中创建。选择任何类型的搜索后，将打开一个设计面板。在此面板中，可以生成和预览图表。在左侧菜单中，可以选择图表的指标。可以通过按左侧菜单顶部的绿色箭头来生成图表。



 

Note 注意



After creating a visualization, it can be saved by choosing *save visualization* option in the menu on the right. If it is not saved, it will be lost after leaving a page or creating another visualization.
创建可视化效果后，可以通过选择右侧菜单中的保存可视化选项来保存它。如果未保存，则在离开页面或创建其他可视化效果后，它将丢失。

### Organize visualizations and searches - Dashboard tab 组织可视化和搜索 - 仪表板选项卡 ¶

In the Dashboard tab all of saved visualizations and searches can be organized in one Dashboard. To add visualization or search, one can choose *add visualization* option in the menu on the right and then choose an item from all saved ones. The order and size of elements can be changed directly in this place by moving them or resizing. The color of charts can also be changed by checking a colorful dots on the legend near each visualization.
在“仪表板”选项卡中，所有保存的可视化和搜索都可以组织在一个仪表板中。要添加可视化或搜索，可以选择右侧菜单中的添加可视化选项，然后从所有保存的项目中选择一个项目。元素的顺序和大小可以通过移动或调整大小直接在该位置更改。图表的颜色也可以通过检查每个可视化效果附近图例上的彩色点来更改。



 

Note 注意



After creating a dashboard, it can be saved by choosing *save dashboard* option in the menu on the right. If it is not saved, it will be lost after leaving a page or creating another dashboard.
创建仪表板后，可以通过选择 保存仪表板 右侧菜单中的选项。如果未保存，则在离开页面或创建另一个仪表板后将丢失。

If a Dashboard has already been saved, it can be opened by choosing *open dashboard* option in the menu on the right.
如果已经保存了仪表板，可以通过选择右侧菜单中的打开仪表板选项来打开它。

### Exporting and importing created items - Settings tab 导出和导入已创建的项目 - 设置选项卡 ¶

Once visualizations, searches or dashboards are created, they can be exported to a JSON format by choosing Settings tab and then Objects tab. Each of the item can be exported separately by selecting it in the menu. All of the items can also be exported at once by choosing *export everything* option. In the same tab (Settings - Objects) one can also import saved items by choosing *import* option.
创建可视化、搜索或仪表板后，可以通过选择“设置”选项卡，然后选择“对象”选项卡，将其导出为 JSON 格式。通过在菜单中选择每个项目，可以单独导出每个项目。也可以通过选择“导出所有内容”选项一次导出所有项目。在同一选项卡（设置 -  对象）中，还可以通过选择导入选项来导入已保存的项目。

## Custom log rules 自定义日志规则 ¶

Kolla Ansible automatically deploys Fluentd for forwarding OpenStack logs from across the control plane to a central logging repository. The Fluentd configuration is split into four parts: Input, forwarding, filtering and formatting. The following can be customised:
Kolla Ansible 自动部署 Fluentd，用于将 OpenStack 日志从整个控制平面转发到中央日志存储库。Fluentd 配置分为四个部分：输入、转发、过滤和格式化。可以自定义以下内容：

### Custom log filtering 自定义日志过滤 ¶

In some scenarios it may be useful to apply custom filters to logs before forwarding them.  This may be useful to add additional tags to the messages or to modify the tags to conform to a log format that differs from the one defined by kolla-ansible.
在某些情况下，在转发日志之前将自定义筛选器应用于日志可能很有用。这对于向消息添加其他标记或修改标记以符合与 kolla-ansible 定义的日志格式不同的日志格式可能很有用。

Configuration of custom fluentd filters is possible by placing filter configuration files in `/etc/kolla/config/fluentd/filter/*.conf` on the control host.
通过 `/etc/kolla/config/fluentd/filter/*.conf` 将过滤器配置文件放在控制主机上，可以配置自定义 fluentd 过滤器。

### Custom log formatting 自定义日志格式 ¶

In some scenarios it may be useful to perform custom formatting of logs before forwarding them. For example, the JSON formatter plugin can be used to convert an event to JSON.
在某些情况下，在转发日志之前执行日志的自定义格式设置可能很有用。例如，JSON 格式化程序插件可用于将事件转换为 JSON。

Configuration of custom fluentd formatting is possible by placing filter configuration files in `/etc/kolla/config/fluentd/format/*.conf` on the control host.
通过 `/etc/kolla/config/fluentd/format/*.conf` 将过滤器配置文件放在控制主机上，可以配置自定义 fluentd 格式。

### Custom log forwarding 自定义日志转发 ¶

In some scenarios it may be useful to forward logs to a logging service other than elasticsearch.  This can be done by configuring custom fluentd outputs.
在某些情况下，将日志转发到 elasticsearch 以外的日志记录服务可能很有用。这可以通过配置自定义 fluentd 输出来完成。

Configuration of custom fluentd outputs is possible by placing output configuration files in `/etc/kolla/config/fluentd/output/*.conf` on the control host.
通过 `/etc/kolla/config/fluentd/output/*.conf` 将输出配置文件放在控制主机上，可以配置自定义 fluentd 输出。

### Custom log inputs 自定义日志输入 ¶

In some scenarios it may be useful to input logs from other services, e.g. network equipment. This can be done by configuring custom fluentd inputs.
在某些情况下，从其他服务（例如网络设备）输入日志可能很有用。这可以通过配置自定义 fluentd 输入来完成。

Configuration of custom fluentd inputs is possible by placing input configuration files in `/etc/kolla/config/fluentd/input/*.conf` on the control host.
通过 `/etc/kolla/config/fluentd/input/*.conf` 将输入配置文件放在控制主机上，可以配置自定义 fluentd 输入。

### Systemd Logs systemd 日志 ¶

By default, when enabling central logging, we also enable reading `systemd` logs from the `/var/log/journal` file.
默认情况下，启用集中日志记录时，我们还启用从 `/var/log/journal` 文件中读取 `systemd` 日志。

To disable this behavior when central logging is enabled, set the value of the variable `enable_fluentd_systemd` to `false` in the configuration file `/etc/kolla/globals.yml`.
若要在启用集中日志记录时禁用此行为，请在配置文件 `/etc/kolla/globals.yml` 中将变量的值 `enable_fluentd_systemd` 设置为 `false` 。

# Grafana 格拉法纳

​        version 版本              





## Overview 概述 ¶

[Grafana](https://grafana.com) is open and composable observability and data visualization platform. Visualize metrics, logs, and traces from multiple sources like Prometheus, Loki, Elasticsearch, InfluxDB, Postgres and many more..
Grafana 是一个开放且可组合的可观测性和数据可视化平台。可视化来自多个来源的指标、日志和跟踪，如 Prometheus、Loki、Elasticsearch、InfluxDB、Postgres 等。

## Preparation and deployment 准备和部署 ¶

To enable Grafana, modify the configuration file `/etc/kolla/globals.yml` and change the following:
要启用 Grafana，请修改配置文件 `/etc/kolla/globals.yml` 并更改以下内容：

```
enable_grafana: "yes"
```

If you would like to set up Prometheus as a data source, additionally set:
如果要将 Prometheus 设置为数据源，请另外设置：

```
enable_prometheus: "yes"
```

Please follow [Prometheus Guide](https://docs.openstack.org/kolla-ansible/latest/reference/logging-and-monitoring/prometheus-guide.html) for more information.
请关注普罗米修斯指南了解更多信息。

## Custom dashboards provisioning 自定义仪表板配置 ¶

Kolla Ansible sets custom dashboards provisioning using [Dashboard provider](https://grafana.com/docs/grafana/latest/administration/provisioning/#dashboards).
Kolla Ansible 使用 Dashboard 提供程序设置自定义仪表板配置。

Dashboard JSON files should be placed into the `{{ node_custom_config }}/grafana/dashboards/` folder. The use of sub-folders is also supported when using a custom `provisioning.yaml` file. Dashboards will be imported into the Grafana dashboards ‘General’ folder by default.
仪表板 JSON 文件应放入 `{{ node_custom_config }}/grafana/dashboards/` 文件夹中。使用自定义 `provisioning.yaml` 文件时，还支持使用子文件夹。默认情况下，仪表板将导入到 Grafana 仪表板的“常规”文件夹中。

Grafana provisioner config can be altered by placing `provisioning.yaml` to `{{ node_custom_config }}/grafana/` folder.
可以通过放置 `provisioning.yaml` 到 `{{ node_custom_config }}/grafana/` 文件夹来更改 Grafana 配置。

For other settings, follow configuration reference: [Dashboard provider configuration](https://grafana.com/docs/grafana/latest/administration/provisioning/#dashboards).
对于其他设置，请遵循配置参考：仪表板提供程序配置。

# InfluxDB - Time Series Database InfluxDB - 时序数据库

​        version 版本              





## Overview 概述 ¶

InfluxDB is a time series database developed by InfluxData. It is possible to deploy a single instance without charge. To use the clustering features you will require a commercial license.
InfluxDB是由InfluxData开发的时序数据库。可以免费部署单个实例。要使用群集功能，您需要商业许可证。

## InfluxDB

The [recommendation](https://docs.influxdata.com/influxdb/v1.7/guides/hardware_sizing/#what-kind-of-storage-do-i-need) is to use flash storage for InfluxDB. If docker is configured to use spinning disks by default, or you have some higher performance drives available, it may be desirable to control where the docker volume is located. This can be achieved by setting a path for `influxdb_datadir_volume` in `/etc/kolla/globals.yml`:
建议对 InfluxDB 使用闪存存储。如果 docker 默认配置为使用旋转磁盘，或者您有一些更高性能的驱动器可用，则可能需要控制 docker 卷的位置。这可以通过设置以下 `influxdb_datadir_volume` `/etc/kolla/globals.yml` 路径来实现：

```
influxdb_datadir_volume: /mnt/ssd/influxdb/
```

The default is to use a named volume, `influxdb`.
缺省设置是使用命名卷 `influxdb` 。

# OSprofiler - Cross-project profiling OSprofiler - 跨项目分析

​        version 版本              





## Overview 概述 ¶

OSProfiler provides a tiny but powerful library that is used by most (soon to be all) OpenStack projects and their corresponding python clients as well as the Openstack client. It provides functionality to generate 1 trace per request, that goes through all involved services. This trace can then be extracted and used to build a tree of calls which can be quite handy for a variety of reasons (for example in isolating cross-project performance issues).
OSProfiler 提供了一个小而强大的库，大多数（即将成为所有）OpenStack 项目及其相应的 python 客户端以及 Openstack  客户端都在使用它。它提供了为每个请求生成 1  个跟踪的功能，该跟踪遍历所有相关服务。然后，可以提取此跟踪并用于构建调用树，由于各种原因（例如，在隔离跨项目性能问题时），该树非常方便。

### Configuration on Kolla deployment Kolla 部署上的配置 ¶

Enable `OSprofiler` in `/etc/kolla/globals.yml` file:
在 `/etc/kolla/globals.yml` 文件中启用 `OSprofiler` ：

```
enable_osprofiler: "yes"
enable_elasticsearch: "yes"
```

### Verify operation 验证操作 ¶

Retrieve `osprofiler_secret` key present at `/etc/kolla/passwords.yml`.
检索 中 `/etc/kolla/passwords.yml` 存在的 `osprofiler_secret` 密钥。

Profiler UUIDs can be created executing OpenStack clients (Nova, Glance, Cinder, Heat, Keystone) with `--profile` option or using the official Openstack client with `--os-profile`. In example to get the OSprofiler trace UUID for **openstack server create** command.
Profiler UUID 可以通过执行 OpenStack 客户端（Nova、Glance、Cinder、Heat、Keystone）来创建， `--profile` 也可以使用带有 `--os-profile` .在示例中获取 OSprofiler trace UUID for openstack server create 命令。

```
openstack --os-profile <OSPROFILER_SECRET> server create \
  --image cirros --flavor m1.tiny --key-name mykey \
  --nic net-id=${NETWORK_ID} demo
```

The previous command will output the command to retrieve OSprofiler trace.
上一个命令将输出用于检索 OSprofiler 跟踪的命令。

```
osprofiler trace show --html <TRACE_ID> --connection-string \
  elasticsearch://<api_interface_address>:9200
```

For more information about how OSprofiler works, see [OSProfiler – Cross-project profiling library](https://docs.openstack.org/osprofiler/latest/).
有关 OSprofiler 工作原理的更多信息，请参阅 OSProfiler – 跨项目分析库。

# Prometheus - Monitoring System & Time Series Database Prometheus - 监控系统和时间序列数据库

​        version 版本              





## Overview 概述 ¶

Kolla can deploy a full working Prometheus setup in either a **all-in-one** or **multinode** setup.
Kolla 可以在一体式或多节点设置中部署完整的 Prometheus 设置。

## Preparation and deployment 准备和部署 ¶

To enable Prometheus, modify the configuration file `/etc/kolla/globals.yml` and change the following:
要启用 Prometheus，请修改配置文件 `/etc/kolla/globals.yml` 并更改以下内容：

```
enable_prometheus: "yes"
```

Note: This will deploy Prometheus version 2.x. Any potentially existing Prometheus 1.x instances deployed by previous Kolla Ansible releases will conflict with current version and should be manually stopped and/or removed. If you would like to stay with version 1.x, set the `enable_prometheus` variable to `no`.
注意：这将部署 Prometheus 版本 2.x。以前的 Kolla Ansible 版本部署的任何可能存在的 Prometheus 1.x 实例都将与当前版本冲突，应手动停止和/或删除。如果要继续使用 1.x 版，请将 `enable_prometheus` 变量设置为 `no` 。

In order to remove leftover volume containing Prometheus 1.x data, execute:
要删除包含 Prometheus 1.x 数据的剩余卷，请执行：

```
docker volume rm prometheus
```

on all hosts wherever Prometheus was previously deployed.
在之前部署了 Prometheus 的所有主机上。

## Basic Auth 基本身份验证 ¶

Prometheus is protected with basic HTTP authentication. Kolla-ansible will create the following users: `admin`, `grafana` (if grafana is enabled) and `skyline` (if skyline is enabled). The grafana username can be overidden using the variable `prometheus_grafana_user`, the skyline username can be overidden using the variable `prometheus_skyline_user`. The passwords are defined by the `prometheus_password`, `prometheus_grafana_password` and `prometheus_skyline_password` variables in `passwords.yml`. The list of basic auth users can be extended using the `prometheus_basic_auth_users_extra` variable:
Prometheus 受基本 HTTP 身份验证保护。Kolla-ansible 将创建以下用户： `admin` 、 `grafana` （如果启用了 grafana）和 `skyline` （如果启用了 skyline）。grafana 用户名可以使用变量覆盖 `prometheus_grafana_user` ，skyline 用户名可以使用变量覆盖 `prometheus_skyline_user` 。密码由 `prometheus_password` 和 `prometheus_grafana_password` 中的 `prometheus_skyline_password` `passwords.yml` 变量定义。可以使用以下 `prometheus_basic_auth_users_extra` 变量扩展基本身份验证用户列表：

```
prometheus_basic_auth_users_extra:
   - username: user
     password: hello
     enabled: true
```

or completely overriden with the `prometheus_basic_auth_users` variable.
或完全被 `prometheus_basic_auth_users` 变量覆盖。

## Extending the default command line options 扩展默认命令行选项 ¶

It is possible to extend the default command line options for Prometheus by using a custom variable. As an example, to set query timeout to 1 minute and data retention size to 30 gigabytes:
可以使用自定义变量扩展 Prometheus 的默认命令行选项。例如，若要将查询超时设置为 1 分钟，将数据保留大小设置为 30 GB，请执行以下操作：

```
prometheus_cmdline_extras: "--query.timeout=1m --storage.tsdb.retention.size=30GB"
```

## Configuration options 配置选项 ¶

| Option                     | Default | Description                                                 |
| -------------------------- | ------- | ----------------------------------------------------------- |
| prometheus_scrape_interval | 60s     | Default scrape interval for all jobs 所有作业的默认抓取间隔 |

## Extending prometheus.cfg 扩展 prometheus.cfg ¶

If you want to add extra targets to scrape, you can extend the default `prometheus.yml` config file by placing additional configs in `{{ node_custom_config }}/prometheus/prometheus.yml.d`. These should have the same format as `prometheus.yml`. These additional configs are merged so that any list items are extended. For example, if using the default value for `node_custom_config`, you could add additional targets to scrape by defining `/etc/kolla/config/prometheus/prometheus.yml.d/10-custom.yml` containing the following:
如果要添加额外的目标进行抓取，可以通过在 中 `{{ node_custom_config }}/prometheus/prometheus.yml.d` 放置其他配置来扩展默认 `prometheus.yml` 配置文件。这些格式应与 `prometheus.yml` .这些附加配置将被合并，以便扩展任何列表项。例如，如果使用 的 `node_custom_config` 默认值 ，则可以通过定义 `/etc/kolla/config/prometheus/prometheus.yml.d/10-custom.yml` 包含以下内容来添加其他目标进行抓取：

```
scrape_configs:
  - job_name: custom
    static_configs:
      - targets:
        - '10.0.0.111:1234'
  - job_name: custom-template
    static_configs:
      - targets:
{% for host in groups['prometheus'] %}
        - '{{ hostvars[host]['ansible_' + hostvars[host]['api_interface']]['ipv4']['address'] }}:{{ 3456 }}'
{% endfor %}
```

The jobs, `custom`, and `custom_template`  would be appended to the default list of `scrape_configs` in the final `prometheus.yml`. To customize on a per host basis, files can also be placed in `{{ node_custom_config }}/prometheus/<inventory_hostname>/prometheus.yml.d` where, `inventory_hostname` is one of the hosts in your inventory. These will be merged with any files in `{{ node_custom_config }}/prometheus/prometheus.yml.d`, so in order to override a list value instead of extending it, you will need to make sure that no files in `{{ node_custom_config }}/prometheus/prometheus.yml.d` set a key with an equivalent hierarchical path.
作业 `custom` 、 和 `custom_template` 将追加到最终 `prometheus.yml` 的 `scrape_configs` 默认列表中。要基于每个主机进行自定义，还可以将文件放置在 `{{ node_custom_config }}/prometheus/<inventory_hostname>/prometheus.yml.d` 清单中的主机之一。 `inventory_hostname` 这些文件将与 中 `{{ node_custom_config }}/prometheus/prometheus.yml.d` 的任何文件合并，因此为了覆盖列表值而不是扩展它，您需要确保没有文件设置 `{{ node_custom_config }}/prometheus/prometheus.yml.d` 具有等效分层路径的键。

## Extra files 额外文件 ¶

Sometimes it is necessary to reference additional files from within `prometheus.yml`, for example, when defining file service discovery configuration. To enable you to do this, kolla-ansible will resursively discover any files in `{{ node_custom_config }}/prometheus/extras` and template them. The templated output is then copied to `/etc/prometheus/extras` within the container on startup. For example to configure [ipmi_exporter](https://github.com/soundcloud/ipmi_exporter), using the default value for `node_custom_config`, you could create the following files:
有时需要从内部 `prometheus.yml` 引用其他文件，例如，在定义文件服务发现配置时。为了使您能够做到这一点，kolla-ansible 将重新发现其中 `{{ node_custom_config }}/prometheus/extras` 的任何文件并对其进行模板化。然后，在启动时将模板化输出复制到 `/etc/prometheus/extras` 容器中。例如，要配置 ipmi_exporter，可以使用 的 `node_custom_config` 默认值创建以下文件：

- `/etc/kolla/config/prometheus/prometheus.yml.d/ipmi-exporter.yml`:

  ```
  ---
  scrape_configs:
  - job_name: ipmi
    params:
      module: ["default"]
      scrape_interval: 1m
      scrape_timeout: 30s
      metrics_path: /ipmi
      scheme: http
      file_sd_configs:
        - files:
            - /etc/prometheus/extras/file_sd/ipmi-exporter-targets.yml
      refresh_interval: 5m
      relabel_configs:
        - source_labels: [__address__]
          separator: ;
          regex: (.*)
          target_label: __param_target
          replacement: ${1}
          action: replace
        - source_labels: [__param_target]
          separator: ;
          regex: (.*)
          target_label: instance
          replacement: ${1}
          action: replace
        - separator: ;
          regex: .*
          target_label: __address__
          replacement: "{{ ipmi_exporter_listen_address }}:9290"
          action: replace
  ```

  where `ipmi_exporter_listen_address` is a variable containing the IP address of the node where the exporter is running.
  其中 `ipmi_exporter_listen_address` 是一个变量，其中包含运行导出器的节点的 IP 地址。

- `/etc/kolla/config/prometheus/extras/file_sd/ipmi-exporter-targets.yml`:

  ```
  ---
  - targets:
    - 192.168.1.1
  labels:
      job: ipmi_exporter
  ```

## Metric Instance labels 指标实例标签 ¶

Previously, Prometheus metrics used to label instances based on their IP addresses. This behaviour can now be changed such that instances can be labelled based on their inventory hostname instead. The IP address remains as the target address, therefore, even if the hostname is unresolvable, it doesn’t pose an issue.
以前，Prometheus 指标用于根据实例的 IP 地址标记实例。现在可以更改此行为，以便可以根据实例的清单主机名来标记实例。IP 地址仍作为目标地址，因此，即使主机名无法解析，也不会造成问题。

The default behavior still labels instances with their IP addresses. However, this can be adjusted by changing the `prometheus_instance_label` variable. This variable accepts the following values:
默认行为仍使用实例的 IP 地址标记实例。但是，这可以通过更改 `prometheus_instance_label` 变量来调整。此变量接受以下值：

- `None`: Instance labels will be IP addresses (default)
   `None` ：实例标签将为 IP 地址（默认）
- `{{ ansible_facts.hostname }}`: Instance labels will be hostnames
   `{{ ansible_facts.hostname }}` ：实例标签将是主机名
- `{{ ansible_facts.nodename }}`: Instance labels will FQDNs
   `{{ ansible_facts.nodename }}` ：实例标签将 FQDN

To implement this feature, modify the configuration file `/etc/kolla/globals.yml` and update the `prometheus_instance_label` variable accordingly. Remember, changing this variable will cause Prometheus to scrape metrics with new names for a short period. This will result in duplicate metrics until all metrics are replaced with their new labels.
要实现此功能，请修改配置文件 `/etc/kolla/globals.yml` 并相应地更新 `prometheus_instance_label` 变量。请记住，更改此变量将导致 Prometheus 在短时间内抓取具有新名称的指标。这将导致重复的指标，直到所有指标都替换为其新标签。

```
prometheus_instance_label: "{{ ansible_facts.hostname }}"
```

This metric labeling feature may become the default setting in future releases. Therefore, if you wish to retain the current default (IP address labels), make sure to set the `prometheus_instance_label` variable to `None`.
此指标标记功能可能会成为未来版本中的默认设置。因此，如果您希望保留当前默认值（IP 地址标签），请确保将 `prometheus_instance_label` 变量设置为 `None` 。



 

Note 注意



This feature may generate duplicate metrics temporarily while Prometheus updates the metric labels. Please be aware of this while analyzing metrics during the transition period.
此功能可能会在 Prometheus 更新指标标签时临时生成重复的指标。在过渡期间分析指标时，请注意这一点。