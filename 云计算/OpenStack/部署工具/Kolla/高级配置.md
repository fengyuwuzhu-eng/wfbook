# Advanced Configuration 高级配置

​        version 版本              





## Endpoint Network Configuration 端点网络配置 ¶

When an OpenStack cloud is deployed, the REST API of each service is presented as a series of endpoints. These endpoints are the admin URL, the internal URL, and the external URL.
部署 OpenStack 云时，每个服务的 REST API 都呈现为一系列端点。这些终结点是管理 URL、内部 URL 和外部 URL。

Kolla offers two options for assigning these endpoints to network addresses: - Combined - Where all three endpoints share the same IP address - Separate - Where the external URL is assigned to an IP address that is different than the IP address shared by the internal and admin URLs
Kolla 提供了两个选项，用于将这些端点分配给网络地址： - 组合 - 所有三个端点共享相同的 IP 地址 - 单独 - 将外部 URL 分配给与内部和管理员 URL 共享的 IP 地址不同的 IP 地址的位置

The configuration parameters related to these options are: - kolla_internal_vip_address - network_interface - kolla_external_vip_address - kolla_external_vip_interface
与这些选项相关的配置参数包括： - kolla_internal_vip_address - network_interface - kolla_external_vip_address - kolla_external_vip_interface

For the combined option, set the two variables below, while allowing the other two to accept their default values. In this configuration all REST API requests, internal and external, will flow over the same network.
对于组合选项，设置下面的两个变量，同时允许其他两个变量接受其默认值。在此配置中，所有内部和外部 REST API 请求都将流经同一网络。

```
kolla_internal_vip_address: "10.10.10.254"
network_interface: "eth0"
```

For the separate option, set these four variables. In this configuration the internal and external REST API requests can flow over separate networks.
对于单独的选项，请设置这四个变量。在此配置中，内部和外部 REST API 请求可以通过不同的网络流动。

```
kolla_internal_vip_address: "10.10.10.254"
network_interface: "eth0"
kolla_external_vip_address: "10.10.20.254"
kolla_external_vip_interface: "eth1"
```

## Fully Qualified Domain Name Configuration 完全限定的域名配置 ¶

When addressing a server on the internet, it is more common to use a name, like `www.example.net`, instead of an address like `10.10.10.254`. If you prefer to use names to address the endpoints in your kolla deployment use the variables:
在 Internet 上对服务器进行寻址时，更常见的是使用名称（如 `www.example.net` ，而不是 ）等 `10.10.10.254` 地址。如果您更喜欢使用名称来称呼 kolla 部署中的端点，请使用以下变量：

- kolla_internal_fqdn
- kolla_external_fqdn

```
kolla_internal_fqdn: inside.mykolla.example.net
kolla_external_fqdn: mykolla.example.net
```

Provisions must be taken outside of kolla for these names to map to the configured IP addresses. Using a DNS server or the `/etc/hosts` file are two ways to create this mapping.
必须在 kolla 之外进行预配，以便这些名称映射到配置的 IP 地址。使用 DNS 服务器或 `/etc/hosts` 文件是创建此映射的两种方法。

## RabbitMQ Hostname Resolution RabbitMQ 主机名解析 ¶

RabbitMQ doesn’t work with IP address, hence the IP address of `api_interface` should be resolvable by hostnames to make sure that all RabbitMQ Cluster hosts can resolve each others hostname beforehand.
RabbitMQ 不使用 IP 地址，因此 的 IP 地址 `api_interface` 应该可以通过主机名解析，以确保所有 RabbitMQ 集群主机都可以事先解析彼此的主机名。



## TLS Configuration TLS 配置 ¶

Configuration of TLS is now covered [here](https://docs.openstack.org/kolla-ansible/latest/admin/tls.html).
现在介绍了 TLS 的配置。



## OpenStack Service Configuration in Kolla Kolla 中的 OpenStack 服务配置 ¶

An operator can change the location where custom config files are read from by editing `/etc/kolla/globals.yml` and adding the following line.
操作员可以通过编辑 `/etc/kolla/globals.yml` 和添加以下行来更改读取自定义配置文件的位置。

```
# The directory to merge custom config files the kolla's config files
node_custom_config: "/etc/kolla/config"
```

Kolla allows the operator to override configuration of services. Kolla will generally look for a file in `/etc/kolla/config/<< config file >>`, `/etc/kolla/config/<< service name >>/<< config file >>` or `/etc/kolla/config/<< service name >>/<< hostname >>/<< config file >>`, but these locations sometimes vary and you should check the config task in the appropriate Ansible role for a full list of supported locations. For example, in the case of `nova.conf` the following locations are supported, assuming that you have services using `nova.conf` running on hosts called `controller-0001`, `controller-0002` and `controller-0003`:
Kolla 允许操作员覆盖服务的配置。Kolla 通常会在 或 `/etc/kolla/config/<< service name >>/<< config file >>` `/etc/kolla/config/<< service name >>/<< hostname >>/<< config file >>` 中 `/etc/kolla/config/<< config file >>` 查找文件，但这些位置有时会有所不同，您应该在相应的 Ansible 角色中检查配置任务，以获取受支持位置的完整列表。例如，在支持以下位置的情况下 `nova.conf` ，假设您有在 `nova.conf` 名为 `controller-0001` 和 `controller-0002` `controller-0003` 的主机上运行的服务：

- `/etc/kolla/config/nova.conf`
- `/etc/kolla/config/nova/controller-0001/nova.conf`
- `/etc/kolla/config/nova/controller-0002/nova.conf`
- `/etc/kolla/config/nova/controller-0003/nova.conf`
- `/etc/kolla/config/nova/nova-scheduler.conf`

Using this mechanism, overrides can be configured per-project, per-project-service or per-project-service-on-specified-host.
使用此机制，可以按项目、按项目服务或按指定主机上的项目服务配置替代。

Overriding an option is as simple as setting the option under the relevant section. For example, to set `override scheduler_max_attempts` in nova scheduler, the operator could create `/etc/kolla/config/nova/nova-scheduler.conf` with content:
覆盖选项就像在相关部分下设置选项一样简单。例如，要在 nova 调度器中设置 `override scheduler_max_attempts` ，操作员可以使用内容创建 `/etc/kolla/config/nova/nova-scheduler.conf` ：

```
[DEFAULT]
scheduler_max_attempts = 100
```

If the operator wants to configure compute node cpu and ram allocation ratio on host myhost, the operator needs to create file `/etc/kolla/config/nova/myhost/nova.conf` with content:
如果算子要在主机myhost上配置计算节点CPU和RAM分配比例，算线员需要创建包含内容的文件 `/etc/kolla/config/nova/myhost/nova.conf` ：

```
[DEFAULT]
cpu_allocation_ratio = 16.0
ram_allocation_ratio = 5.0
```

This method of merging configuration sections is supported for all services using Oslo Config, which includes the vast majority of OpenStack services, and in some cases for services using YAML configuration. Since the INI format is an informal standard, not all INI files can be merged in this way. In these cases Kolla supports overriding the entire config file.
使用 Oslo Config 的所有服务（包括绝大多数 OpenStack 服务）都支持这种合并配置部分的方法，在某些情况下，使用 YAML  配置的服务也支持这种合并配置部分的方法。由于 INI 格式是一种非正式标准，因此并非所有 INI  文件都可以以这种方式合并。在这些情况下，Kolla 支持覆盖整个配置文件。

Additional flexibility can be introduced by using Jinja conditionals in the config files.  For example, you may create Nova cells which are homogeneous with respect to the hypervisor model. In each cell, you may wish to configure the hypervisors differently, for example the following override shows one way of setting the `bandwidth_poll_interval` variable as a function of the cell:
通过在配置文件中使用 Jinja 条件，可以引入额外的灵活性。例如，您可以创建相对于虚拟机管理程序模型同构的 Nova 单元。在每个单元中，您可能希望以不同的方式配置虚拟机管理程序，例如，以下覆盖显示了将 `bandwidth_poll_interval` 变量设置为单元函数的一种方法：

```
[DEFAULT]
{% if 'cell0001' in group_names %}
bandwidth_poll_interval = 100
{% elif 'cell0002' in group_names %}
bandwidth_poll_interval = -1
{% else %}
bandwidth_poll_interval = 300
{% endif %}
```

An alternative to Jinja conditionals would be to define a variable for the `bandwidth_poll_interval` and set it in according to your requirements in the inventory group or host vars:
Jinja 条件的替代方法是为 定义一个变量， `bandwidth_poll_interval` 并根据您在 inventory 组或 host vars 中的要求进行设置：

```
[DEFAULT]
bandwidth_poll_interval = {{ bandwidth_poll_interval }}
```

Kolla allows the operator to override configuration globally for all services. It will look for a file called `/etc/kolla/config/global.conf`.
Kolla 允许操作员全局覆盖所有服务的配置。它将查找一个名为 `/etc/kolla/config/global.conf` .

For example to modify database pool size connection for all services, the operator needs to create `/etc/kolla/config/global.conf` with content:
例如，要修改所有服务的数据库池大小连接，操作员需要使用内容创建 `/etc/kolla/config/global.conf` ：

```
[database]
max_pool_size = 100
```

## OpenStack policy customisation OpenStack 策略定制 ¶

OpenStack services allow customisation of policy. Since the Queens release, default policy configuration is defined within the source code for each service, meaning that operators only need to override rules they wish to change. Projects typically provide documentation on their default policy configuration, for example, [Keystone](https://docs.openstack.org/keystone/latest/configuration/policy).
OpenStack 服务允许自定义策略。自 Queens 发布以来，默认策略配置是在每个服务的源代码中定义的，这意味着运营商只需要覆盖他们希望更改的规则。项目通常提供有关其默认策略配置的文档，例如 Keystone。

Policy can be customised via JSON or YAML files. As of the Wallaby release, the JSON format is deprecated in favour of YAML. One major benefit of YAML is that it allows for the use of comments.
可以通过 JSON 或 YAML 文件自定义策略。从 Wallaby 版本开始，JSON 格式已被弃用，取而代之的是 YAML。YAML 的一个主要好处是它允许使用注释。

For example, to customise the Neutron policy in YAML format, the operator should add the customised rules in `/etc/kolla/config/neutron/policy.yaml`.
例如，要以 YAML 格式自定义 Neutron 策略，操作员应在 中 `/etc/kolla/config/neutron/policy.yaml` 添加自定义规则。

The operator can make these changes after services have been deployed by using the following command:
操作员可以使用以下命令在部署服务后进行这些更改：

```
kolla-ansible deploy
```

In order to present a user with the correct interface, Horizon includes policy for other services. Customisations made to those services may need to be replicated in Horizon. For example, to customise the Neutron policy in YAML format for Horizon, the operator should add the customised rules in `/etc/kolla/config/horizon/neutron_policy.yaml`.
为了向用户提供正确的界面，Horizon 包含了其他服务的策略。对这些服务所做的自定义可能需要在 Horizon 中复制。例如，要为 Horizon 自定义 YAML 格式的 Neutron 策略，操作员应在 中 `/etc/kolla/config/horizon/neutron_policy.yaml` 添加自定义规则。

## IP Address Constrained Environments IP 地址受限环境 ¶

If a development environment doesn’t have a free IP address available for VIP configuration, the host’s IP address may be used here by disabling HAProxy by adding:
如果开发环境没有可用于 VIP 配置的空闲 IP 地址，则可以通过添加以下内容来禁用 HAProxy 来使用主机的 IP 地址：

```
enable_haproxy: "no"
```

Note this method is not recommended and generally not tested by the Kolla community, but included since sometimes a free IP is not available in a testing environment.
请注意，不推荐使用此方法，Kolla 社区通常不会对其进行测试，但会包含此方法，因为有时测试环境中没有免费 IP。

In this mode it is still necessary to configure `kolla_internal_vip_address`, and it should take the IP address of the `api_interface` interface.
在这种模式下，仍然需要配置 `kolla_internal_vip_address` ，并且它应该采用 `api_interface` 接口的 IP 地址。

## External Elasticsearch/Kibana environment 外部 Elasticsearch/Kibana 环境 ¶

It is possible to use an external Elasticsearch/Kibana environment. To do this first disable the deployment of the central logging.
可以使用外部 Elasticsearch/Kibana 环境。为此，请首先禁用中央日志记录的部署。

```
enable_central_logging: "no"
```

Now you can use the parameter `elasticsearch_address` to configure the address of the external Elasticsearch environment.
现在，您可以使用该参数 `elasticsearch_address` 配置外部 Elasticsearch 环境的地址。

## Non-default <service> port 非默认<service>端口 ¶

It is sometimes required to use a different than default port for service(s) in Kolla. It is possible with setting `<service>_port` in `globals.yml` file. For example:
有时需要在 Kolla 中使用与默认端口不同的服务端口。在 `globals.yml` 文件中设置 `<service>_port` 是可能的。例如：

```
database_port: 3307
```

As `<service>_port` value is saved in different services’ configuration so it’s advised to make above change before deploying.
由于 `<service>_port` 值保存在不同服务的配置中，因此建议在部署前进行上述更改。

## Use an external Syslog server 使用外部 Syslog 服务器 ¶

By default, Fluentd is used as a syslog server to collect Swift and HAProxy logs. When Fluentd is disabled or you want to use an external syslog server, You can set syslog parameters in `globals.yml` file. For example:
默认情况下，Fluentd 用作 syslog 服务器来收集 Swift 和 HAProxy 日志。当 Fluentd 被禁用或您想使用外部 syslog 服务器时，您可以在 `globals.yml` 文件中设置 syslog 参数。例如：

```
syslog_server: "172.29.9.145"
syslog_udp_port: "514"
```

You can also set syslog facility names for Swift and HAProxy logs. By default, Swift and HAProxy use `local0` and `local1`, respectively.
您还可以为 Swift 和 HAProxy 日志设置 syslog 工具名称。默认情况下，Swift 和 HAProxy 分别使用 `local0` 和 `local1` 。

```
syslog_swift_facility: "local0"
syslog_haproxy_facility: "local1"
```

If Glance TLS backend is enabled (`glance_enable_tls_backend`), the syslog facility for the `glance_tls_proxy` service uses `local2` by default. This can be set via `syslog_glance_tls_proxy_facility`.
如果启用了 Glance TLS 后端 （ `glance_enable_tls_backend` ），则默认使用 `glance_tls_proxy`  `local2` 服务的 syslog 工具。这可以通过 `syslog_glance_tls_proxy_facility` 进行设置。

If Neutron TLS backend is enabled (`neutron_enable_tls_backend`), the syslog facility for the `neutron_tls_proxy` service uses `local4` by default. This can be set via `syslog_neutron_tls_proxy_facility`.
如果启用了 Neutron TLS 后端 （ `neutron_enable_tls_backend` ），则默认使用 `neutron_tls_proxy`  `local4` 服务的 syslog 工具。这可以通过 `syslog_neutron_tls_proxy_facility` 进行设置。

## Mount additional Docker volumes in containers 在容器中挂载其他 Docker 卷 ¶

It is sometimes useful to be able to mount additional Docker volumes into one or more containers. This may be to integrate 3rd party components into OpenStack, or to provide access to site-specific data such as x.509 certificate bundles.
有时，能够将其他 Docker 卷装载到一个或多个容器中很有用。这可能是将第三方组件集成到 OpenStack 中，或者提供对特定于站点的数据（如 x.509 证书包）的访问。

Additional volumes may be specified at three levels:
可以在三个级别指定其他卷：

- globally 全球
- per-service (e.g. nova) 每个服务（例如 NOVA）
- per-container (e.g. `nova-api`)
  每个容器（例如） `nova-api` 

To specify additional volumes globally for all containers, set `default_extra_volumes` in `globals.yml`. For example:
要全局指定所有容器的其他卷，请在 `globals.yml` 中设置 `default_extra_volumes` 。例如：

```
default_extra_volumes:
  - "/etc/foo:/etc/foo"
```

To specify additional volumes for all containers in a service, set `<service_name>_extra_volumes` in `globals.yml`. For example:
要为服务中的所有容器指定其他卷，请在 `globals.yml` 中设置 `<service_name>_extra_volumes` 。例如：

```
nova_extra_volumes:
  - "/etc/foo:/etc/foo"
```

To specify additional volumes for a single container, set `<container_name>_extra_volumes` in `globals.yml`. For example:
要为单个容器指定其他卷，请在 `globals.yml` 中设置 `<container_name>_extra_volumes` 。例如：

```
nova_libvirt_extra_volumes:
  - "/etc/foo:/etc/foo"
```