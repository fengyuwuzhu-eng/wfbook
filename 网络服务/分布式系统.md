# 分布式系统

分布式系统主要分成存储模型和计算模型两类。其中计算模型的分布式系统原理与存储模型类似，只是会根据自身计算特点加一些特殊调度逻辑进去。任何一个分布式系统都需要考虑如下几个问题：

1. 数据如何存储

   就像把鸡蛋放进篮子里面。一般来说篮子大小是一样的，当然也有的系统支持不一样大小的篮子。鸡蛋大小也不一样，有很多系统就把鸡蛋给“切割”成一样大小然后再放。并且有的鸡蛋表示对篮子有要求，如对机房/机架位的要求。衡量一个数据分布算法好不好就看它是否分得足够均匀，使得所有机器的负载方差足够小。

2. 数据如何容灾

   分布式系统一个很重要的定位就是要让程序自动来管机器，尽量减少人工参与，否则一个分布式系统的运维成本将是不可接受的。系统中最容易出问题的硬盘的年故障率可能会达到 10%。这样算下来一个有 1000 台机器的集群，每一个星期就会有2台机器宕机。在机器数量大了之后，这是一个很正常的事情。一般一台机器出故障之后修复周期是 24 小时，这个过程中进行人工接入换设备或者重启机器。在机器恢复之后内存信息完全丢失，硬盘信息可能可以保存。一个分布式系统必须保证一台机器的宕机对服务不受影响，并且在修复好了之后再重新放到集群当中之后也能正常工作，

3. 网络故障

   网络故障是最常见的故障，就是该问题会大大增加分布式系统设计的难度，故障一般发生在网络拥塞、路由变动、设备异常等情况出现时。出现的问题可能是丢包，可能是延时，也可能是完全失去连接。有鉴于此，一般在设计分布式系统的时候，四层协议都采用TCP，很少采用 UDP/UDT 协议。而且由于 TCP 协议并不能完全保证数据传输到对面，如当再发送数据，只要数据写入本地缓冲区，操作系统就会返回应用层说发送成功，但是有可能根本没送到对面。所以一般还需要加上应用层的 ACK ，来保证网络层的行为是可预期的。

4. 如何保证数据读写一致性

   想获知数据是否具有一致性很简单，就是更新/删除请求返回之后，别人是否能读到新写的这个值。对于单机系统，这个一致性要达到很简单，大不了是损失一点写的效率。但是对于分布式系统就复杂了。为了容灾，一份数据肯定有多个副本，那么如何更新这多个副本以及控制读写协议就成了一个大问题。而且有的写操作可能会跨越多个分片，复制副本的时候甚至出现网络故障，造成保证数据一致性的难度成倍增加。

   对于普通用户而言，常见的数据存储方式为集中式存储，例如，计算机中 C 盘，或者映射的网络硬盘等，一旦硬盘出现故障，系统将出现不可恢复的故障。与传统集中式存储不同，分布式存储技术并不是将数据存储在某个或多个特定的节点上，而是通过网络使用企业中的每台机器上的硬盘空间，并将这些分散的存储资源构成一个虚拟的存储设备，数据分散在企业的各个角落，每个分散的数据甚至复制多个副本进行分散存储在不同节点，一旦某个副本出现，如上面的网络故障或者丢失等，通过一致性检查，出现故障或丢失的副本即将被恢复出来。

   常见的分布式文件系统有 HDFS、GlusterFS、Lustre、MooseFS、Ceph 等。各自适用于不同的领域。它们都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。

   