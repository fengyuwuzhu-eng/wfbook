# 监控 etcd

Monitoring etcd for system health & cluster debugging
监控 etcd 以进行系统运行状况和集群调试



Each etcd server provides local monitoring information on its client port  through http endpoints. The monitoring data is useful for both system  health checking and cluster debugging.
每个 etcd 服务器都通过 http 端点在其客户端端口上提供本地监控信息。监控数据对于系统运行状况检查和集群调试都很有用。

## Debug endpoint 调试终结点

If `--log-level=debug` is set, the etcd server exports debugging information on its client port under the `/debug` path. Take care when setting `--log-level=debug`, since there will be degraded performance and verbose logging.
如果 `--log-level=debug` 设置了，则 etcd 服务器会在 `/debug` 路径下导出其客户端端口上的调试信息。设置 `--log-level=debug` 时要小心，因为会有性能下降和详细日志记录。

The `/debug/pprof` endpoint is the standard go runtime profiling endpoint. This can be  used to profile CPU, heap, mutex, and goroutine utilization. For  example, here `go tool pprof` gets the top 10 functions where etcd spends its time:
端 `/debug/pprof` 点是标准的 go 运行时分析端点。这可用于分析 CPU、堆、互斥锁和 goroutine 利用率。例如，这里 `go tool pprof` 列出了 etcd 花费时间的前 10 个函数：

```sh
$ go tool pprof http://localhost:2379/debug/pprof/profile
Fetching profile from http://localhost:2379/debug/pprof/profile
Please wait... (30s)
Saved profile in /home/etcd/pprof/pprof.etcd.localhost:2379.samples.cpu.001.pb.gz
Entering interactive mode (type "help" for commands)
(pprof) top10
310ms of 480ms total (64.58%)
Showing top 10 nodes out of 157 (cum >= 10ms)
    flat  flat%   sum%        cum   cum%
   130ms 27.08% 27.08%      130ms 27.08%  runtime.futex
    70ms 14.58% 41.67%       70ms 14.58%  syscall.Syscall
    20ms  4.17% 45.83%       20ms  4.17%  github.com/coreos/etcd/vendor/golang.org/x/net/http2/hpack.huffmanDecode
    20ms  4.17% 50.00%       30ms  6.25%  runtime.pcvalue
    20ms  4.17% 54.17%       50ms 10.42%  runtime.schedule
    10ms  2.08% 56.25%       10ms  2.08%  github.com/coreos/etcd/vendor/github.com/coreos/etcd/etcdserver.(*EtcdServer).AuthInfoFromCtx
    10ms  2.08% 58.33%       10ms  2.08%  github.com/coreos/etcd/vendor/github.com/coreos/etcd/etcdserver.(*EtcdServer).Lead
    10ms  2.08% 60.42%       10ms  2.08%  github.com/coreos/etcd/vendor/github.com/coreos/etcd/pkg/wait.(*timeList).Trigger
    10ms  2.08% 62.50%       10ms  2.08%  github.com/coreos/etcd/vendor/github.com/prometheus/client_golang/prometheus.(*MetricVec).hashLabelValues
    10ms  2.08% 64.58%       10ms  2.08%  github.com/coreos/etcd/vendor/golang.org/x/net/http2.(*Framer).WriteHeaders
```

The `/debug/requests` endpoint gives gRPC traces and performance statistics through a web browser. For example, here is a `Range` request for the key `abc`:
 `/debug/requests` 终结点通过 Web 浏览器提供 gRPC 跟踪和性能统计信息。例如，下面是对 `Range` 密钥 `abc` 的请求：

```
When	Elapsed (s)
2017/08/18 17:34:51.999317 	0.000244 	/etcdserverpb.KV/Range
17:34:51.999382 	 .    65 	... RPC: from 127.0.0.1:47204 deadline:4.999377747s
17:34:51.999395 	 .    13 	... recv: key:"abc"
17:34:51.999499 	 .   104 	... OK
17:34:51.999535 	 .    36 	... sent: header:<cluster_id:14841639068965178418 member_id:10276657743932975437 revision:15 raft_term:17 > kvs:<key:"abc" create_revision:6 mod_revision:14 version:9 value:"asda" > count:1
```

## Metrics endpoint 指标终结点

Each etcd server exports metrics under the `/metrics` path on its client port and optionally on locations given by `--listen-metrics-urls`.
每个 etcd 服务器在其客户端端口的 `/metrics` 路径下导出指标，也可以在 提供 `--listen-metrics-urls` 的位置导出指标。

The metrics can be fetched with `curl`:
可以通过以下方式 `curl` 获取指标：

```sh
$ curl -L http://localhost:2379/metrics | grep -v debugging # ignore unstable debugging metrics

# HELP etcd_disk_backend_commit_duration_seconds The latency distributions of commit called by backend.
# TYPE etcd_disk_backend_commit_duration_seconds histogram
etcd_disk_backend_commit_duration_seconds_bucket{le="0.002"} 72756
etcd_disk_backend_commit_duration_seconds_bucket{le="0.004"} 401587
etcd_disk_backend_commit_duration_seconds_bucket{le="0.008"} 405979
etcd_disk_backend_commit_duration_seconds_bucket{le="0.016"} 406464
...
```

## Health Check 健康检查

Since v3.3.0, in addition to responding to the `/metrics` endpoint, any locations specified by `--listen-metrics-urls` will also respond to the `/health` endpoint. This can be useful if the standard endpoint is configured  with mutual (client) TLS authentication, but a load balancer or  monitoring service still needs access to the health check.
从 v3.3.0 开始，除了响应 `/metrics` 端点外，指定的 `--listen-metrics-urls` 任何位置也会响应端 `/health` 点。如果标准终端节点配置了相互（客户端）TLS 身份验证，但负载均衡器或监控服务仍需要访问运行状况检查，则这可能很有用。

Since v3.5.12, two new endpoints `/livez` and `/readyz` are added.
从 v3.5.12 开始，添加了两个新的端点 `/livez`  `/readyz` 。

- the `/livez` endpoint reflects whether the process is alive or if it needs a restart.
   `/livez` 终结点反映进程是否处于活动状态或是否需要重新启动。
- the `/readyz` endpoint reflects whether the process is ready to serve traffic.
   `/readyz` 终结点反映进程是否准备好为流量提供服务。

Design details of the endpoints are documented in the [KEP](https://github.com/kubernetes/enhancements/tree/master/keps/sig-etcd/4331-livez-readyz).
端点的设计细节记录在 KEP 中。

Each endpoint includes several individual health checks, and you can use the `verbose` parameter to print out the details of the checks and their status, for example
每个终端节点都包含多个单独的运行状况检查，例如，您可以使用该 `verbose` 参数打印出检查的详细信息及其状态

```bash
curl -k http://localhost:2379/readyz?verbose
```

and you would see the response similar to
你会看到类似于

```text
[+]data_corruption ok
[+]serializable_read ok
[+]linearizable_read ok
ok
```

The http API also supports to exclude specific checks, for example
http API 还支持排除特定检查，例如

```bash
curl -k http://localhost:2379/readyz?exclude=data_corruption
```

## Prometheus 普罗 米修斯

Running a [Prometheus](https://prometheus.io/) monitoring service is the easiest way to ingest and record etcd’s metrics.
运行 Prometheus 监控服务是摄取和记录 etcd 指标的最简单方法。

First, install Prometheus:
首先，安装 Prometheus：

```sh
PROMETHEUS_VERSION="2.0.0"
wget https://github.com/prometheus/prometheus/releases/download/v$PROMETHEUS_VERSION/prometheus-$PROMETHEUS_VERSION.linux-amd64.tar.gz -O /tmp/prometheus-$PROMETHEUS_VERSION.linux-amd64.tar.gz
tar -xvzf /tmp/prometheus-$PROMETHEUS_VERSION.linux-amd64.tar.gz --directory /tmp/ --strip-components=1
/tmp/prometheus -version
```

Set Prometheus’s scraper to target the etcd cluster endpoints:
将 Prometheus 的抓取工具设置为以 etcd 集群端点为目标：

```sh
cat > /tmp/test-etcd.yaml <<EOF
global:
  scrape_interval: 10s
scrape_configs:
  - job_name: test-etcd
    static_configs:
    - targets: ['10.240.0.32:2379','10.240.0.33:2379','10.240.0.34:2379']
EOF
cat /tmp/test-etcd.yaml
```

Set up the Prometheus handler:
设置 Prometheus 处理程序：

```sh
nohup /tmp/prometheus \
    -config.file /tmp/test-etcd.yaml \
    -web.listen-address ":9090" \
    -storage.local.path "test-etcd.data" >> /tmp/test-etcd.log  2>&1 &
```

Now Prometheus will scrape etcd metrics every 10 seconds.
现在 Prometheus 将每 10 秒抓取一次 etcd 指标。

### Alerting 提醒

There is a set of [default alerts](https://github.com/etcd-io/etcd/tree/master/contrib/mixin) for etcd v3 clusters for Prometheus.
Prometheus 的 etcd v3 集群有一组默认警报。

#### Note 注意

Note that `job` labels may need to be adjusted to fit a particular need. The rules were written to apply to a single cluster so it is recommended to choose  labels unique to a cluster.
请注意， `job` 可能需要调整标签以满足特定需求。这些规则是为应用于单个集群而编写的，因此建议选择集群独有的标签。

### Grafana 格拉法纳

[Grafana](http://grafana.org/) has built-in Prometheus support; just add a Prometheus data source:
Grafana 内置了 Prometheus 支持;只需添加一个 Prometheus 数据源：

```
Name:   test-etcd
Type:   Prometheus
Url:    http://localhost:9090
Access: proxy
```

Then import the default [etcd dashboard template](https://etcd.io/docs/v3.5/op-guide/grafana.json) and customize. For instance, if Prometheus data source name is `my-etcd`, the `datasource` field values in JSON also need to be `my-etcd`.
然后导入默认的 etcd 仪表板模板并进行自定义。例如，如果 Prometheus 数据源名称为 `my-etcd` ，则 JSON 中的 `datasource` 字段值也需要为 `my-etcd` 。

Sample dashboard: 示例仪表板：

![img](https://etcd.io/docs/v3.5/op-guide/etcd-sample-grafana.png)

## Distributed tracing 分布式跟踪

In v3.5 etcd has added support for distributed tracing using [OpenTelemetry](https://github.com/open-telemetry).
在 v3.5 中，etcd 添加了对使用 OpenTelemetry 进行分布式跟踪的支持。

#### Note 注意

This feature is still experimental and can change at any time.
此功能仍处于实验阶段，可以随时更改。

To enable this experimental feature, pass the `--experimental-enable-distributed-tracing=true` to the etcd server, along with the `--experimental-distributed-tracing-sampling-rate=<number>` flag to choose how many samples to collect per million spans, the default sampling rate is `0`.
要启用此实验性功能，请将 传递 `--experimental-enable-distributed-tracing=true` 给 etcd 服务器，并带有 `--experimental-distributed-tracing-sampling-rate=<number>` 标志以选择每百万个跨度收集多少样本，默认采样率为 `0` 。

Configure the distributed tracing by starting etcd server with the following optional flags:
通过使用以下可选标志启动 etcd 服务器来配置分布式跟踪：

- `--experimental-distributed-tracing-address` - (Optional) - “localhost:4317” - Address of the tracing collector.
   `--experimental-distributed-tracing-address` - （可选） - “localhost：4317” - 跟踪收集器的地址。
- `--experimental-distributed-tracing-service-name` - (Optional) - “etcd” - Distributed tracing service name, must be same across all etcd instances.
   `--experimental-distributed-tracing-service-name` - （可选） - “etcd” - 分布式跟踪服务名称，在所有 etcd 实例中必须相同。
- `--experimental-distributed-tracing-instance-id` - (Optional) - Instance ID, while optional it’s strongly recommended to set, must be unique per etcd instance.
   `--experimental-distributed-tracing-instance-id` - （可选） - 实例 ID，虽然是可选的，但强烈建议设置，但每个 etcd 实例必须是唯一的。

Before enabling the distributed tracing, make sure to have the OpenTelemetry  endpoint, if that address differs to the default one, override with the `--experimental-distributed-tracing-address` flag. Due to OpenTelemetry having different ways of running, refer to the [collector documentation](https://opentelemetry.io/docs/collector/getting-started/) to learn more.
在启用分布式跟踪之前，请确保 OpenTelemetry 终结点（如果该地址与默认地址不同）使用 `--experimental-distributed-tracing-address` 标志进行覆盖。由于 OpenTelemetry 具有不同的运行方式，请参阅收集器文档以了解更多信息。

#### Note 注意

There is a resource overhead, as with any observability signal, according to  our initial measurements that overhead could be between 2% - 4% CPU  overhead.
与任何可观测性信号一样，存在资源开销，根据我们的初始测量，开销可能在 2% - 4% 的 CPU 开销之间。