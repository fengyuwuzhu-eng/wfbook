# HTTP 负载均衡器

[TOC]

## 简介

跨多个应用程序实例的负载平衡是优化资源利用率、最大化吞吐量、减少延迟和确保容错配置的常用技术。

可以使用 nginx 作为一个非常有效的 HTTP 负载平衡器，将流量分配到多个应用程序服务器，并使用 nginx 提高web 应用程序的性能、可扩展性和可靠性。

## 负载均衡方法

nginx 支持以下负载平衡机制（或方法）：

- round-robin              以循环方式分发对应用服务器的请求。
- least-connected       将下一个请求分配给活动连接数最少的服务器。
- ip-hash                       哈希函数用于确定下一个请求应选择哪个服务器（基于客户端的 IP 地址）。

## 默认负载平衡配置

nginx 负载平衡的最简单配置如下：

```nginx
http {
  upstream myapp1 {
    server srv1.example.com;
    server srv2.example.com;
    server srv3.example.com;
  }

  server {
    listen 80;

    location / {
        proxy_pass http://myapp1;
    }
  }
}
```

在上面的示例中，有 3 个相同应用程序的实例在 srv1-srv3 上运行。如果未专门配置负载均衡方法，则默认为轮询 round-robin 。所有请求都代理到服务器组 myapp1，nginx 应用 HTTP 负载均衡来分发请求。

nginx 中的反向代理实现，包括 HTTP、HTTPS、FastCGI、uwsgi、SCGI、memcached 和 gRPC 的负载均衡。

要为 HTTPS 而不是 HTTP 配置负载平衡，只需使用 https 作为协议即可。

为 FastCGI、uwsgi、SCGI、memcached 或 gRPC 设置负载均衡时，请分别使用 fastcgi_pass、uwsgi_pass、scgi_pass、memcached_pass 和 grpc_pass 指令。

## 连接最少的负载均衡

Another load balancing discipline is least-connected. Least-connected allows controlling the load on application instances more fairly in a situation when some of the requests take longer to complete.另一个负载平衡规则是连接最少的。“连接最少”允许在某些请求需要更长的时间才能完成的情况下更公平地控制应用程序实例上的负载。

With the least-connected load balancing, nginx will try not to overload a busy application server with excessive requests, distributing the new requests to a less busy server instead.通过连接最少的负载均衡，nginx 将尽量不因过多的请求而使繁忙的应用程序服务器过载，而是将新请求分发到不太繁忙的服务器。

Least-connected load balancing in nginx is activated when the [ least_conn](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#least_conn) directive is used as part of the server group configuration:当 least_conn 指令用作服务器组配置的一部分时，将激活 nginx 中的最小连接负载平衡：

```nginx
upstream myapp1 {
  least_conn;
  server srv1.example.com;
  server srv2.example.com;
  server srv3.example.com;
} 
```

## 会话持久性

Please note that with round-robin or least-connected load balancing, each subsequent client’s request can be potentially distributed to a different server. There is no guarantee that the same client will be always directed to the same server.

If there is the need to tie a client to a particular application server — in other words, make the client’s session “sticky” or “persistent” in terms of always trying to select a particular server — the ip-hash load balancing mechanism can be used.

With ip-hash, the client’s IP address is used as a hashing key to determine what server in a server group should be selected for the client’s requests. This method ensures that the requests from the same client will always be directed to the same server except when this server is unavailable.

To configure ip-hash load balancing, just add the [ip_hash](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#ip_hash) directive to the server (upstream) group configuration:

```nginx
upstream myapp1 {
ip_hash;
server srv1.example.com;
server srv2.example.com;
server srv3.example.com;
}
```

## Weighted load balancing

It is also possible to influence nginx load balancing algorithms even further by using server weights.

In the examples above, the server weights are not configured which means that all specified servers are treated as equally qualified for a particular load balancing method.

With the round-robin in particular it also means a more or less equal distribution of requests across the servers — provided there are enough requests, and when the requests are processed in a uniform manner and completed fast enough.

When the [weight](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) parameter is specified for a server, the weight is accounted as part of the load balancing decision.

```nginx
upstream myapp1 {
  server srv1.example.com weight=3;
  server srv2.example.com;
  server srv3.example.com;
}
```

With this configuration, every 5 new requests will be distributed across the application instances as the following: 3 requests will be directed to srv1, one request will go to srv2, and another one — to srv3.

It is similarly possible to use weights with the least-connected and ip-hash load balancing in the recent versions of nginx.



## Health checks

Reverse proxy implementation in nginx includes in-band (or passive) server health checks. If the response from a particular server fails with an error, nginx will mark this server as failed, and will try to avoid selecting this server for subsequent inbound requests for a while.

The [max_fails](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) directive sets the number of consecutive unsuccessful attempts to communicate with the server that should happen during [fail_timeout](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server). By default, [max_fails](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) is set to 1. When it is set to 0, health checks are disabled for this server. The [fail_timeout](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) parameter also defines how long the server will be marked as failed. After [fail_timeout](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server) interval following the server failure, nginx will start to gracefully probe the server with the live client’s requests. If the probes have been successful, the server is marked as a live one.



## Further reading

In addition, there are more directives and parameters that control server load balancing in nginx, e.g. [proxy_next_upstream](https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream), [backup](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server), [down](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#server), and [keepalive](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive). For more information please check our [reference documentation](https://nginx.org/en/docs/).

Last but not least, [ application load balancing](https://www.nginx.com/products/application-load-balancing/), [ application health checks](https://www.nginx.com/products/application-health-checks/), [ activity monitoring](https://www.nginx.com/products/live-activity-monitoring/) and [ on-the-fly reconfiguration](https://www.nginx.com/products/on-the-fly-reconfiguration/) of server groups are available as part of our paid NGINX Plus subscriptions.

The following articles describe load balancing with NGINX Plus in more detail:

- [ Load Balancing with NGINX and NGINX Plus](https://www.nginx.com/blog/load-balancing-with-nginx-plus/)
- [ Load Balancing with NGINX and NGINX Plus part 2](