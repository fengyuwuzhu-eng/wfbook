# 文件系统

[TOC]

## 概述

随着 Linux 从各种不同的操作系统吸收了许多特性，Linux 上的文件系统一直在快速演变。每种类型的文件系统解决不同的问题，它们的用法是特定于应用程序的。使用有关关键差异和注意事项的信息，来根据特定应用程序要求部署合适的文件系统。内核的 VFS（Virtual File System，虚拟文件系统）层对于 PC 来说特别方便，因为它提供了安装“原始’文件系统（比如臭名昭著的 Windows FAT 文件系统）所需要的框架。

快速小测验：在“文件系统”中，会找到下面的哪一项?

* 进程
* 串行端口(串口)
* 内核数据结构和调整参数
* 进程间的通信通道。

如果系统是 Linux，那么答案是“以上全是”。当然，也会在文件系统里找到一些文件（或许更为准确的说法是这些东西都在文件系统内表示。在大多数情况下，文件系统作为一个结合点，把客户程序同它们所要用的驱动程序和服务程序联系起来。）。

尽管文件系统的基本目的是表示和组织系统的存储资源，但程序员一直渴望在处理其他类型对象时，避免重新设计表示结构。事实已经多次证明，把那些对象映射到文件系统的名字空间里是自然和方便的做法。这种统一既有优点（一致的编程接口、易于从 shell 访问），也有一些缺点（有“自作自受”之嫌的文件系统实现）。但是，不管您是否喜欢，这已经成为了 UNIX （因此也是 Linux ）的方式。

可以认为文件系统包括 4 种主要的组成部分：

* 名字空间--给事物取名，并按一种层次结构组织它们。
* API--用来遍历和操作对象的一套系统调用（Application Programming Interface(应用程序编程接口)，它是一个通用术语，用于描述由库、操作系统或软件包提供给程序员来调用的一组例程。）。
* 安全模型--用来保护、隐藏和共享事物的方案。
* 实现--把逻辑模型同实际硬件联系到一起的软件。

Linux 定义了一个抽象的内核级接口，能够适应多种不同的后端文件系统。文件树的有些部分由传统的基于磁盘的实现来处理；其他部分则由内核中单独的驱动程序来负责。例如，NFS 文件系统由一个驱动程序来处理，这个驱动程序把被请求的操作转发到另外一台计算机的服务器。

遗憾的是，体系结构上的界线划分并不清晰，因此还有许多特殊的情形。例如，设备文件的存在给程序提供了一种同内核内部的驱动程序进行通信的方式。这些设备文件不是真正的数据文件，但它们由基本的文件系统驱动程序来处理，并且它们的特征都存储在磁盘上。如果现在根据过去几十年的经验重新实现文件系统的话，那么在细节方面会有些区别。

另外还有一个因素使问题变复杂(但最终还是有益的)，即 Linux 支持不只一种基于磁盘的文件系统。现在最好的一类文件系统包括：作为大多数 Linux 发行版本默认文件系统的 ext3fs，还有 ReiserFS 、IBM 的 JFS 和 SGI 的 XFS 。ext3fs 之前的 ext2fs 比较老了，但所有的发行版本都支持它，将来很长一段时间里也仍然会保持对它的支持在。

Linux 上也实现了许多外来的文件系统，比如在微软 Windows 上使用的文件系统 FAT 和 NTFS，以及 CD-ROM 上使用的 ISO-9660 文件系统。Linux 支持的文件系统数量超过了任何一种别的 UNIX 变体。它提供的丰富选择赋予了用户更多的灵活性，而且更易于和别的系统共享文件。

## 路径名称

文件系统表现为单个统一的层次结构：从目录 `/` 开始并通过若干数量的子目录继续向下扩展，`/` 也叫做根目录。（这种单一层次结构的系统和 Windows 所采用的不一样，Windows 保留了特定于磁盘的名字空间概念。）

为了找到某个特定文件而必须遍历的一系列目录，再加上文件名就形成了“路径名”。路径名既可以是绝对的（/tmp/foo），也可以是相对的（book4/lesystem）。相对路径认为是从当前目录开始。用户可能习惯于把当前目录看作是 shell 的特色，但实际上每个进程也都拥有一个当前目录。

术语文件（file）、文件名（filename）、路径名（pathname）、路径（path）或多或少都可以互换使用。文件名和路径可以用来指绝对路径和相对路径，路径名通常表示绝对路径。

文件系统的深度可以任意。不过，路径名每部分的长度一定不能超过 255 个字符，并且单个路径总长不能超过 4095 个字符。要访问超过这个长度的路径名，就必须 cd 到中间的目录并使用相对路径。（多数文件系统的磁盘格式本身并没有对路径名称的总体长度进行限制。但是，访问文件系统的系统调用不允许它们的字符串参数的长度超过 4095 个字符。）

除了名称在长度上有限制和不能够包含 “`/`” 字符或空值以外，对文件和目录的命名基本上没有什么其他限制。特别是在一定程度上允许使用空格。由于 UNIX 长期以来有着以空白来分隔命令行参数的传统，所以当文件名中出现空格时，老软件可能会出现问题。

在文件名中有空白的情况过去主要出现在与 Mac 和 PC 共享的文件系统上，但是现在已经蔓延到 Linux 的文化之中，在一些标准的软件包里也能看到这样的文件名了。没别的办法，负责系统管理的脚本必须做好处理空白的准备。

在 shell 和在脚本中，只需用引号扩起带有空白的文件名，就能保持其完整性。例如，命令 `less "My excellent file.txt"` 会把 `My excellent file.txt` 当作是 less 的单个参数。还可以用反斜线转移空格。常用 shell 所带的文件名补全功能（通常绑定到<tab>键上）就能替用户做转移。

在编写脚本的时候，要知道一个很有用的工具，这就是 `find` 命令的 `-print0` 选项。这个选项和 xargs -0 起使用就能让 find / xargs 命令组合不管文件名是否包含有空白都能争取执行。例如，下面的命令:

```bash
find /home -size +1M -print0 | xargs -0 ls -l
```

找到 /home 分区下大小超过 1MB 的每个文件，按 ls 命令的长格式列出。

## 挂载和卸载文件系统

文件系统由更小一些的块所组成，这些块儿也叫文件系统，每个这样的块都是由一个目录及其子目录和文件所组成的。正常情况下，根据上下文就可以明确判断出正在讨论的是哪种类型的“文件系统”，但为了清楚起见，将使用术语“文件树”来指文件系统的整个结构，而保留“文件系统”一词用来表示附加到文件树的块。

大多数文件系统是磁盘分区，文件系统可以是遵循适当 API 的任何事物：网络文件服务器、内核组件、基于内存的磁盘模拟器等。Linux 甚至有一个不错的 “loopback (环回)” 文件系统，能让用户安装单个文件，就好像它们是独立的设备一样。

使用 mount 命令把文件系统附加到文件树上。mount 把现有文件树中的一个目录映射为新加入的文件系统的根，这个目录叫做安装点 (mountpoint) 。只要有另一个文件系统被安装在安装点上，那么就不能再访问到这个安装点以前的内容了。不过安装点通常是一些空目录。例如，命令：

```bash
mount /dev/hda4 /users
```

将把存储在磁盘分区上由 /dev/hda4 表示的文件系统安装到路径 /users 下。随后可以使用 `Is /users` 来查看这个文件系统的内容。

根据惯例，安装在某个特定系统上的文件系统清单保存在 `/etc/fstab` 文件中。包含在这个文件中的信息让这些文件系统在引导时先检查（`fsck -A`）再自动安装（mount -a）到系统中。它还充当了磁盘上文件系统布局的文档资料这一角色，并可以使用像 mount /usr 这样的简写命令（文件系统要安装的位置可以在 fstab 中査到）。

umount 命令用来卸载文件系统。在大多数系统上，不能卸载正处于“busy(繁忙)” 状态的文件系统。在该文件系统中不能有任何打开的文件，也不能有任何进程的当前目录，并且如果文件系统包含有可执行的程序，那么这些程序也不能够处于运行状态。

2.4.11 版以后的 Linux 内核定义了一种 “lazy(缓慢)” 的卸载方式（用 `umount -l` 命令调用)，在从目录名的层次结构中删除某个文件系统的时候，先要让当前所有对该文件系统内文件的访问都关闭，才能真正卸载这个文件系统。首先，不能保证当前的访问都会自行关闭。其次，“半卸载”状态也给使用文件系统的程序带来了不一致的文件系统语义。它们可以通过已有的文件句柄执行读写操作，却不能打开新文件或者执行其他文件系统操作。

如果内核抱怨说用户正在试图卸载处于繁忙状态的文件系统，可以运行 fuser 命令来查明原因。当以 -mv 标志加一个安装点为参数来调用 fuser 命令时，它会显示出正在使用该文件系统上的文件或目录的每个进程的 PID ：

```bash
fuser -mv /usr

		USER	PID	ACCESS 	COMMAND
/usr	root	444	....m	atd
		root	499	....m	sshd
		root	520	....m	lpd
		...
```

ACCESS 列的字母代码表示每个进程对 unmount 命令产生的反应。

| 代码 | 含义                                                         |
| ---- | ------------------------------------------------------------ |
| f    | 进程有一个为了读或者写而打开的文件。                         |
| c    | 进程的当前目录在这个文件系统上。                             |
| e    | 进程目前在执行一个文件。                                     |
| r    | 进程的根目录（用 chroot 命令设置）在这个文件系统上。         |
| m    | 进程已经映射了一个文件或者共享库（通常是一个非主动的可执行文件）。 |

为了准确地判断带来麻烦的进程是什么，只要用 fuser 返回的 PID 清单运行一下 ps 就行了。例如：

```bash
ps -fp "444 499 520"
UID		PID	PPID	C	STIME TTY 	TIME		CMD
daemon	444	1		0	Apr11	?	00:00:00	/usr/sbin/atd
root	499	1		0	Apr11	?	00:00:23	/usr/sbin/sshd
lp		520	1		0	Apr11	?	00:00:00	[lpd]
```

引号强迫 shell 将 PID 清单作为一个参数传递给 ps 。

fuser 也能报告特定文件（与整个文件系统相反）的使用，语法是 `fuser -v flename` 。fuser 也接受 `-k` 选项，杀死每个带来麻烦的进程（或者向它们发送一个信号）。危险——您必须是 root （或者使用 sudo ）。

fuser 的替代工具是程序 Isof ，它是由普渡大学（Purdue University）的 Vic Abell 编写的。lsof 在许多不同的 UNIX 和 Linux 变体上都能运行，这使得它很适合由必须在多种系统上运行的脚本调用。Isof 是一种比 fuser 更复杂和先进的程序，它的输出相应地也详细一些。

脚本在搜索特殊信息的时候也可以直接去读 /proc 下的文件。不过，更简单、移植性更好的一种做法是使用 `lsof -F` 命令让 Isof 的输出有格式，从而易于分析。再加上其他命令行标志来限定只请求所需的信息。

## 文件树的组织

UNIX 家族的文件系统还从来没有被很好地组织过。各种互不兼容的命名约定在同时使用，整个名字空间中随意散落着不同类型的文件。在许多情况下，文件是按照其功能而不是按照被修改的可能性进行划分的，这使得操作系统的升级变得困难起来。例如，/etc 目录中既包含了一些从来就不需要定制的文件，又包含了一些完全是本地性的文件。如何知道哪些文件在升级过程中应该保存呢？是的，管理员确实必须知道 ……

像 /var 这样的新增目录已经帮助解决了一些问题，但是大多数系统仍然处于缺乏组织的状态。尽管如此，每一个文件还都有其从文化意义上看是合适的位置。在 Linux 下，不要弄乱文件树的默认结构尤其重要，因为软件包和它们的安装工具经常对文件的位置做出大胆的假设（就像其他系统管理员那样！）。

根文件系统包括根目录和最小的一组文件和子目录，包含内核的那个文件位于根文件系统中的 `/boot` 目录下，它的名字通常以 vmlinuz 开头（以前 /boot 一度常作为一个独立的文件系统，这样做大多是因为内核必须放在靠近启动盘的开头处，好让 BIOS 能访问到。现代的 PC 不再有这个问题了，/boot 更常作为根文件系统的一部分。）。存放设备文件的 /dev 目录（除了 /dev/pts，它单独安装）、存放关键系统文件的 /etc 目录、存放重要工具的 /sbin 和 /bin 目录，有时候还有用来存放临时文件的 /tmp
目录都是根文件系统的一部分。

目录 /usr 和 /var 也非常重要。/usr 是存放大多数标准程序的地方，它还有其他一些内容，例如在线用户手册和绝大多数数库文件。把 /usr 作为单独的文件系统并非严格要求，但出于管理上的方便，几乎总是这么设置。为了让系统能够最终启动到多用户模式，必须有 /usr 和 /var 这两个目录。

/var 存放有假脱机目录、日志文件、记账信息和其他各种快速增长或变化的东西以及随主机不同而有所不同的东西。由于 /var 包含有日志文件，而日志文件会随着故障出现的次数增多而增长，所以如果可行的话，把 /var 放置在它自己的文件系统上是一个好主意。

用户的主目录应该保存在单独的文件系统上，这个单独的文件系统通常安装在根目录中。还可以用单独的文件系统存储占用空间较大的东西，例如源代码库和数据库等。

处于不断发展中的文件系统层次结构标准（Filesystem Hierarchy Standard）正在努力编制标准目录使之合理，并加以说明。在要确定该把什么东西放在哪儿的时候，最好参考一下这个资源。

| 路径名          | 内容                                              |
| --------------- | ------------------------------------------------- |
| /bin            | 获得最小的系统可操作性所需要的命令                |
| /boot           | 内核和加载内核所需的文件                          |
| /dev            | 终端、磁盘、调制解调器等的设备项                  |
| /etc            | 关键的启动文件和配置文件                          |
| /home           | 用户的主目录                                      |
| /lib            | C 编译器的库和部分 C 编译器                       |
| /media          | 可移动介质上文件系统的安装点                      |
| /opt            | 可选的应用软件包（尚未广泛采用）                  |
| /proc           | 所有正在运行进程的映像                            |
| /root           | 超级用户的主目录（经常就是 /）                    |
| /sbin           | 引导、修复或者恢复系统的命令                      |
| /tmp            | 每次重新引导就消失的临时文件                      |
| /usr            | 次要文件和命令的层次结构                          |
| /usr/bin        | 大多数命令和可执行文件                            |
| /usr/include    | 编译 C 程序的头文件                               |
| /usr/lib        | 库，供标准程序使用的支持文件                      |
| /usr/local      | 本地软件(用户所编写或者安装的软件)                |
| /usr/local/bin  | 本地的可执行文件                                  |
| /usr/local/etc  | 本地系统配置文件和命令                            |
| /usr/local/lib  | 本地的支持文件                                    |
| /usr/local/sbin | 静态链接的本地系统维护命令                        |
| /usr/local/src  | /usr/local/*的源代码                              |
| /usr/man        | 联机用户手册                                      |
| /usr/sbin       | 不太关键的系统管理命令和修复命令                  |
| /usr/share      | 多种系统共同的东西(只读)                          |
| /usr/share/man  | 联机用户手册                                      |
| /usr/src        | 非本地软件包的源代码                              |
| /var            | 系统专用数据和配置文件                            |
| /var/adm        | 各种不同的东西:日志、系统设置记录、奇怪的管理信息 |
| /var/log        | 各种系统日志文件                                  |
| /var/spool      | 供打印机、邮件等使用的假脱机目录                  |
| /var/tmp        | 更多的临时空间（在重新引导以后，文件予以保留）    |

## 文件类型

Linux 定义了 7 种文件类型。即使在开发人员把精彩的新内容添加到文件树中（比如在 /proc 下列出的进程信息）的时候，仍然必须让新内容看起来像下面 7 种类型之一：

* 普通文件
* 目录
* 字符设备文件
* 块设备文件
* 本地域套接口
* 有名管道（FIFO）
* 符号链接。

用户可以用命令 `Is -ld` 来判断现有文件的类型。ls 命令输出的第一个字符表示类型。下面的例子表明 /usr/include 是一个目录：

```bash
1s -ld /usr/include

drwxr-xr-x	27 root	root	4096 Jul 15 20:57	/usr/include
```

Is 使用下表中给出的代码来表示文件的各种类型。

| 文件类型     | 符号 | 创建方式        | 删除方式            |
| ------------ | ---- | --------------- | ------------------- |
| 普通文件     | `-`  | 编辑器，`cp` 等 | `rm`                |
| 目录         | `d`  | `mkdir`         | `rmdir`  /  `rm -r` |
| 字符设备文件 | `c`  | `mknod`         | `rm`                |
| 块设备文件   | `b`  | `mknod`         | `rm`                |
| 本地域套接口 | `s`  | `socket(2)`     | `rm`                |
| 有名管道     | `p`  | `mknod`         | `rm`                |
| 符号链接     | `l`  | `ln -s`         | `rm`                |

`rm` 是删除不要文件的通用工具。不过，怎样删除一个名为 `-f` 的文件呢？它在大多数文件系统中都是一个完全合法的文件名，但是 `rm -f` 却不能起作用，因为 `-f` 被解释成了一个 `rm` 的标志。答案是，要么用更完整的路径名（比如 `./-f`）来指出文件，要么用 `rm` 的 `--` 参数来告诉它后面的所有东西都是文件名而不是选项（例如，`rm -- -f` ）。

包含控制字符的文件名带来了一个类似的问题，因为从键盘复制这些名字很困难乃至不可能。在这种情况下，可以使用 shell 的通配方式（模式匹配）来确定要删除的文件。在采用模式匹配的时候，使用 `rm` 的 `-i` 选项，让 `rm` 确认每个文件的删除操作是一个好主意。这项功能可以防止删除偶然匹配模式但又是“好”的任何文件。例如，要删除一个名为 `foo<Control-D>bar` 的文件，可以使用：

```bash
$ 1s
foo?bar	foose	kde-root

$ rm -i foo*
rm:remove `foo\004bar'? y
rm:remove `foose'? n
```

注意，`ls` 将控制字符显示为一个问号，这会有点儿欺骗性"（`ls -b` 命令以八进制数显示特殊字符，如果需要特意辨别它们的话，这个命令就可以帮上忙。<Control-A>是 1（八进制为 `\001` ）、<Control-B> 是 2 ，以此类推。）。如果忘记了 “?” 是一个 shell 要进行模式匹配的字符，而试着用 `rm foo?bar` ，那么可能会删除不只一个文件。`-i` 应该是常用的选项！

为了删除名字最难对付的文件，可能需要求助 `rm -i *` 这条命令。

还有一种方法能删除名字古怪的文件，就是通过访问文件系统的其他接口，比如 emacs 的 dired 模式，或者像 Nautilus 这样的可视化工具。

### 普通文件

普通文件只是一个装字节的包而已；Linux 并没有就其内容规定任何结构。文本文件、数据文件、可执行程序和共享库都作为普通文件存储。普通文件既能顺序存取，也能随机存取。

### 目录

目录包含按名字对其他文件的引用。用户可以使用 `mkdir` 命令来创建目录，使用 `rmdir` 命令来删除空目录，使用 `rm -r` 命令来删除非空目录。

特殊项 “`.`” 和 “`..`” 分别代表目录本身和它的父目录，它们不可以移动。由于根目录没有父目录，所以 “`/..`” 和 “`/.`” 是等价的（都等同于 `/` ）。

文件的名称实际上存储在它的父目录中，而不是和文件本身存储在一起。事实上，在同一时间，不只一个目录（或者是单个目录中的不只一个目录项）能够引用一个文件，并且引用可以拥有不同的名称。这样的安排产生了这样的错觉：一个文件同时存在于多个位置。

这些多出来的引用（链接）跟原来的文件是没有什么区别的；在 Linux 看来，它们都是等同的。Linux 维护着指向每个文件的链接的计数，在该文件的最后一个链接被删除之前不释放该文件的数据块。Linux 的链接不能够跨过文件系统的边界。

现在，这种类型的引用通常叫做“硬链接”，以此把它们同符号链接区分开来。采用 `ln` 命令来创建硬链接，采用 `rm` 命令来删除硬链接。

如果记住 `ln` 是 `cp` 的镜像，那么就很容易记住 `ln` 的语法。命令 `cp oldfile newfile` 创建 oldfile 的一个副本，该副本叫做 newfile 。`In oldfle newfile` 让名称 newfile 成为对 oldfile 新增的一个引用。

要理解硬链接并不是文件的一种独特类型，这一点很重要。文件系统只是允许不只一个目录项指向某个特定的文件，而不是定义了一个单独的称为硬链接的“事物”。除了文件的内容之外，所有链接之间还共享这个文件的根本属性，比如归属关系和访问权限。

### 字符设备文件和块设备文件

设备文件让程序能够同系统的硬件和外围设备进行通信。在配置内核的时候，那些知道怎样同系统的每个设备进行通信的模块就被链入内核（这些模块也可以被内核动态地加载。）。用于某个特定设备的模块叫做设备驱动程序，它负责管理该设备的凌乱细节。

设备驱动程序提供了一个标准的通信接口，该接口看起来就好像是一个普通文件。当内核接到一个对字符或块设备文件的请求时，它就简单地把这个请求传递给适当的设备驱动程序。不过，区分设备文件和设备驱动程序是很重要的。设备文件只是用来同设备驱动程序进行通信的结合点。它们并不是设备驱动程序本身。

字符设备文件让与之相关的驱动程序做它们自己的输入和输出缓冲。块设备文件由处理块数据 I / O 的驱动程序使用，并要求内核为它们提供缓冲。以前，有些类型的硬件既可以表示为块设备文件，也可以表示为字符设备文件。但是现在很少有这样的配置了。

设备文件用两个数字来表示其特征，这两个数字分别叫做主设备号和次设备号。主设备号告诉内核该文件访问哪个驱动程序，次设备号告诉驱动程序对哪个物理单元寻址。例如，Linux 系统上的主设备号 6 表示并行端口驱动程序。第一个并行端口（/dev/lp0）的主设备号为 6，次设备号为 0 。

有些设备驱动程序以它们高兴的方式来解释传给它们的次设备号。例如，磁带驱动程序经常使用次设备号来确定关闭该设备文件时是否应该回卷磁带。

设备文件可以使用 `mknod` 命令来创建，使用 rm 来删除。不过基本上没有必要手工创建设备文件。大多数发行版本使用 udev 根据内核对硬件的检测结果自动创建和删除设备文件。通过限制 /dev 目录下虚设的设备文件数量，以及确保分配给文件的设备号符合内核期望的做法，udev 就能保持 /dev 目录的整洁。

万一需要手工创建设备文件时，有个叫做 /dev/MAKEDEV 的老脚本作为 udev 的备用工具挺不错的。这个脚本能为各类设备定出符合规范的设备文件名和设备号，因此用户不必亲自去检查结果。例如，`MAKEDEV pty` 这条命令能给伪终端创建设备文件。如果需要得知一个驱动程序的主次设备号，在该驱动程序的手册页中第 4 节（例如，`man 4 tty` ）里就能找到这方面的信息。

### 本地域套接口

套接口（socket）就是在进程之间让它们以“干净卫生”的方式进行通信的连接。Linux 提供了几种不同类型的套接口，其中大多数涉及使用网络。本地域套接口只能从本地主机访问，并且是通过文件系统对象而不是网络端口来使用。它们有时称为 “UNIX 域套接口（UNIX domain socket）”。

尽管套接口文件对于其他进程是可见的目录项，但是通信连接之外的进程不能够读写它们。使用本地域套接口的一些标准工具有打印系统、X Windows 系统和 syslog。

本地域套接口由系统调用 socket 创建，当套接口不再有任何用户时，可以使用 rm 命令或系统调用 unlink 来删除它。

### 有名管道

与本地域套接口类似，有名管道能让运行在同一主机上的两个进程之间进行通信。它们也称为 “ FIFO 文件”（FIFO 是“first in,first out [先入先出] ”的缩写）。有名管道使用 mknod 来创建，使用 rm 命令来删除。

### 符号链接

符号链接或者叫做“软”链接通过名字指向文件。当内核在查找路径名的过程中遇到符号链接时，它就把它的注意力重定向到作为该链接的内容而存储的路径名上。硬链接和符号链接之间的区别在于：硬链接是直接引用，而符号链接是通过名称进行引用，符号链接跟它们指向的文件是不同的。

符号链接使用 `ln -s` 来创建，使用 rm 来删除。由于符号链接能够包含任意的路径，所以它们可以指向其他文件系统上的文件或者指向不存在的文件。几个符号链接还可以形成一个环。

符号链接既可以包含绝对路径，也可以包含相对路径，例如，

```bash
ln -s archived/secure /var/log/secure
```

这个命令采用相对路径把 `/var/log/secure` 链接到 `/var/achived/secure` 。它用一个目标路径 “archived/secure" 创建了一个符号链接 `/var/log/secure` ，结果见下面这条 Is 命令的输出：

```bash
ls -1 /var/1og/secure
lrwxrwxrwx	1	root	root	18	2024-09-07	12:03	/var/log/secure -> archived/secure

# ls 显示的符号链接的文件权限为 lrwxrwxrwx，这个权限是虚设的。创建、删除链接或者跟随链接的权限都由包含链接的目录控制，而读写和执行链接目标的权限由目标自己的权限决定。因此，符号链接不需要(也没有)它自己的任何权限信息。
```

整个 `/var/log` 目录可以移动到另外某个位置而不会让这个符号链接不起作用（建议不要移动那个目录）。

认为 `ln -s` 的第一个参数与自己的当前工作目录有关是一个常见错误。ln 不把它解析为一个文件名，它只是被逐字用作符号链接的目标。

## 文件属性

在传统的 UNIX 和 Linux 文件系统模型中，每个文件都有一组 9 个权限位用来控制谁能够读写和执行该文件的内容。这 9 位和另外影响到可执行程序运行的 3 个权限位一起，构成了文件的“模式”（mode）。

这 12 个模式位和 4 位的文件类型信息一起保存在一个 16 位的字中。这 4 个文件类型位在文件创建时设定并且不能修改，但是 12 个模式位可以由文件的属主或超级用户使用 chmod （改变模式）命令来修改。使用 `ls -l` （对于目录来说，使用 `ls -ld` ）可以査看这些位的值。

### 权限位

9 个权限位用来确定可以由谁对文件执行什么样的操作。（尽管 Linux 现在在所有主要的文件系统上都支持访问控制列表），传统的 UNIX 不能逐个用户地去设置权限。而是为文件的属主、文件的属组和其他每个人设置访问权限集合。每个集合有 3 位：读取位、写入位和执行位。

采用八进制数字来讨论文件的访问权限很方便，因为一个八进制数字的每一位代表 3 位，而每组权限位中正好有 3 位。最前面的 3 位（对应的八进制值为400、200 和 100）控制属主的访问权限。第二个三位组（40、20 和 10）控制组的访问权限。最后面的三位组（4、2 和 1）控制其他每个人的访问权限。在每个三位组中，高位是读取位，中间位是写入位，低位是执行位。

每个用户只能够划归为这 3 个三位组中的一组，使用最具体的权限。例如，一个文件的属主（owner）拥有的访问权限由属主权限位而不是组权限位所确定。“其他”（other）和“组”（group）类别有可能拥有比属主更多的访问权限，但这样的配置很少使用。

在普通文件上，读取位允许打开该文件并读取它的内容。写入位允许修改或删截该文件的内容。不过，能否删除和重命名（或者删除后再重建）该文件则由该文件父目录上的权限设置所控制（因为名字到数据空间的映射关系实际上存储在父目录中）。

执行位允许执行文件。可执行文件有两种类型：一种是二进制的，CPU 能够直接运行它；另外一种是脚本，脚本必须由 shell 或其他某种程序来解释。按照惯例，脚本以下面形式的一行代码开始：

```bash
#!/usr/bin/perl
```

这行代码指定了一个合适的解释程序。没有指定解释程序的那些非二进制可执行文件（由用户的 shell ）假定为 bash 或者 sh 脚本文件（内核能够理解 #! 语法，碰到它后会直接开始操作。不过，如果没有完全和正确地指定解释程序，那么内核将拒绝执行文件。接下来 shell 会通过调用 sh 来再次尝试执行这个脚本。）。

对于目录来说，当分析路径名时，执行位（在这种上下文环境中，也经常叫做“搜索[search]”位或“扫描[scan]”位）的作用是控制是否能够进入或通过该目录，而不是控制能否列出它的内容。读取位和执行位的组合的作用才是控制是否列出目录中的内容。写入位和执行位的组合则允许在目录中创建、删除和重新命名文件。

### setuid 和 setgid 位

八进制值为 4000 和 2000 的两位是 setuid 位和 setgid 位。如果在可执行文件上设置这两位，那么它们能让程序访问运行它们的用户本来无权访问的文件和进程。

在某个目录上设置了 setgid 位以后，在这个目录中新创建的文件具有该目录的属组权限而不是创建该文件的用户的默认属组。这项约定使得在几个用户之间（只要这些用户都属于一个共同的组）共享一个目录中的文件变得更加简单。对 setgid 位的这种解释跟它在可执行文件上设置时的含义没有什么关系，但不要混淆了这两种意义。

还可以在非可执行的纯文本文件上设置 setgid 位，在该文件被打开时请求特殊的锁定操作。但是，我们从未见到这项功能被用过。

### 粘附位

八进制值为 1000 的位叫做“粘附位”。在早期的 UNIX 系统上，它作为限定符对于可执行文件来说很重要。不过，粘附位的含义现在已经过时了，现代操作系统已经悄然地忽略了它。如果在目录上设置了这个粘附位，那么除非您是该目录的属主、该文件的属主或者是超级用户，否则文件系统不会允许删除或重新命名该目录中的文件。在这个目录上拥有写入权限是不够的。这项约定有助于让像 `/tmp` 之类的目录变得多少有些隐私性和安全性。

### 查看文件属性

文件系统为每个文件维护大约 40 项单独的信息，但其中的大多数只是对于文件系统本身有用。作为系统管理员，主要关心的是链接数、属主、属组、模式、大小、最后访问时间、最后修改时间和类型。所有信息可以使用 `ls -l` （或者对于目录来说是 `ls -ld`）来查看。

文件系统还为每个文件维护了属性改变的时间。给这个时间起的习惯名称（ctime，代表 changetime ）使得一些人以为它是文件的创建时间。遗憾的是，它不是，它只是记录文件属性（属主、模式等）最后改变的时间（注意跟修改文件内容的时间区分开来）。

考虑下面的例子:

```bash
ls -l /bin/gzip

-rwxr-xr-x	3	root	root	57136 Jun 15 2004 /bin/gzip
```

第一个字段指定该文件的类型和模式。第一个字符是短划线，因此这个文件是普通文件。

这个字段中接下来的 9 个字符就是 3 组权限位。这些组的顺序是“属主-属组-其他”，每组中位的次序是“读-写-执行”。尽管这些位只有二进制的值，但 ls 用字母来显示它们：字母 r 表示读取、字母 w 表示写入、字母 x 表示执行。在这个例子中，属主对该文件拥有全部的访问权限，其他每个人只拥有读取和执行的权限。

如果已经设置了 setuid 位，那么，表示属主的执行权限的 x 将用一个 s 来替代。如果 setgid 位已经被设置的话，那么表示组执行权限的 x 也会被 s 所替代。如果该文件的粘附位已经被打开，那么权限的最后那个字符（就是规定“其他人”执行权限的字符）显示为 t 。如果设置了 setuid、setgid 或粘附位中的一个，但又没有设置其相应的执行位，那么这些位就显示为 S 或 T 。

列表中的下一个字段是该文件的链接数目。在示例中是 3，表示 /bin/gzip 是这个文件 3 个名字中的一个（另外两个名字是 /bin/gunzp 和 /bin/zcat）。每次建立一个该文件的硬链接时，链接数目就增加 1 。所有目录将至少拥有两个硬链接：来自父目录的链接和来自目录本身内部的特殊文件 “.” 的链接。符号链接不影响链接数目。

在 ls 输出中接下来的两个字段是文件的属主和属组。在这个例子中，该文件的属主是 root，该文件又属于组 root 。文件系统实际上保存的是用户 ID 和组 ID 的编号，而不是字符串名。如果不能够确定数字 ID 号对应的文字（名字），那么这些字段将包含数字 ID 号。如果拥有该文件的用户或组已经从 /etc/passwd  或 /etc/group 文件中删除的话，那么可能会出现这种情况。出现这种情况还可能预示着 NIS 或者 LDAP 数据库（如果用到这个数据库的话）有问题。

接下来的字段是文件以字节为单位的大小。示例中的文件长度是 57136 字节，大约 56K （0K 表示千，它是 1000 的公制度量前缀。然而，计算机世界把它误用成了2^10，即1024。与此类似，计算机的1兆字节实际上不是1百万字节，而是2^20，即1048576个字节。国际电子技术委员会正在推行一组明确地基于2的幂的新数字前缀(例如kibi 和 mebi)。现在看来似乎过去的习惯用法不大可能会改变。让情况更为混乱的是，甚至以2的幂为单位也不一定得到统一使用。RAM(随机存取存储器)是以2的幂为单位来表示的，但网络带宽却始终是用10的幂为单位来表示。制造商用10的幂为单位来报存储空间的大小，但是别人却会按2的幂来计算。这也是硬盘格式化后的空间要比标称值小一些的原因。）。接下来的字节是文件最后被修改的日期：2004 年 6 月15 日。列表中最后那个字段是该文件的名称 /bin/gzip 。

如果是设备文件，ls 的输出稍微有些不同，例如：

```bash
ls -l /dev/tty0

crw-rw----	1	root	root	4,0 Jun 11 20:41 /dev/tty0
```

大多数字段是一样的，但不显示文件的大小，而是显示其主设备号和次设备号。/dev/tty0 是设备驱动程序 4 （在这个系统上，是终端驱动程序）所控制的第一个虚拟控制台。

ls 有一个选项 -i ，它用于査看硬链接，这个选项让 ls 显示每个文件的“索引节点号”。没有必要过多地深究有关文件系统实现的具体细节，只是说索引节点号是列出文件系统里所有文件的一张表中的一个索引。索引节点就是目录项所指向的东西，同一文件的硬链接项具有相同的索引节点号。要勾勒出链接复杂的网状关系，需要使用 `ls -li` 命令来给出链接数目和索引节点号，和 find 一起来找到匹配结果。（尝试使用 `find mountpoint -xdev -inum inode -print` 。）

系统自动跟踪修改时间戳、链接数目和文件大小信息的变化。相反地，权限位、归属关系和属组权只有当它们分别采用 chmod、chown 和 chgrp 命令修改时才改变。

其他一些应该知道的 ls 重要选项有：`-a` 列出一个目录的所有项（包括名字以点开头的文件），`-t` 按照时间对文件排序（或者 `-tr` ，按照时间逆序排列），`-F` 以区分目录和可执行文件的方式显示文件名，`-R` 逆序显示，以及 `-h` 以方便人们阅读的形式显示文件大小（例如，8K 或者 53M ）。

### chmod ：改变权限

chmod 命令改变文件的权限。只有文件的属主和超级用户才能够修改它的权限。为了在早期的 UNIX 系统上使用该命令，就不得不学一点八进制记法的知识，但该命令的当前版本既能够接受八进制的记法，也可以接受易于记忆的语法。一般说来，八进制的语法对于系统管理员来说更加方便，但它只可以用来指定权限位的绝对值。易于记忆的语法既可以修改一些位而又不影响其他位。

chmod 的第一个参数是要给文件分配的访问权限的说明，第二个参数及其以后的参数是要改变访问权限的文件的名字。在采用八进制记法的情况下，说明的第一个八进制位代表属主的权限，第二个八进制位代表组的权限，第三个八进制位代表其他每个人的权限。如果想要打开 setuid、setgid 或粘附位，则要使用 4 个而不是 3 个八进制位，由 3 个特殊位来构成第一个八进制位。

下表说明了每个三位组的 8 种可能组合，其中的 r、w 和 x 分别代表读取、写入和执行。

| 八进制 | 二进制 | 权限 |
| ------ | ------ | ---- |
| 0      | 000    | ---  |
| 1      | 001    | --x  |
| 2      | 010    | -w-  |
| 3      | 011    | -wx  |
| 4      | 100    | r--  |
| 5      | 101    | r-x  |
| 6      | 110    | rw-  |
| 7      | 111    | rwx  |

例如，`chmod 711 myprog` 赋予属主所有的权限，而只给其他每个人赋予执行权限。（如果 myprog 是一个 shell 脚本，那么它需要同时打开读取和执行的权限。为了让解释程序运行这个脚本，这个脚本必须像文本文件一样被打开和读取。二进制文件是由内核直接执行的，因此不需要打开读取权限。）

chmod 的助记语法的全部信息可以在 chmod 的手册页中找到。其规则的一些示例如表所示：

| 规则      | 含义                                                         |
| --------- | ------------------------------------------------------------ |
| u+w       | 为文件的属主添加写入的权限                                   |
| ug=rw,o=r | 赋予属主和属组读取/写入的权限，赋予其他人读取的权限          |
| a-x       | 删除全部 3 种类别用户（属主/属组/其他人）的执行权限          |
| ug=srx,o= | 设置文件的 setuid 和 setgid 位，并且只给属主和属组赋予读取/执行的权限 |
| g=u       | 让属组的权限跟属主的权限完全一样                             |

使用助记语法的困难之处在于要记住 `o` 代表 “owner（属主）” 还是 “other（其他人）” （正确答案是其他人）。只要类比 UID 和 GID 记住 `u` 和 `g`，那么就只剩下一种可能了。

还可以通过类比一个现有的文件来指定要分配的权限模式。例如，`chmod --reference=filea fileb` 让 fileb 的权限模式和 filea 的权限模式一样。

`chmod` 可以使用 `-R` 选项递归地更新某个目录下文件的权限。不过，这可比它看上去更需慎重对待，因为包含进来的文件和目录可能不是全都有相同的属性（例如，有些文件可能是可执行文件，而别的文件可能是文本文件)。采用 `-R` 选项时使用助记语法格外有用，因为没有明确设置的任何位，其值都保持不变。例如：

```bash
chmod -R g+w mydir
```

给 mydir 及其所有内容增加了属组的写入权限，同时又不会弄错目录以及程序的执行位。

### chown：改变归属关系和组

chown 命令改变文件和文件的属组所有权。chown 的语法跟 chmod 类似，只不过它的第一个参数以 `user:group` 的形式指定了新的属主和属组。属主和属组之一都可以为空。如果没有属组，也就不需要冒号（`:`）了，但是带上冒号，会让 chown 命令把 user 的属组设为默认组。出于历史原因，`user.group` 这样的形式也能接受，但是由于用户名可以包括点，所以这种形式不够通用。

要改变一个文件的属组，您必须是该文件的属主而且属于目标属组的成员，或者必须是超级用户您必须是超级用户才能改变文件的属主。

类似 chmod ，chown 也提供了递归的 -R 标志，能够改变一个目录以及在它之下所有文件的设定。例如，命令序列：

```bash
chmod 755	~matt
chown -R matt:staff ~matt
```

可以在复制了默认启动文件以后用来建立一个新用户的主目录。一定不要尝试采用类似下面的命令来 chown 新用户的点文件 （`.`）：

```bash
chown -R matt:staff ~matt/.*
```

这个模式将匹配 `~matt..` ，导致其父目录的归属关系被修改，而且很可能还会造成其他用户主目录归属关系被修改。

传统的 UNIX 系统使用一个单独的命令 `chgrp` 去改变一个文件的属组。Linux 也一样提供了chgrp 命令。它的用法与 chown 命令基本相同。

### umask：分配默认的权限

用户可以使用内建的 shell 命令 umask 来影响分配给新创建文件的默认权限。umask 用一个三位数字的八进制值形式来指定，这个值代表要“剥夺”的权限。当创建文件时，它的权限就设置为创建程序请求的任何权限去掉 umask 禁止的权限。

| 八进制 | 二进制 | 权限 |
| ------ | ------ | ---- |
| 0      | 000    | rwx  |
| 1      | 001    | rw-  |
| 2      | 010    | r-x  |
| 3      | 011    | r--  |
| 4      | 100    | -wx  |
| 5      | 101    | -w-  |
| 6      | 110    | --x  |
| 7      | 111    | ---  |

例如，`umask 027` 允许属主具有所有权限，但禁止属组的写入权限，并且不允许其他任何用户有任何权限。默认的 umask 值是 022 ，它不允许属组和其他用户有写入权限。

没有办法强制用户拥有某个特定的 umask 值，因为用户能够把这个值重设为他们想要的任何值。但是，在给新用户提供的 `.cshrc` 和 `.profle` 样本文件中，可以提供一个合适的默认值。

### 额外的标志

Linux 的 ext2fs 和 ext3fs 文件系统定义了一些补充属性，可以打开它们来请求获得特殊的文件系统语义——“请求”是操作字，因为许多标志实际上还没有实现。例如，一个标志让文件只能追加（append），另一个标志让文件不可变动和不可删除。

既然这些标志不能用于 ext* 系列以外的其他文件系统，所以 Linux 使用了特殊命令 Isattr 和 chattr 来查看和改变它们。下表列出了当前能用的标志（目前大约只占在手册页中提到的那些标志的 50%）。

| 标准 | 含义                                           |
| ---- | ---------------------------------------------- |
| A    | 从不更新访问时间（st_atime；出于性能原因）。   |
| a    | 只允许以追加模式写入（只有 root 能设置）。     |
| D    | 强制目录更新被同步写入。                       |
| d    | 不作备份——让 dump 忽略这个文件。               |
| i    | 让文件不可变动和不可删除（只有 root 能设置）。 |
| j    | 为数据变化和元数据都保留日志。                 |
| S    | 强迫变动被同步写入（不作缓冲）                 |

除了“不作备份”标志可能有所例外，还不清楚它们中间别的功能可以提供多少日用价值。“不可改变”和“仅限追加”标志多被认为能让系统对黑客或者恶意代码损坏的抵抗力更强。遗憾的是，它们会搞乱软件，并且只能防止还不知道使用 `chattr-ia` 的黑客的攻击。实际经验已经表明，这些标志往往黑客用得比防黑客的还多。

启动同步写的 S 和 D 选项也应引起特别注意。由于它们迫使与某个文件和目录有关的所有文件系统页面都要随变动而立即写出到硬盘上，所以似乎能在发生崩溃的时候提供额外的保护，防止数据丢失。但是同步更新的操作次序不固定，而且已经知道这会把 fsck 搞糊涂，因此，可能导致受损文件系统的恢复更困难而不是更可靠。随 ext3fs 提供的文件系统日志机制通常是更好的选项。`j` 选项强制对特定文件的数据做日志，但这样会带来一些性能上的开销。

## 访问控制列表

9 位的属主/属组/其他人访问控制系统已得到证明是强大的，足以满足大多数管理方面的需求。虽然这种系统有明显的局限性，但是它却非常好地保持了 UNIX 简洁和可预测的传统（有人可能会说是“前传统”）。

事实上，在所有非 UNIX 的操作系统上都采用了一种实质上更为复杂的方式来管理对于文件的访问：访问控制列表（access control list），简称 ACL 。ACL 不限长度，可以包含用于多个用户或者用户组的权限规定。更先进的系统能让系统管理员指定部分权限的集合或者否定方式的权限。有些系统还有继承特性，可以一次依靠多个 ACL 来指定访问权限。这些系统显然比传统的 UNIX 模型功能更强，但是对于系统管理员和软件开发人员来说，它们的复杂性也增加了一个数量级。

因为在 POSIX 规范中增加了 ACL ，所以许多 UNIX 的变体也开始支持一种相当标准的 ACL 机制。这种机制和传统的 UNIX 9 位权限模式平行地发挥作用。在Linux 下，ext2、ext3、ReiserFS、XFS 和 JFS 都支持 ACL 。通常在默认情况下会禁用它们，在调用 mount 命令时加 `-o acl` 选项就可以启用 ACL 。

但是不要被其华丽的外表所迷惑—— ACL 不一定比传统的文件权限更好，在行的系统管理员应该在一定程度上谨慎地使用它们。不仅因为它们用起来复杂而且费事，而且它们在和 NFS、备份系统以及文本编辑器这样的程序联用的时候也会造成问题。ACL 在不断变化，所以随着时间推移在变得不可维护。

使用 ACL 表面上看起来最能让人接受的理由或许就是增强与其他操作系统的兼容性。具体来说用来和 Windows 系统共享文件的 Samba 软件能够识别 ACL ，实实在在地在 Linux 和 Windows 的 ACL 之间进行转换。

### ACL 概述

Linux 的 ACL 主要是对标准的 9 位权限模型直接进行扩展。读写和执行权限只是系统能够处理的权力(capability)。而像 setuid 和粘附位这样的功能还是通过传统的模式位专门处理。ACL 可以按照用户和用户组的任意组合独立地设置 rwx 权限位。

| 格式                  | 举例            | 权限                         |
| --------------------- | --------------- | ---------------------------- |
| user::perms           | user::rw-       | 文件的属主                   |
| user:username:perms   | user:trent:rw-  | 某个特定的用户               |
| group::perms          | group::r-x      | 文件的属组                   |
| group:groupname:perms | group:staff:rw- | 某个特定的组                 |
| other: :perms         | other::---      | 所有其他人                   |
| mask::perms           | mask::rwx       | 除去属主和其他人之外的所有人 |

user 和 group 可以用名字或者 UID / GID 来标识。一个 ACL 能包含的组成项的数量随着文件系统实现的不同而不同，范围从 XFS 的最低 25 项，到 ReiserFS 和 JFS 的最多可以没有限制。ext2 和 ext3 文件系统可以有 32 项，对于在任何情况下都能管理来说，这或许是一个比较合理的上限。

getfacl 命令可以显示一个文件当前的 ACL ，setfacl 命令可以修改或者设置文件当前的 ACL 。`setfacl -b file` 命令可以清除 ACL ，`setfacl -m aclspec file` 可以修改或者扩展 ACL ，而 `setfacl -x aclspec file` 可以删除 ACL 中的特定项（使用 `-x` 选项时省略权限说明部分）。只要在 aclspec 中用逗号分隔 ACL 项，就能够在其中包含多个 ACL 项。

带有 ACL 的文件仍然保留有它们原来的权限模式位，但是会自动在两套权限设置之间强制保持一致，使它们一定不发生冲突。下面的例子展示了 ACL 项随着 chmod 命令对权限模式位的修改而自动更新的情况：

```bash
$ touch /tmp/example
$ ls -l /tmp/example
-rw-rw-r--	1	garth garth	0 Jun 14 15:57 /tmp/example

$ getfacl /tmp/example
getfacl:Removing leading '/' from absolute path names
# file:  tmp/example
# owner: garth
# group: garth
user::rw-
group::rw-
other::r--

$ chmod 640	/tmp/example
$ getfacl --omit-header	/tmp/example
user::rw-
group::r--
other::---
```

这种强制保持一致的做法让不知道 ACL 的老软件在有 ACL 的情况下也能很好地工作。不过有一点问题。虽然前面例子中 group:: 这个 ACL 项似乎对应了传统权限模式的中间一组权限位，但情况不一定总是这样。

为了理解其中的原委，假定有个老程序清除了传统权限模式中所有三组权限位中的写权限位（例如，`chmod ugo-w file`）。这样做的目的很清楚，就是不让任何人能够写这个文件。但是如果产生的 ACL 将会是下面这个样子该怎么办？

```bash
user::r--
group::r--
group:staff:rw-
other::r--
```

从老程序的角度来看，文件不能修改，但是 staff 组中的任何成员实际上都对文件有写权。为了减少出现二义性和误会的机会，Linux 采用了下面的规则：

* ACL 项 user:: 和 other:: 定义为等价于传统文件模式中 “owner（属主）” 和 “other（其他人）” 的权限位。权限模式改变，对应的 ACL 项也改变。反之亦然。
* 在所有情况下，对于文件的属主以及没有以别的方式提到的用户，给它们赋予的有效访问权限就是在 user:: 和 other:: 这两个 ACL 项中分别指定的权限。
* 如果一个文件没有显示规定的 ACL，或者一个 ACL 只包含一个 user:: 、一个 group:: 和一个 other:: 项，那么这几个 ACL 项等同于传统的三组权限位。上面给出的 getfacl 的例子就属于这种情况。（这样的 ACL 称为“最小” ACL，实际上不需要按一个逻辑上独立的 ACL 来实现。）
* 在更复杂的 ACL 里，传统的组权限位对应于一个称为 “mask” 的特殊 ACL 项，而不是 group:: 那个 ACL 项。ACL 的 mask 项限制了 ACL 能够赋予所有有名字的用户、所有有名字的组以及默认组的访问权限。

换句话说，mask 规定了 ACL 能够给单个组和用户访问权限的上限。它在概念上类似于 umask ，不同之处在于 ACL 的 mask 始终有效，而且规定的是允许的权限，而不是不允许的权限。给有名字的用户、有名字的组以及默认组的 ACL 项包括 mask 中没有出现的权限位，但是内核会忽略它们。

因此，传统的权限模式位不会描述不了 ACL 所允许的访问权限。而且从传统权限模式的组权限位中清除一位，也会清除 ACL mask 中对应的位，因而让除了该文件的属主以及处于 “other” 类的用户之外的所有人都没有该权限。

扩充前面例子里的 ACL，使它包括对某个特定用户和组的 ACL 项，setfacl 会自动提供一个合适的 mask ：

```bash
$ setfacl -m user::r,user:trent:rw,group:admin:rw /tmp/example
$ ls -l /tmp/example
-r--rw----+1 garth staff 0 Jun 14 15:57 /tmp/example

$ getfacl --omit-header /tmp/example
user::r--
user:trent:rw-
group::r--
group:admin:rw-
mask::rw-
other::---
```

如前所示，setfacl 命令产生了一个 mask，让 ACL 中赋予的所有权限都发生作用。如果不想手工设置 mask，可以在给 setfacl 命令的 ACL,项清单中包含这个mask，或者使用 -n 选项避免 setfacl 命令重复产生它。

在尝试访问文件的时候，要把有效 UID 同该文件属主的 UID 进行比较。如果它们两者一样，那么 ACL 中的 user:: 项权限就决定了能否访问。否则，如果匹配某个特定于用户的 ACL 项，那么那个 ACL 项连同 ACL 的 mask 就一起决定了能否访问。如果没有特定于某个用户的 ACL 项，那么文件系统就尝试找到一个有效的组 ACL 项，能提供所请求的访问。这样的 ACL 也要和 ACL 的 mask 一起处理。如果没有找到匹配项，那么再用 other:: 这个 ACL 项。

如果在一个有 ACL 的文件上使用传统的 chmod 命令来控制组的访问权限，那么要注意修改只对 mask 有影响。继续用前面的例子来说明：

```bash
$ chmod 770 /tmp/example
$ ls -l /tmp/example
-rwxrwx---+ 1 garth staff 0 Jun 14 15:57 /tmp/example

$ getfacl --omit-header /tmp/example
user::rwx
user:trent:rw-
group::r--
group:admin:rw-
mask::rwx
other::---
```


这里 Is 命令的输出有点误导性。尽管表面上看给组权限，但是没有人因为是组成员而有权执行该文件。为了让组有这样的权限，必须编辑 ACL 本身。

除了上表列出的 ACL 项之外，目录的 ACL 可以包括一个 “default(默认)” 项，加到在目录下新创建的文件和子目录的 ACL 上。子目录能接收主动和默认形式的 ACL 项。因此，最初的默认项最后会向下加给几层子目录。

在复制了默认项之后，父子 ACL 之间就不再有联系。如果父亲的默认项发生变化，不会反映到现有子目录的 ACL 上。

## 本地文件系统

本地文件系统是在单一本地服务器中运行并直接附加到存储中的文件系统。

例如，本地文件系统是内部 SATA 或 SAS 磁盘的唯一选择，可在当服务器具有带有本地驱动器的内部硬件 RAID 控制器时使用。当 SAN 上导出的设备未共享时，本地文件系统也是 SAN 连接的存储上最常用的文件系统。

所有本地文件系统都与 POSIX 兼容。与 POSIX 兼容的文件系统为一组定义良好的系统调用提供支持，如 `read()`、`write()` 和 `seek()`。

从应用程序员的角度来看，本地文件系统之间的差别相对较少。从用户的角度来看，最显著的差异与可扩展性和性能相关。在考虑文件系统的选择时，考虑文件系统需要多大、应具有哪些独特功能，以及它在工作负载下性能如何。

### 列表

* AFP (Apple文件归档协议,Apple Filing Protocol)

* amufs5

* amufs4

* amufs3

* amufs2

* amufs1

* amufs0

* amufs

* apfs1

* apfs2

* affs7

* affs4

* affs3

* affs2

* affs1

* affs0

* asfs

* btrfs

  通常读为 Butter FS，是在 2007 年 Oracle 发布的文件系统，支持最大 16EB 的文件系统（分区），最大文件大小是 16EB 。它拥有强大的扩展性、数据一致性，支持快照和克隆等一系列先进技术。可是很遗憾，BTRFS 读写速度上非常缓慢，甚至连 Ext4 或 XFS 文件系统的一半都达不到，这使得 BTRFS 的实用性大大降低。目前 CentOS 7.x 虽然支持 BTRFS 文件系统，但是并不推荐大家使用。

* EXT (扩展文件系统,Extended Filesystem)

  * ext2

    Second Extended File System，也常称为 ext2fs，在过去很长时间里一直是主流的 Linux 文件系统。它主要是由 Rémy Card、Theodore Ts‘o 和 Stephen Tweedie 设计和实现的。虽然 ext2 的代码是专为 Linux 编写的，但是它采用了许多源自于 BSD FFS 文件系统的概念，后者由 Kirk McKusick 和他的小组在 1984 年设计和实现。

  * ext3

    ext2 文件系统的升级版本，带日志功能，支持最大 16TB 的分区和最大 2TB 的文件。而且 ext3 文件系统最大只支持 32000 个子目录。

    ext3fs（Third Extended File System）是对 ext2fs 的一种非常知名的扩充，它最初由 Stephen Tweedie 开发，现在是大多数 Linux 发行版本默认的文件系统。ext3s 向现有的 ext2fs 代码加入了日志功能，从概念上说很简单的修改却大大增加了可靠性。更有意思的是，甚至不必改变 ext2fs 的基础结构，就可以实现 ext3fs 扩展。实际上，仍然可以把一个 ext3fs 文件系统当作 ext2fs 文件系统来安装——它只是不会启动日志功能而已。

    ext3fs 文件系统在硬盘上专辟了一个区域来保存日志文件。在发生文件系统操作的时候，所要求的修改首先写入日志文件。在完成日志更新之后，写入一条“提交记录（commit record）”标记日志项的结束。只有这样以后，才对正规的文件系统作修改。如果发生了崩溃，可以用日志记录重构出完全相同的文件系统。

    日志机制将执行文件系统一致性检查所需的时间减小到每个文件系统大约 1 秒。除了某种硬件故障之外，ext3fs 的状态几乎能立即评估和恢复。

  * ext4

    ext3 文件系统的升级版，向下兼容 ext3 文件系统，支持无限量子目录，支持最大 1EB 的文件系统（分区）和最大 16TB 的文件。这是 CentOS 6.x 默认的文件系统。在 Linux 中具有长寿的优势。因此，几乎所有 Linux 应用程序都支持它。在大多数情况下，它与 XFS 在性能上竞争。ext4 通常用于主目录。

* FAT (文件分配表,File Allocation Table)

  * FAT16

  * FAT32

    早期 Windows的文件系统，支持最大 32GB 的分区和最大 4GB 的文件。

* hfs   HFS+(分级文件系统,Hierarchical File System)

* hfsx

* hfs+

* hp-ufs

* ISO9660

* JFS

* linux-swap(v1)

* linux-swap(v0)

* linux-swap

* linux-swap(new)

* linux-swap(old)

* LOOPBACKFS (回送文件系统,Loopback File System)

* nilfs2

* NTFS (新技术文件系统,New TechnologyFile System)

  现在 Windows 的主流文件系统，比 FAT32 更加安全、速度更快，支持最大 2TB 的分区和最大 64GB 的文件。

* PROCFS (进程文件系统,ProcessFile System)

* ReiserFS

  Hans Reiser 开发的 ReiserFs 是另一种在 Linux 上新出现的文件系统，SUSE 把它作为自己默认的文件系统。和 ext3fs 一样，ReiserFS 也是一种日志文件系统，因此能够维护文件系统的一致性，不必担心诸如系统崩溃、意外重启这样的异常事件。2004 年 8 月发布的 ReiserFS 第 4 版包含在 Ubuntu 的默认安装中。Fedora 和 SUSE 迄今仍然在使用较早的版本。

  除了日志功能之外，Reiser4 还会提供一种模块化的文件系统接口，通过这个接口，应用软件开发人员和系统管理员可以在非常细的粒度上指定应该怎样处理（和保护）文件。这项功能有可能在特殊环境里增强文件的安全性。ReiserFS 由 DARPA 提供资助，它是声称为达到军用级别的安全性而设计的唯一开放源代码的文件系统。

  Reiser4 的新算法比以前的算法空间效率更高。别的文件系统（以及 ReiserFS 的较早版本）使用平衡树算法来分配地址空间块。虽然这种尝试性的方法经证实很可靠，但是它一般会在速度和磁盘利用率之间进行折中。Reiser4 的 “dancing tree” 算法不要求系统管理员在速度和磁盘利用率两方面进行选择。

  * ReiserFS 4

* sun-ufs

* swsusp

* TMPFS (临时文件系统)

* UDF (通用磁盘格式)

* UFS (Unix文件系统,UnixFile System)

* XFS

  一种高性能的日志文件系统，于 2000 年左右移植到 Linux 内核中。XFS 特别擅长处理大文件，同时提供平滑的数据传输。XFS 最大支持 18EB 的文件系统和 9EB 的单个文件。这是 CentOS 7.x 的默认文件系统。

## XFS

XFS 是一个高度可扩展、高性能、健壮且成熟的 64 位日志文件系统，其支持单个主机上非常大的文件和文件系统。是 RHEL 9 中的默认文件系统。

XFS 最初于 1990 年代由 SGI  早期开发，并在非常大型的服务器和存储阵列中运行有很长的历史记录。 

由于它将文件布局为扩展数据块，所以不像 ext4 那样易受碎片的影响。红帽建议将 XFS 部署为本地文件系统。	

### 功能包括

- 可靠性
  * 元数据日志，其确保系统崩溃后文件系统的完整性，方法是保留系统重启和重新挂载文件系统时可以重新执行的文件系统操作的记录
  * 广泛的运行时元数据一致性检查
  * 可扩展且快速修复工具
  * 配额日志。这可避免在崩溃后进行冗长的配额一致性检查。
- 可伸缩性和性能
  * 支持最多 1024 TiB 的文件系统大小
  * 支持大量并发操作的能力
  * B-tree 索引，用于空闲空间的可扩展性管理
  * 复杂的元数据读头算法
  * 优化流视频工作负载 							
- 分配方案
  * 基于扩展数据块的分配
  * 条带化分配策略
  * 延迟分配
  * 空间预分配
  * 动态分配的 inode 							
- 其他功能
  * 基于 Reflink 的文件副本
  * 严格集成备份和恢复工具
  * 在线清理
  * 在线文件系统增大
  * 全面的诊断功能
  * 扩展属性(`xattr`)。这允许系统能够按文件关联多个额外的名称/值对。
  * 项目或目录配额。这允许对目录树的配额限制。
  * 小于秒的时间戳 							

### 性能特性

XFS 在具有企业工作负载的大型系统上具有高性能。大型系统是一个有相对较多的 CPU 、多个 HBA 和连接外部磁盘阵列的系统。XFS 在具有多线程、并行 I/O 工作负载的较小系统上也表现良好。

对于单线程、元数据密集型工作负载，XFS 的性能相对较低：例如，在单个线程中创建或删除大量小文件的工作负载。

### 备份

使用 `xfsdump` 将 XFS 文件系统备份到文件或磁带。

- 对常规文件镜像执行备份。

  只能将一个备份写入常规文件。

- 在磁带驱动器中执行备份。

  允许将多个备份写入同一磁带。备份可跨越多个标题。要将多个文件系统备份到单个磁带设备，只需将备份写入已包含 XFS 备份的磁带。这会将新备份附加到上一个备份。默认情况下，`xfsdump` 永远不会覆盖现有的备份。

- 创建增量备份。

  使用转储级来确定其他备份所相对的基本备份。从 0 到 9 的数字表示增加的转储级。增量备份只备份自上一次较低级别转储以来发生变化的文件：

  - 要执行全备份，对文件系统中执行 0 级转储。
  - 1 级转储是全备份后的第一个增量备份。下一个增量备份为 2 级，它仅备份自 1 级转储以来更改的文件，以此类推，最高到 9 级。

- 使用大小、子树或 inode 标志从备份中排除文件，以过滤它们。

使用以下命令备份 XFS 文件系统： 				

```bash
xfsdump -l level [-L label] -f backup-destination path-to-xfs-filesystem
```

- 使用备份的转储级别替换 *level*。使用 `0` 执行全备份，或使用 `1` 到 `9` 执行后续增量备份。

- 使用要存储备份的路径替换 *backup-destination*。目的地可以是常规文件、磁带驱动器或远程磁带设备。

  例如：用于文件的 `/backup-files/Data.xfsdump` 或者用于磁带驱动器的 `/dev/st0` 。

- 使用要备份的 XFS 文件系统的挂载点替换 *path-to-xfs-filesystem*。例如：`/mnt/data/`。文件系统必须挂载。

- 当备份多个文件系统，并将它们保存在单个磁带设备上时，请使用 `-L label` 选项来为每个备份添加一个会话标签，以便在恢复时更轻松地识别它们。使用备份的任何名称替换 *label* ：例如 `backup_data`。

示例：

```bash
# 要备份挂载在 /boot/ 和 /data/ 目录中的 XFS 文件系统内容，并将它们保存为 /backup-files/ 目录中的文件
xfsdump -l 0 -f /backup-files/boot.xfsdump /boot
xfsdump -l 0 -f /backup-files/data.xfsdump /data

# 要备份多个文件系统到单个磁带设备中，请使用 -L label 选项来为每个备份添加一个会话标签
xfsdump -l 0 -L "backup_boot" -f /dev/st0 /boot
xfsdump -l 0 -L "backup_data" -f /dev/st0 /data
```

### 恢复

使用 `xfsrestore` 工具来恢复用 `xfsdump` 工具创建的，并存储在文件或磁带中的 XFS 备份。

`xfsrestore` 工具有两个模式：

- **简单** 模式允许用户从 0 级转储恢复整个文件系统。这是默认的模式。
- **累计** 模式启用从增量备份恢复文件系统：即，1 级到 9 级。

唯一 *会话 ID* 或 *会话标签* 标识每个备份。从包含多个备份的磁带恢复备份需要相应的会话 ID 或标签。

要从备份中提取、添加或删除特定文件，请进入 `xfsrestore` 交互模式。交互模式提供了一组命令来操作备份文件。

## 24.2. 使用 xfsrestore 从备份中恢复 XFS 文件系统

​				这个步骤描述了如何从文件或者磁带备份中恢复 XFS 文件系统的内容。 		

**先决条件**

- ​						XFS 文件系统的文件或磁带备份，如 [备份 XFS 文件系统](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#assembly_backing-up-an-xfs-file-system_managing-file-systems) 中所述。 				
- ​						您可以恢复备份的存储设备。 				

**流程**

- ​						恢复备份的命令因您是从全备份或增量备份中恢复，还是从单个磁带设备恢复多个备份而有所不同： 				

  ```none
  # xfsrestore [-r] [-S session-id] [-L session-label] [-i]
               -f backup-location restoration-path
  ```

  - ​								使用备份位置替换 *backup-location*。这可以是常规文件、磁带驱动器或远程磁带设备。例如：用于文件的 `/backup-files/Data.xfsdump` 或者用于磁带驱动器的 `/dev/st0` 。 						

  - ​								使用要恢复文件系统的目录的路径替换 *restore-path*。例如：`/mnt/data/`。 						

  - ​								要从增量（1 级到 9 级）备份恢复文件系统，请添加 `-r` 选项。 						

  - ​								要从包含多个备份的磁带设备恢复备份，请使用 `-S` 或 `-L` 选项指定备份。 						

    ​								`-S` 选项允许您按会话 ID 选择备份，而 `-L` 选项则允许您按会话标签进行选择。要获取会话 ID 和会话标签，请使用 `xfsrestore -I` 命令。 						

    ​								使用备份的会话 ID 替换 *session-id*。例如，`b74a3586-e52e-4a4a-8775-c3334fa8ea2c`。使用备份的会话标签替换 *session-label*。例如，`my_backup_session_label`。 						

  - ​								要以交互方式使用 `xfsrestore`，请使用 `-i` 选项。 						

    ​								在 `xfsrestore` 完成读取指定设备后，交互对话框开始。交互式 `xfsrestore` shell 中的可用命令包括 `cd`、`ls` 、`add`、`delete` 和 `extract`; 如需命令的完整列表，请使用 `help` 命令。 						

例 24.1. 恢复多个 XFS 文件系统

- ​							要恢复 XFS 备份文件，并将其内容保存到 `/mnt/` 下的目录中： 					

  ```none
  # xfsrestore -f /backup-files/boot.xfsdump /mnt/boot/
  # xfsrestore -f /backup-files/data.xfsdump /mnt/data/
  ```

- ​							要从包含多个备份的磁带设备恢复，请使用会话标签或会话 ID 指定每个备份： 					

  ```none
  # xfsrestore -L "backup_boot" -f /dev/st0 /mnt/boot/
  # xfsrestore -S "45e9af35-efd2-4244-87bc-4762e476cbab" \
               -f /dev/st0 /mnt/data/
  ```



## 24.3. 从磁带恢复 XFS 备份时的说明性消息

​				当从存有多个文件系统备份的磁带恢复备份时，`xfsrestore` 工具可能会发出消息。当 `xfsrestore` 按顺序检查磁带上的每个备份时，消息会通知您是否找到了与请求的备份相匹配的备份。例如： 		

```none
xfsrestore: preparing drive
xfsrestore: examining media file 0
xfsrestore: inventory session uuid (8590224e-3c93-469c-a311-fc8f23029b2a) does not match the media header's session uuid (7eda9f86-f1e9-4dfd-b1d4-c50467912408)
xfsrestore: examining media file 1
xfsrestore: inventory session uuid (8590224e-3c93-469c-a311-fc8f23029b2a) does not match the media header's session uuid (7eda9f86-f1e9-4dfd-b1d4-c50467912408)
[...]
```

​				说明性消息会一直显示，直到找到匹配的备份。 		

## 和 ext4、XFS 一起使用的工具比较

​				这部分比较用于完成 ext4 和 XFS 文件系统中常用任务的工具。 		

| 任务                 | ext4             | XFS                               |
| -------------------- | ---------------- | --------------------------------- |
| 创建文件系统         | `mkfs.ext4`      | `mkfs.xfs`                        |
| 文件系统检查         | `e2fsck`         | `xfs_repair`                      |
| 重新定义文件系统大小 | `resize2fs`      | `xfs_growfs`                      |
| 保存文件系统的镜像   | `e2image`        | `xfs_metadump` 和 `xfs_mdrestore` |
| 标签或者调整文件系统 | `tune2fs`        | `xfs_admin`                       |
| 备份文件系统         | `tar` 和 `rsync` | `xfsdump` 和 `xfsrestore`         |
| 配额管理             | `quota`          | `xfs_quota`                       |
| 文件映射             | `filefrag`       | `xfs_bmap`                        |

注意

​					如果您需要通过网络进行备份的完整客户端-服务器解决方案，您可以使用 RHEL 9 中提供的 `bacula` 备份实用程序。有关 Bacula 的更多信息，请参阅 [Bacula 备份解决方案](https://www.bacula.org/documentation/documentation/)。 			

# 第 21 章 创建 XFS 文件系统

​			作为系统管理员，您可以在块设备上创建 XFS 文件系统，使其可以存储文件和目录。 	

## 21.1. 使用 mkfs.xfs 创建 XFS 文件系统

​				这个流程描述了如何在块设备上创建 XFS 文件系统。 		

**流程**

1. ​						要创建文件系统，请执行以下操作： 				

   - ​								如果设备是常规分区、LVM 卷、MD 卷、磁盘或者类似的设备，请使用以下命令： 						

     ```none
     # mkfs.xfs block-device
     ```

     - ​										使用到块设备的路径替换 *block-device*。例如： `/dev/sdb1`、`/dev/disk/by-uuid/05e99ec8-def1-4a5e-8a9d-5945339ceb2a` 或 `/dev/my-volgroup/my-lv`。 								
     - ​										一般情况下，默认选项是常见用途的最佳选择。 								
     - ​										在包含现有文件系统的块设备上使用 `mkfs.xfs` 时，添加 `-f` 选项来覆盖该文件系统。 								

   - ​								要在硬件 RAID 设备上创建文件系统，检查系统是否正确检测到该设备的条带几何结构： 						

     - ​										如果条带几何结构信息正确，则不需要额外的选项。创建文件系统： 								

       ```none
       # mkfs.xfs block-device
       ```

     - ​										如果信息不正确，请使用 `-d` 选项的 `su` 和 `sw 参数` 来手动指定条带几何结构。`su` 参数指定 RAID 块大小，`sw` 参数指定 RAID 设备中数据磁盘的数量。 								

       ​										例如： 								

       ```none
       # mkfs.xfs -d su=64k,sw=4 /dev/sda3
       ```

2. ​						使用以下命令等待系统注册新设备节点： 				

   ```none
   # udevadm settle
   ```

**其它资源**

- ​						`mkfs.xfs(8)` 手册页。 				

# 第 22 章 使用 RHEL 系统角色在块设备中创建 XFS 文件系统

​			这部分描述了如何使用 `存储` 角色在多个目标机器的块设备上创建 XFS 文件系统。 	

**先决条件**

- ​					存在一个使用该 `存储` 角色的 Ansible playbook。 			

  ​					如需有关如何应用此类 playbook 的信息，[请参阅 应用角色](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/getting-started-with-rhel-system-roles_configuring-basic-system-settings#applying-a-role_getting-started-with-rhel-system-roles)。 			

## 22.1. 在块设备中创建 XFS 文件系统的 Ansible playbook 示例

​				本节提供了一个 Ansible playbook 示例。此 playbook 应用存储角色，以使用默认参数在块设备中创建 XFS 文件系统。 		

警告

​					存储角色只能在未分区、整个磁盘或者逻辑卷(LV)上创建文件系统。它不能在分区中创建文件系统。 			

例 22.1. 在 /dev/sdb 上创建 XFS 的 playbook

```none
---
- hosts: all
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs
  roles:
    - rhel-system-roles.storage
```

- ​							卷名称（示例中为 `*barefs*` ）目前是任意的。Storage 角色根据 disk: 属性中列出的磁盘设备标识卷。`` 					

- ​							您可以省略 `fs_type: xfs` 行，因为 XFS 是 RHEL 9 中的默认文件系统。 					

- ​							要在 LV 上创建文件系统，请在 `disks:` 属性下提供 LVM 设置，包括括起的卷组。 					

  ​							不要提供到 LV 设备的路径。 					

**其它资源**

- ​						`/usr/share/ansible/roles/rhel-system-roles.storage/README.md` 文件。 				

## 22.2. 其它资源

- ​						[存储角色简介](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/managing-local-storage-using-rhel-system-roles_managing-file-systems#storage-role-intro_managing-local-storage-using-rhel-system-roles) 				

# 第 25 章 增加 XFS 文件系统的大小

​			作为系统管理员，您可以增大 XFS 文件系统的大小来使用较大的存储容量。 	

重要

​				目前不能缩小 XFS 文件系统的大小。 		

## 25.1. 使用 xfs_growfs 增加 XFS 文件系统的大小

​				这个流程描述了如何使用 `xfs_growfs` 工具增大 XFS 文件系统。 		

**先决条件**

- ​						确保底层块设备的大小适当，以便以后保留调整了大小的文件系统。为受影响的块设备使用合适的调整大小的方法。 				
- ​						挂载 XFS 文件系统。 				

**流程**

- ​						在挂载 XFS 文件系统时，使用 `xfs_growfs` 工具来增加其大小： 				

  ```none
  # xfs_growfs file-system -D new-size
  ```

  - ​								使用 XFS 文件系统的挂载点替换 *file-system*。 						

  - ​								使用 `-D` 选项，将 *new-size* 替换为在文件系统块数中指定的文件系统所需的新大小。 						

    ​								要找出给定 XFS 文件系统的块大小（kB），请使用 `xfs_info` 工具： 						

    ```none
    # xfs_info block-device
    
    ...
    data     =              bsize=4096
    ...
    ```

  - ​								如果没有 `-D` 选项，`xfs_growfs` 将文件系统增大到底层设备所支持的最大大小。 						

**其它资源**

- ​						`xfs_growfs(8)` 手册页。 				

# 第 26 章 配置 XFS 错误行为

​			您可以配置 XFS 文件系统在遇到不同的 I/O 错误时的行为方式。 	

## 26.1. XFS 中的可配置错误处理

​				当 I/O 操作期间发生错误时，XFS 文件系统以以下其中一种方式响应： 		

- ​						XFS 重复重试 I/O 操作，直到操作成功或 XFS 达到设定的限制。 				

  ​						限制是基于重试的最大次数或重试的最长时间。 				

- ​						XFS 认为错误是永久性的，并停止文件系统上的操作。 				

​				您可以配置 XFS 如何对以下错误情况做出响应： 		

- `EIO`

  ​							读取或写入时出错 					

- `ENOSPC`

  ​							该设备中没有剩余空间 					

- `ENODEV`

  ​							无法找到设备 					

​				您可以设置重试的最大次数，以及 XFS 认为其是永久错误前的最长时间（以秒为单位）。XFS 在达到任合一个限制时停止重试操作。 		

​				您还可以配置 XFS，以便在卸载文件系统时，XFS 会立即取消重试，而不考虑任何其他配置。但此配置可让卸载操作成功，尽管存在持续的错误。 		

**默认行为**

​					每个 XFS 错误情况的默认行为取决于错误上下文。`ENODEV` 等 XFS 错误都被视为致命且不可恢复的，无论重试次数如何。其默认重试限制为 0。 			

## 26.2. 特定和未定义的 XFS 错误条件的配置文件

​				以下目录保存用来控制不同错误条件的 XFS 错误行为的配置文件： 		

- `/sys/fs/xfs/*device*/error/metadata/EIO/`

  ​							对于 `EIO` 错误情况 					

- `/sys/fs/xfs/*device*/error/metadata/ENODEV/`

  ​							对于 `ENODEV` 错误情况 					

- `/sys/fs/xfs/*device*/error/metadata/ENOSPC/`

  ​							对于 `ENOSPC` 错误情况 					

- `/sys/fs/xfs/*device*/error/default/`

  ​							所有其他未定义错误条件的通用配置 					

​				每个目录包括以下配置文件来配置重试限制： 		

- `max_retries`

  ​							控制 XFS 重试操作的次数上限。 					

- `retry_timeout_seconds`

  ​							指定 XFS 停止重试操作后的时间限值（以秒为单位）。 					

## 26.3. 为特定条件设置 XFS 行为

​				这个步骤配置了 XFS 如何响应特定的错误条件。 		

**流程**

- ​						设置重试的最大重试次数、重试时间限制或两者： 				

  - ​								要设置重试的最大次数，请将所需的次数写入 `max_retries` 文件： 						

    ```none
    # echo value > /sys/fs/xfs/device/error/metadata/condition/max_retries
    ```

  - ​								要设置时间限制，将所需的秒数写入 `retry_timeout_seconds` 文件： 						

    ```none
    # echo value > /sys/fs/xfs/device/error/metadata/condition/retry_timeout_second
    ```

  ​						*value* 是介于 -1 和 C 带符号整数类型的最大可能值之间的数字。64 位 Linux 中是 2147483647。 				

  ​						在这两个限制中，值 `-1` 用于持续重试，`0` 用于立即停止。 				

  ​						*device* 是设备的名称，可以在 `/dev/` 目录中找到；例如，`sda`. 				

## 26.4. 为未定义条件设置 XFS 行为

​				此流程配置 XFS 如何对共享一个通用配置的所有未定义的错误情况做出响应。 		

**流程**

- ​						设置重试的最大重试次数、重试时间限制或两者： 				

  - ​								要设置重试的最大次数，请将所需的次数写入 `max_retries` 文件： 						

    ```none
    # echo value > /sys/fs/xfs/device/error/metadata/default/max_retries
    ```

  - ​								要设置时间限制，将所需的秒数写入 `retry_timeout_seconds` 文件： 						

    ```none
    # echo value > /sys/fs/xfs/device/error/metadata/default/retry_timeout_seconds
    ```

  ​						*value* 是介于 -1 和 C 带符号整数类型的最大可能值之间的数字。64 位 Linux 中是 2147483647。 				

  ​						在这两个限制中，值 `-1` 用于持续重试，`0` 用于立即停止。 				

  ​						*device* 是设备的名称，可以在 `/dev/` 目录中找到；例如，`sda`. 				

## 26.5. 设置 XFS 卸载行为

​				这个流程配置 XFS 在卸载文件系统时如何对错误情况做出响应。 		

​				如果您在文件系统中设置 `fail_at_unmount` 选项，它会在卸载过程中覆盖所有其他错误配置，并立即卸载文件系统，而不重试 I/O 操作。这允许卸载操作在出现持久错误时也可以成功。 		

警告

​					在卸载过程启动后，您不能更改 `fail_at_unmount` 值，因为卸载过程会从相应文件系统的 `sysfs` 接口删除配置文件。您必须在文件系统开始卸载前配置卸载行为。 			

**流程**

- ​						启用或禁用 `fail_at_unmount` 选项： 				

  - ​								要在文件系统卸载时取消重试所有操作，请启用这个选项： 						

    ```none
    # echo 1 > /sys/fs/xfs/device/error/fail_at_unmount
    ```

  - ​								要在文件系统卸载时遵守 `max_retries` 和 `retry_timeout_seconds` 重试限制，请禁用这个选项： 						

    ```none
    # echo 0 > /sys/fs/xfs/device/error/fail_at_unmount
    ```

  ​						*device* 是设备的名称，可以在 `/dev/` 目录中找到；例如，`sda`. 				

### ext4

ext4 通常用于主目录。 						

ext4 是 ext 文件系统系列的第四代。	

ext4 驱动程序可以对 ext2 和 ext3 文件系统进行读写，但 ext4 文件系统格式与 ext2 和 ext3 驱动程序不兼容。 		

ext4 添加了几个新的改进的功能，例如： 		

- 支持的文件系统大小高达 50 TiB 				
- 基于扩展的元数据 				
- 延迟分配 				
- 日志的 checksum 				
- 大型存储支持 				

基于扩展数据块的元数据和延迟分配功能提供了一种更加紧凑和高效的方法来跟踪文件系统中的已用空间。这些功能提高了文件系统性能，并减少了元数据所占用的空间。延迟分配允许文件系统延迟选择新写入用户数据的永久位置，直到数据刷新到磁盘。这可实现更高的性能，因为它允许更大的、连续的分配，允许文件系统根据更佳的信息做出决策。 		

ext4 中使用 `fsck` 工具的文件系统修复时间比 在 ext2 和 ext3 中要快得多。一些文件系统修复的性能会增加最多 6 倍。 		

## ext4

Ext4文件系统会把整块硬盘分成多个块组（Block Group），块组主要分为以下三部分。
• 超级块（Super Block）：记录整个文件系统的信息，包括 block与 inode的总量、已经使用的 inode和 block的数量、未使用的 inode和 block的数量、block与 inode的大小、文件系统的挂载时间、最近一次的写入时间、最近一次的磁盘检验时间等。
• i节点表（inode Table）：inode的默认大小为 128 Byte，用来记录文件的权限（r、w、x）、文件的所有者和属组、文件的大小、文件的状态改变时间（ctime）、文件的最近一次读取时间（atime）、文件的最近一次修改时间（mtime）、文件的特殊权限（如 SUID、SGID等）、文件的数据真正保存的 block编号。每个文件需要占用一个 inode。大家如果仔细查看，就会发现 inode 中是不记录文件名的，那是因为文件名是记录在文件上级目录的 block中的。
• 数据块（block）：block的大小可以是 1KB、2KB、4KB，默认为 4KB。block用于实际的数据存储，如果一个 block放不下数据，则可以占用多个 block。例如，有一个 10KB的文件需要存储，则会占用 3个 block，虽然最后一个 block不能占满，但也不能再放入其他文件的数据。这 3个 block有可能是连续的，也有可能是分散的。
（2）XFS文件系统原理
大家可能会比较奇怪，我们不是在讲 CentOS 7.x系统吗？在 CentOS 7.x中，默认文件系统不是 XFS吗？我们怎么还在讲解 Ext4文件系统？那是由于 XFS文件系统的基本原理和 Ext4非常相似，如果了解了 Ext4文件系统，那么也比较容易理解 XFS文件系统。
XFS文件系统是一种高性能的日志文件系统，在格式化速度上远超 Ext4文件系统，现在的硬盘越来越大，格式化的速度越来越慢，使得 Ext4文件系统的使用受到了限制（其实在运行速度上来讲，XFS对比 Ext4并没有明显的优势，只是在格式化的时候，速度差别明显）。而且 XFS理论上可以支持最大 18EB的单个分区，9EB的最大单个文件，这都远远超过 Ext4文件系统。

 数据区（Data section）：在数据区中，可以划分多个分配区群组（Allocation Groups），这个分配区群组大家就可以看成 Ext4文件系统中的块组了。在分配区群组中也划分为超级块、i节点、数据块，数据的存储方式也和 Ext4类似。
• 文件系统活动登录区（Log section）：在文件系统活动登录区中，文件的改变会在这里记录下来，直到相关的变化记录在硬盘分区中之后，这个记录才会被结束。那么如果文件系统由于特殊原因损坏，可以依赖文件系统活动登录区中的数据修复文件系统。
• 实时运行区（Realtime section）：这个文件系统不建议大家更改，有可能会影响硬盘的性能。

​			作为系统管理员，您可以创建、挂载、调整大小、备份和恢复 ext4 文件系统。ext4 文件系统是 ext3 文件系统的可扩展扩展。使用 Red Hat Enterprise Linux 9，它可以支持的最大的文件大小为 `16` TB，支持的最大的文件系统大小为 `50` TB。 	

## 44.1. ext4 文件系统的特性

​				以下是 ext4 文件系统的特性： 		

- ​						使用数据块：ext4 文件系统使用数据块，这可在使用大型文件时提高性能，并减少大型文件的元数据开销。 				

- ​						Ext4 相应地标记未分配的块组和 inode 表部分，这允许在文件系统检查期间跳过块组和表部分。它可快速进行文件系统检查，随着文件系统大小的增加，该检查将变得更加有益。 				

- ​						元数据校验和：默认情况下，在 Red Hat Enterprise Linux 9 中启用此功能。 				

- ​						ext4 文件系统的分配特性： 				

  - ​								持久性预分配 						
  - ​								延迟分配 						
  - ​								多块分配 						
  - ​								条带感知分配 						

- ​						扩展属性(`xattr`)：这允许系统为每个文件关联多个额外名称和值对。 				

- ​						配额日志：这避免了崩溃后需要很长时间的配额一致性检查。 				

  注意

  ​							ext4 中唯一支持的日志模式是 `data=ordered` （默认）。如需更多信息，请参阅 [RHEL 是否支持 EXT journaling 选项 "data=writeback"?](https://access.redhat.com/solutions/424073)知识库文章。 					

- ​						次秒时间戳 - 这为次秒提供时间戳。 				

**其它资源**

- ​						`ext4` 手册页。 				

## 44.2. 创建 ext4 文件系统

​				作为系统管理员，您可以使用 `mkfs.ext4` 命令在块设备上创建 ext4 文件系统。 		

**先决条件**

- ​						您磁盘中的一个分区。有关创建 MBR 或 GPT 分区的详情，请参阅 [在磁盘上创建分区表](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#assembly_creating-a-partition-table-on-a-disk_managing-file-systems)。 				

  ​						另外，还可使用 LVM 或者 MD 卷。 				

**流程**

1. ​						要创建 ext4 文件系统： 				

   - ​								对于常规分区设备、LVM 卷、MD 卷或者类似的设备，使用以下命令： 						

     ```none
     # mkfs.ext4 /dev/block_device
     ```

     ​								使用到块设备的路径替换 /dev/*block_device*。 						

     ​								例如：`/dev/sdb1`、`/dev/disk/by-uuid/05e99ec8-def1-4a5e-8a9d-5945339ceb2a` 或 `/dev/my-volgroup/my-lv`。一般说来，默认选项适用于大多数使用场景。 						

   - ​								对于条带块设备（如 RAID5 阵列），可以在创建文件系统时指定条带几何结构。使用正确的条带几何结构可提高 ext4 文件系统的性能。例如，要在 4k-块文件系统上创建跨距为 64k（即 16 x 4096）的文件系统，请使用以下命令： 						

     ```none
     # mkfs.ext4 -E stride=16,stripe-width=64 /dev/block_device
     ```

     ​								在给定示例中： 						

     - ​										stride=value：指定 RAID 块大小 								
     - ​										stripe-width=value：指定 RAID 设备中数据磁盘的数量，或者条带中的条带单元的数量。 								

   注意

   - ​									在创建文件系统时指定 UUID: 							

     ```none
     # mkfs.ext4 -U UUID /dev/block_device
     ```

     ​									使用您要设置的 UUID 替换 *UUID*：例如，`7cd65de3-e0be-41d9-b66d-96d749c02da7`。 							

     ​									使用 ext4 文件系统的路径替换 /dev/*block_device*，来将 UUID 添加给它：例如 `/dev/sda8`。 							

   - ​									在创建文件系统时指定标签： 							

     ```none
     # mkfs.ext4 -L label-name /dev/block_device
     ```

2. ​						查看创建的 ext4 文件系统： 				

   ```none
   # blkid
   ```

**其它资源**

- ​						`ext4` 手册页。 				
- ​						`mkfs.ext4` 手册页。 				

## 44.3. 挂载 ext4 文件系统

​				作为系统管理员，您可以使用 `mount` 工具挂载 ext4 文件系统。 		

**先决条件**

- ​						ext4 文件系统。有关创建 ext4 文件系统的详情，请参考 [创建 ext4 文件系统](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-an-ext4-file-system_getting-started-with-an-ext4-file-system)。 				

**流程**

1. ​						要创建一个挂载点来挂载文件系统： 				

   ```none
   # mkdir /mount/point
   ```

   ​						使用创建分区挂载点的目录名替换 */mount/point*。 				

2. ​						挂载 ext4 文件系统： 				

   - ​								要挂载一个没有额外选项的 ext4 文件系统： 						

     ```none
     # mount /dev/block_device /mount/point
     ```

   - ​								要永久挂载文件系统，请参阅 [永久挂载文件系统](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/assembly_persistently-mounting-file-systems_managing-file-systems)。 						

3. ​						查看挂载的文件系统： 				

   ```none
   # df -h
   ```

**其它资源**

- ​						`mount` 手册页。 				
- ​						`ext4` 手册页。 				
- ​						`fstab` 手册页。 				
- ​						[挂载文件系统](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/assembly_mounting-file-systems_managing-file-systems) 。 				

## 44.4. 重新定义 ext4 文件系统大小

​				作为系统管理员，您可以使用 `resize2fs` 工具调整 ext4 文件系统的大小。`resize2fs` 工具以文件系统块大小为单位读取大小，除非使用后缀表示特定的单位。以下后缀表示特定的单位： 		

- ​						s（扇区）- `512` 字节扇区 				
- ​						K(KB)- `1,024` 字节 				
- ​						M（兆字节）- `1,048,576` 字节 				
- ​						G(GB)- `1,073,741,824` 字节 				
- ​						T(TB)- `1,099,511,627,776` 字节 				

**先决条件**

- ​						ext4 文件系统。有关创建 ext4 文件系统的详情，请参考 [创建 ext4 文件系统](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-an-ext4-file-system_getting-started-with-an-ext4-file-system)。 				
- ​						调整大小后可保留文件系统的基本块设备。 				

**流程**

1. ​						要重新定义 ext4 文件系统大小，请执行以下步骤： 				

   - ​								要缩小并增大卸载的 ext4 文件系统的大小： 						

     ```none
     # umount /dev/block_device
     # e2fsck -f /dev/block_device
     # resize2fs /dev/block_device size
     ```

     ​								使用块设备的路径替换 */dev/block_device*，例如 `/dev/sdb1`。 						

     ​								使用 `s`、`K`、`M`、`G` 和 `T` 后缀将 *size* 替换为所需的调整大小的值。 						

   - ​								可以使用 `resize2fs` 命令在挂载时增大 ext4 文件系统： 						

     ```none
     # resize2fs /mount/device size
     ```

     注意

     ​									扩展时 size 参数是可选的（通常是多余的）。`resize2fs` 会自动扩展来填充容器的可用空间，通常是逻辑卷或分区。 							

2. ​						查看重新定义大小的文件系统： 				

   ```none
   # df -h
   ```

**其它资源**

- ​						`resize2fs` 手册页。 				
- ​						`e2fsck` 手册页。 				
- ​						`ext4` 手册页。 				

## 44.5. 和 ext4 和 XFS 一起使用的工具比较

​				这部分比较用于完成 ext4 和 XFS 文件系统中常用任务的工具。 		

| 任务                 | ext4             | XFS                               |
| -------------------- | ---------------- | --------------------------------- |
| 创建文件系统         | `mkfs.ext4`      | `mkfs.xfs`                        |
| 文件系统检查         | `e2fsck`         | `xfs_repair`                      |
| 重新定义文件系统大小 | `resize2fs`      | `xfs_growfs`                      |
| 保存文件系统的镜像   | `e2image`        | `xfs_metadump` 和 `xfs_mdrestore` |
| 标签或者调整文件系统 | `tune2fs`        | `xfs_admin`                       |
| 备份文件系统         | `tar` 和 `rsync` | `xfsdump` 和 `xfsrestore`         |
| 配额管理             | `quota`          | `xfs_quota`                       |
| 文件映射             | `filefrag`       | `xfs_bmap`                        |

注意

​					如果您需要通过网络进行备份的完整客户端-服务器解决方案，您可以使用 RHEL 9 中提供的 `bacula` 备份实用程序。有关 Bacula 的更多信息，请参阅 [Bacula 备份解决方案](https://www.bacula.org/documentation/documentation/)。 			

# 第 45 章 使用 RHEL 系统角色创建并挂载 ext4 文件系统

​			这部分描述了如何在磁盘上创建带有给定标签的 ext4 文件系统，并使用 `存储` 角色永久挂载文件系统。 	

**先决条件**

- ​					包含 `存储` 角色的 Ansible playbook 已存在。 			

​			如需有关如何应用此类 playbook 的信息，[请参阅 应用角色](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_basic_system_settings/index#applying-a-role_getting-started-with-rhel-system-roles)。 	

## 45.1. 创建和挂载 Ext4 文件系统的 Ansible playbook 示例

​				本节提供了一个 Ansible playbook 示例。此 playbook 应用存储角色来创建和挂载 Ext4 文件系统。 		

例 45.1. 在 /dev/sdb 上创建 Ext4 并挂载到 /mnt/data 的 playbook

```none
---
- hosts: all
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: ext4
        fs_label: label-name
        mount_point: /mnt/data
  roles:
    - rhel-system-roles.storage
```

- ​							playbook 在 `/dev/sdb` 磁盘上创建文件系统。 					
- ​							playbook 永久将文件系统挂载在 `*/mnt/data*` 目录。 					
- ​							文件系统的标签是 `*label-name*`。 					

**其它资源**

- ​						`/usr/share/ansible/roles/rhel-system-roles.storage/README.md` 文件。 				

### XFS 和 ext4 的比较 		

- 元数据错误行为

  在 ext4 中，当文件系统遇到元数据错误时您可以配置行为。默认的行为是继续操作。当 XFS 遇到不可恢复的元数据错误时，它会关闭文件系统，并返回 `EFSCORRUPTED` 错误。

- 配额

  在 ext4 中，您可以在创建文件系统时启用配额，或稍后在现有文件系统上启用配额。然后您可以使用挂载选项配置配额强制。

  XFS 配额不是一个可重新挂载的选项。您必须在初始挂载中激活配额。

  在 XFS 文件系统上运行 `quotacheck` 命令没有效果。当您第一次打开配额记帐时，XFS 会自动检查配额。

- 文件系统重新定义大小

  XFS 没有工具来缩小文件系统的大小。您只能增大 XFS 文件系统的大小。而 ext4 支持扩展和缩小文件系统大小。

- 内节点（inode）号

  ext4 文件系统不支持超过 2 <sup>32</sup> 内节点。

  XFS 动态分配内节点。只要文件系统上存在空闲空间，XFS 文件系统就无法耗尽 inode 。

  某些应用程序无法正确处理 XFS 文件系统上大于2 <sup>32</sup> 的 inode 数。这些应用程序可能会导致 32 位 stat 调用失败，返回值为 `EOVERFLOW` 。在以下情况下，inode 数超过 2 <sup>32</sup>: 

  * 文件系统大于 1 TiB，其 inode 为 256 字节。
  * 文件系统大于 2 TiB，其 inode 为 512 字节。

  如果您的应用程序由于 inode 数太大而失败，请使用 `-o inode32` 选项挂载 XFS 文件系统，来强制inode 数低于 2 <sup>32</sup>。请注意，使用 `inode32` 不会影响已分配了 64 位数的 inode。
  
  > 重要:
  >
  > 除非特定环境需要，否则 *请勿* 使用 `inode32` 选项。`inode32` 选项可改变分配行为。因此，如果没有可用空间在较低磁盘块中分配 inode ，则可能会出现 `ENOSPC` 错误。 						

### 本地文件系统选择

需要了解要在其上部署文件系统的目标系统。

* 有一个大的服务器吗？
* 有大的存储要求或一个本地的慢速的 SATA 驱动器吗？
* 所期望的应用程序存在哪一种 I/O 工作负载？
* 对吞吐量和延迟的要求是什么？
* 服务器和存储硬件稳定性如何？
* 文件和数据组的典型大小是什么？
* 如果系统失败，可以承受多少停机时间？ 				

如果您的服务器和存储设备都很大，那么 XFS 是最佳选择。即使存储阵列较小，当平均文件大小较大（例如，几百兆字节）时，XFS 也表现良好。 		

如果现有工作负载在 ext4 上表现良好，则继续使用 ext4 会为您和您的应用程序提供一个非常熟悉的环境。 		

ext4 文件系统在 I/O 能力有限的系统上往往表现更好。它在有限带宽（小于 200MB/s）上性能更好，最高可达到 1000 IOPS 的能力。对于较高能力的任何事情，XFS 往往会更快。

与 ext4 相比，XFS 消耗大约两倍的每个元数据所使用的 CPU ，因此如果有一个很少并发的 CPU 绑定工作负载，则 ext4  将更快。通常，如果应用程序使用单个读/写线程和小文件，则 ext4 更佳；而当应用程序使用多个读/写线程和较大的文件时，XFS 会更出色。 		

无法缩小 XFS 文件系统。如果需要缩小文件系统，考虑使用 ext4 ，其支持离线缩小。 	

通常，红帽建议使用 XFS，除非有 ext4 的特定用例。还应衡量目标服务器和存储系统上特定应用的性能，以确保选择了合适的文件系统类型。

| 场景                             | 推荐的文件系统 |
| -------------------------------- | -------------- |
| 没有特殊用例                     | XFS            |
| 大服务器                         | XFS            |
| 大存储设备                       | XFS            |
| 大文件                           | XFS            |
| 多线程 I/O                       | XFS            |
| 单线程 I/O                       | ext4           |
| 有限 I/O 功能（在 1000 IOPS 下） | ext4           |
| 有限带宽（在 200MB/s 下）        | ext4           |
| CPU 绑定工作负载                 | ext4           |
| 支持离线缩小                     | ext4           |

### 创建文件系统

```bash
mkfs.xfs /dev/vdb1
```

### 扫描连接到计算机的块设备并检索文件系统UUID

```bash
lsblk --fs
```
## 分布式文件系统

* ceph

  支持FUSE，客户端已经进入了linux-2.6.34内核，也就是说可以像ext3/rasierFS一样，选择ceph为文件系统。彻底的分布式，没有单点依赖，用C编写，性能较好。

* fastDFS

  国人在mogileFS的基础上进行改进的key-value型文件系统，不支持FUSE，提供比mogileFS更好的性能。

* GFS

  Google

* GFS2

  GFS2 为计算集群成员提供共享写入访问。其重点在于稳定性和可靠性，获得与本地文件系统类似的体验。

* lustre

  Oracle公司的企业级产品，非常庞大，对内核和ext3深度依赖。

* mogileFS

  Key-Value型元文件系统，不支持FUSE，应用程序访问它时需要API，主要用在web领域处理海量小图片，效率相比mooseFS高很多。

* mooseFS

## 网络文件系统

网络文件系统也称为客户端/服务器文件系统，使客户端系统能够访问存储在共享服务器上的文件。这使得多个系统上的多个用户可以共享文件和存储资源。 		

此类文件系统构建自一个或多个服务器，它们将一组文件系统导出到一个或多个客户端。客户端节点无法访问底层的块存储，而是使用允许更好的访问控制的协议来与存储进行交互。

* NFS (网络文件系统,Network File System)

  老牌网络文件系统。

* Samba (SMB/CIFS)

  使用 SMB 进行与微软 Windows 系统的文件共享。

* WebDAV



# 挂载文件系统

​			作为系统管理员，您可以在系统上挂载文件系统以访问其上的数据。 	

## 28.1. Linux 挂载机制

​				这部分论述了在 Linux 中挂载文件系统的基本概念。 		

​				在 Linux、UNIX 和类似的操作系统中，不同分区和可移动设备（例如，CD、DVD 或者 USB 闪存）上的文件系统可以附加到目录树中的某个点（挂载点），然后再次分离。虽然文件系统挂载在目录上，但无法访问该目录的原始内容。 		

​				请注意，Linux 不会阻止您将文件系统挂载到已附加了文件系统的目录。 		

​				挂载时，您可以通过以下方法识别设备： 		

- ​						通用唯一标识符(UUID)：例如，`UUID=34795a28-ca6d-4fd8-a347-73671d0c19cb` 				
- ​						卷标签：例如，`LABEL=home` 				
- ​						到非持久性块设备的完整路径：例如，`/dev/sda3` 				

​				当您使用 `mount` 命令挂载文件系统时，如果没有提供所有必需的信息，即设备名称、目标目录或文件系统类型，`mount` 工具会读取 `/etc/fstab` 文件的内容，以检查其中是否列出了给定的文件系统。`/etc/fstab` 文件包含设备名称列表、所选文件系统要挂载的目录，以及文件系统类型和挂载选项。因此，当挂载在 `/etc/fstab` 中指定的文件系统时，以下命令语法就足够了： 		

- ​						使用挂载点挂载： 				

  ```none
  # mount directory
  ```

- ​						使用块设备挂载： 				

  ```none
  # mount device
  ```

**其它资源**

- ​						`mount(8)` 手册页 				
- ​						[如何列出持久命名属性，如 UUID](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes)。 				

## 28.2. 列出当前挂载的文件系统

​				这个流程描述了如何在命令行上列出所有当前挂载的文件系统。 		

**流程**

- ​						要列出所有挂载的文件系统，请使用 `findmnt` 工具： 				

  ```none
  $ findmnt
  ```

- ​						要将列出的文件系统限制为特定的文件系统类型，请添加 `--types` 选项： 				

  ```none
  $ findmnt --types fs-type
  ```

  ​						例如： 				

  例 28.1. 只列出 XFS 文件系统

  ```none
  $ findmnt --types xfs
  
  TARGET  SOURCE                                                FSTYPE OPTIONS
  /       /dev/mapper/luks-5564ed00-6aac-4406-bfb4-c59bf5de48b5 xfs    rw,relatime
  ├─/boot /dev/sda1                                             xfs    rw,relatime
  └─/home /dev/mapper/luks-9d185660-7537-414d-b727-d92ea036051e xfs    rw,relatime
  ```

**其它资源**

- ​						`findmnt(8)` 手册页 				

## 28.3. 使用 mount 挂载文件系统

​				这个流程描述了如何使用 `mount` 工具挂载文件系统。 		

**先决条件**

- ​						确定在您选择的挂载点上还没有挂载文件系统： 				

  ```none
  $ findmnt mount-point
  ```

**流程**

1. ​						要附加某个文件系统，请使用 `mount` 工具： 				

   ```none
   # mount device mount-point
   ```

   例 28.2. 挂载 XFS 文件系统

   ​							例如：要挂载由 UUID 识别的本地 XFS 文件系统： 					

   ```none
   # mount UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b /mnt/data
   ```

2. ​						如果 `mount` 无法自动识别文件系统类型，请使用 `--types` 选项来指定： 				

   ```none
   # mount --types type device mount-point
   ```

   例 28.3. 挂载 NFS 文件系统

   ​							例如：要挂载远程 NFS 文件系统： 					

   ```none
   # mount --types nfs4 host:/remote-export /mnt/nfs
   ```

**其它资源**

- ​						`mount(8)` 手册页 				

## 28.4. 移动挂载点

​				这个步骤描述了如何将挂载的文件系统挂载点更改为不同的目录。 		

**流程**

1. ​						要更改挂载文件系统的目录： 				

   ```none
   # mount --move old-directory new-directory
   ```

   例 28.4. 移动本地文件系统

   ​							例如，将挂载在 `/mnt/userdirs/` 目录的文件系统移动到 `/home/` 挂载点： 					

   ```none
   # mount --move /mnt/userdirs /home
   ```

2. ​						验证文件系统是否已如预期移动： 				

   ```none
   $ findmnt
   $ ls old-directory
   $ ls new-directory
   ```

**其它资源**

- ​						`mount(8)` 手册页 				

## 28.5. 使用 umount 卸载文件系统

​				这个流程描述了如何使用 `umount` 工具卸载文件系统。 		

**流程**

1. ​						使用以下命令之一卸载文件系统： 				

   - ​								通过挂载点： 						

     ```none
     # umount mount-point
     ```

   - ​								通过设备： 						

     ```none
     # umount device
     ```

   ​						如果命令失败并显示类似如下的错误，这意味着文件系统正在使用，因为进程正在使用其上的资源： 				

   ```none
   umount: /run/media/user/FlashDrive: target is busy.
   ```

2. ​						如果文件系统正在使用，请使用 `fuser` 工具来确定哪个进程正在访问它。例如： 				

   ```none
   $ fuser --mount /run/media/user/FlashDrive
   
   /run/media/user/FlashDrive: 18351
   ```

   ​						之后，终止正在使用文件系统的进程，并尝试再次卸载它。 				

## 28.6. 常用挂载选项

​				这部分列出了 `mount` 工具的一些常用选项。 		

​				您可以按以下语法使用这些选项： 		

```none
# mount --options option1,option2,option3 device mount-point
```

表 28.1. 常用挂载选项

| 选项       | 描述                                                     |
| ---------- | -------------------------------------------------------- |
| `async`    | 对文件系统启用异步输入和输出操作。                       |
| `auto`     | 使用 `mount -a` 命令使文件系统被自动挂载。               |
| `defaults` | 为 `async,auto,dev,exec,nouser,rw,suid` 选项提供别名。   |
| `exec`     | 允许在特定文件系统中执行二进制文件。                     |
| `loop`     | 将镜像挂载为 loop 设备。                                 |
| `noauto`   | 默认行为禁用使用 `mount -a` 命令对文件系统进行自动挂载。 |
| `noexec`   | 不允许在特定文件系统中执行二进制文件。                   |
| `nouser`   | 不允许普通用户（即 root 用户）挂载和卸载文件系统。       |
| `remount`  | 如果已经挂载文件系统，则会重新挂载文件系统。             |
| `ro`       | 仅挂载文件系统以读取。                                   |
| `rw`       | 挂载文件系统以进行读和写操作。                           |
| `user`     | 允许普通用户（即 root 用户）挂载和卸载该文件系统。       |

# 第 29 章 在多个挂载点共享挂载

​			作为系统管理员，您可以重复挂载点以便从多个目录中访问文件系统。 	

## 29.1. 共享挂载的类型

​				您可以使用多种共享挂载。当您在共享挂载点挂载另一个文件系统时，这两种文件系统之间的区别就是这种情况。共享挂载使用*共享子树*功能实现。 		

​				可用的挂载类型如下： 		

- `private`

  ​							这个类型不接收或转发任何传播事件。 					 						当您在重复或者原始挂载点下挂载另一个文件系统时，不会反映在另一个文件系统中。 					

- `shared`

  ​							这个类型会为给定挂载点创建准确的副本。 					 						当挂载点被标记为 `shared` 挂载时，原始挂载点中的任何挂载都会反映在其中，反之亦然。 					 						这是根文件系统的默认挂载类型。 					

- `slave`

  ​							此类型会创建给定挂载点的有限重复。 					 						当挂载点标记为 `slave` 挂载时，原始挂载点中的任何挂载都会反映在该挂载点中，但 `slave` 挂载中的任何挂载都没有反映在其原始挂载中。 					

- `unbindable`

  ​							此类型可防止给定挂载点被复制。 					

**其它资源**

- ​						[Linux Weekly News 上的 *共享子树* 文章](https://lwn.net/Articles/159077/)。 				

## 29.2. 创建私有挂载点副本

​				这个流程将挂载点复制为私有挂载。您稍后挂载到复制或原始挂载点下的文件系统不会反映在另一个文件系统中。 		

**流程**

1. ​						从原始挂载点创建虚拟文件系统(VFS)节点： 				

   ```none
   # mount --bind original-dir original-dir
   ```

2. ​						将原始挂载点标记为私有： 				

   ```none
   # mount --make-private original-dir
   ```

   ​						或者，要更改所选挂载点以及其下的所有挂载点的挂载类型，请使用 `--make-rprivate` 选项，而不是 `--make-private` 选项。 				

3. ​						创建副本： 				

   ```none
   # mount --bind original-dir duplicate-dir
   ```

例 29.1. 将 /media 复制到 /mnt 作为专用挂载点

1. ​							从 `/media` 目录创建 VFS 节点： 					

   ```none
   # mount --bind /media /media
   ```

2. ​							将 `/media` 目录标记为私有： 					

   ```none
   # mount --make-private /media
   ```

3. ​							在 `/mnt` 中创建副本： 					

   ```none
   # mount --bind /media /mnt
   ```

4. ​							现在可以验证 `/media` 和 `/mnt` 共享内容，但 `/media` 中的挂载内容没有出现在 `/mnt` 中。例如，如果 CD-ROM 驱动器包含非空介质，并且 `/media/cdrom/` 目录存在，请使用： 					

   ```none
   # mount /dev/cdrom /media/cdrom
   # ls /media/cdrom
   EFI  GPL  isolinux  LiveOS
   # ls /mnt/cdrom
   #
   ```

5. ​							还可以验证 `/mnt` 目录中挂载的文件系统没有反映在 `/media` 中。例如，如果插入了使用 `/dev/sdc1` 设备的非空 USB 闪存，且 `/mnt/flashdisk/` 目录存在，请使用： 					

   ```none
   # mount /dev/sdc1 /mnt/flashdisk
   # ls /media/flashdisk
   # ls /mnt/flashdisk
   en-US  publican.cfg
   ```

**其它资源**

- ​						`mount(8)` 手册页 				

## 29.3. 创建共享挂载点副本

​				这个流程将挂载点复制为共享挂载。您稍后挂载到原始目录或副本下的文件系统始终反映在其它文件系统中。 		

**流程**

1. ​						从原始挂载点创建虚拟文件系统(VFS)节点： 				

   ```none
   # mount --bind original-dir original-dir
   ```

2. ​						将原始挂载点标记为共享： 				

   ```none
   # mount --make-shared original-dir
   ```

   ​						或者，要更改所选挂载点和其下的所有挂载点的挂载类型，请使用 `--make-rshared` 选项,而不是 `--make-shared`。 				

3. ​						创建副本： 				

   ```none
   # mount --bind original-dir duplicate-dir
   ```

例 29.2. 将 /media 重复到 /mnt 作为共享挂载点

​					要使 `/media` 和 `/mnt` 目录共享相同的内容： 			

1. ​							从 `/media` 目录创建 VFS 节点： 					

   ```none
   # mount --bind /media /media
   ```

2. ​							将 `/media` 目录标记为共享： 					

   ```none
   # mount --make-shared /media
   ```

3. ​							在 `/mnt` 中创建副本： 					

   ```none
   # mount --bind /media /mnt
   ```

4. ​							现在，可以验证 `/media` 中的挂载是否也出现在 `/mnt` 中。例如，如果 CD-ROM 驱动器包含非空介质，并且 `/media/cdrom/` 目录存在，请使用： 					

   ```none
   # mount /dev/cdrom /media/cdrom
   # ls /media/cdrom
   EFI  GPL  isolinux  LiveOS
   # ls /mnt/cdrom
   EFI  GPL  isolinux  LiveOS
   ```

5. ​							同样，还可以验证 `/mnt` 目录中挂载的任何文件系统是否反映在 `/media` 中。例如，如果插入了使用 `/dev/sdc1` 设备的非空 USB 闪存，且 `/mnt/flashdisk/` 目录存在，请使用： 					

   ```none
   # mount /dev/sdc1 /mnt/flashdisk
   # ls /media/flashdisk
   en-US  publican.cfg
   # ls /mnt/flashdisk
   en-US  publican.cfg
   ```

**其它资源**

- ​						`mount(8)` 手册页 				

## 29.4. 创建从挂载点副本

​				这个流程将挂载点复制为 `slave` 挂载类型。您稍后挂载在原始挂载点下的文件系统将反映在副本中，而不是反过来。 		

**流程**

1. ​						从原始挂载点创建虚拟文件系统(VFS)节点： 				

   ```none
   # mount --bind original-dir original-dir
   ```

2. ​						将原始挂载点标记为共享： 				

   ```none
   # mount --make-shared original-dir
   ```

   ​						或者，要更改所选挂载点和其下的所有挂载点的挂载类型，请使用 `--make-rshared` 选项,而不是 `--make-shared`。 				

3. ​						创建副本，并将其标记为 `slave` 类型： 				

   ```none
   # mount --bind original-dir duplicate-dir
   # mount --make-slave duplicate-dir
   ```

例 29.3. 将 /media 复制到 /mnt 作为从挂载点

​					这个示例演示了如何使 `/media` 目录的内容也出现在 `/mnt` 中，但 `/mnt` 目录中的任何挂载都不会反映在 `/media` 中。 			

1. ​							从 `/media` 目录创建 VFS 节点： 					

   ```none
   # mount --bind /media /media
   ```

2. ​							将 `/media` 目录标记为共享： 					

   ```none
   # mount --make-shared /media
   ```

3. ​							在 `/mnt` 中创建副本，并将其标记为 `slave` ： 					

   ```none
   # mount --bind /media /mnt
   # mount --make-slave /mnt
   ```

4. ​							验证 `/media` 中的挂载是否也出现在 `/mnt` 中。例如，如果 CD-ROM 驱动器包含非空介质，并且 `/media/cdrom/` 目录存在，请使用： 					

   ```none
   # mount /dev/cdrom /media/cdrom
   # ls /media/cdrom
   EFI  GPL  isolinux  LiveOS
   # ls /mnt/cdrom
   EFI  GPL  isolinux  LiveOS
   ```

5. ​							还要验证 `/mnt` 目录中挂载的文件系统是否没有反映在 `/media` 中。例如，如果插入了使用 `/dev/sdc1` 设备的非空 USB 闪存，且 `/mnt/flashdisk/` 目录存在，请使用： 					

   ```none
   # mount /dev/sdc1 /mnt/flashdisk
   # ls /media/flashdisk
   # ls /mnt/flashdisk
   en-US  publican.cfg
   ```

**其它资源**

- ​						`mount(8)` 手册页 				

## 29.5. 防止挂载点重复

​				这个流程将挂载点标记为 unbindable，因此不能在另一个挂载点中复制它。 		

**流程**

- ​						要将挂载点的类型改为 unbindable 挂载，请使用： 				

  ```none
  # mount --bind mount-point mount-point
  # mount --make-unbindable mount-point
  ```

  ​						或者，要更改所选挂载点和其下的所有挂载点的挂载类型，请使用 `--make-runbindable` 选项，而不是 `--make-unbindable` 选项。 				

  ​						重复此挂载的任何后续尝试都会失败，并显示以下错误： 				

  ```none
  # mount --bind mount-point duplicate-dir
  
  mount: wrong fs type, bad option, bad superblock on mount-point,
  missing codepage or helper program, or other error
  In some cases useful info is found in syslog - try
  dmesg | tail  or so
  ```

例 29.4. 防止 /media 被复制

- ​							要防止 `/media` 目录被共享，请使用： 					

  ```none
  # mount --bind /media /media
  # mount --make-unbindable /media
  ```

**其它资源**

- ​						`mount(8)` 手册页 				

# 第 30 章 永久挂载文件系统

​			作为系统管理员，您可以永久地挂载文件系统以配置不可移动的存储。 	

## 30.1. /etc/fstab 文件

​				这部分描述了控制文件系统永久挂载点的 `/etc/fstab` 配置文件。使用 `/etc/fstab` 是永久挂载文件系统的建议方法。 		

​				`/etc/fstab` 文件中的每一行定义了文件系统的挂载点。它包括六个字段，用空格分开： 		

1. ​						由持久属性标识的块设备或其 `/dev` 目录的路径。 				
2. ​						挂载该设备的目录。 				
3. ​						该设备的文件系统。 				
4. ​						文件系统的挂载选项。选项 `defaults` 表示在启动时使用默认选项挂载分区。本节还识别 `x-systemd.*选项*` 格式的 `systemd` 挂载单元选项。 				
5. ​						`dump` 工具的备份选项。 				
6. ​						`fsck` 工具的检查顺序。 				

注意

​					RHEL 9 中删除了用于备份文件系统的 `转储` 实用程序，并可在 EPEL 9 软件仓库中找到。 			

例 30.1. /etc/fstab 中的 /boot 文件系统

| 块设备                                      | 挂载点  | File system | 选项       | Backup | 检查 |
| ------------------------------------------- | ------- | ----------- | ---------- | ------ | ---- |
| `UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b` | `/boot` | `xfs`       | `defaults` | `0`    | `0`  |

​				`systemd` 服务从 `/etc/fstab` 中的条目自动生成挂载单元。 		

**其它资源**

- ​						`fstab(5)` 手册页 				
- ​						`systemd.mount(5)` 手册页 				

## 30.2. 在 /etc/fstab 中添加文件系统

​				这个流程描述了如何在 `/etc/fstab` 配置文件中为文件系统配置持久性挂载点。 		

**流程**

1. ​						找到文件系统的 UUID 属性： 				

   ```none
   $ lsblk --fs storage-device
   ```

   ​						例如： 				

   例 30.2. 查看分区的 UUID

   ```none
   $ lsblk --fs /dev/sda1
   
   NAME FSTYPE LABEL UUID                                 MOUNTPOINT
   sda1 xfs    Boot  ea74bbec-536d-490c-b8d9-5b40bbd7545b /boot
   ```

2. ​						如果挂载点目录不存在，请创建它： 				

   ```none
   # mkdir --parents mount-point
   ```

3. ​						以 root 用户身份，编辑 `/etc/fstab` 文件，并为文件系统添加一行，由 UUID 标识。 				

   ​						例如： 				

   例 30.3. /etc/fstab 中的 /boot 挂载点

   ```none
   UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b /boot xfs defaults 0 0
   ```

4. ​						重新生成挂载单元以便您的系统注册新配置： 				

   ```none
   # systemctl daemon-reload
   ```

5. ​						尝试挂载文件系统来验证配置是否正常工作： 				

   ```none
   # mount mount-point
   ```

**其它资源**

- ​						[持久性命名属性概述](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes)。 				

# 第 31 章 使用 RHEL 系统角色永久挂载文件系统

​			这部分描述了如何使用 `存储` 角色永久挂载文件系统。 	

**先决条件**

- ​					存在一个使用该 `存储` 角色的 Ansible playbook。 			

  ​					如需有关如何应用此类 playbook 的信息，[请参阅 应用角色](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_basic_system_settings/index#applying-a-role_getting-started-with-rhel-system-roles)。 			

## 31.1. 永久挂载文件系统的 Ansible playbook 示例

​				本节提供了一个 Ansible playbook 示例。此 playbook 应用存储角色，以立即和永久挂载 XFS 文件系统。 		

例 31.1. 将 /dev/sdb 上的文件系统挂载到 /mnt/data 的 playbook

```none
---
- hosts: all
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs
        mount_point: /mnt/data
  roles:
    - rhel-system-roles.storage
```

- ​							此 playbook 将文件系统添加到 `/etc/fstab` 文件中，并立即挂载文件系统。 					
- ​							如果 `/dev/sdb` 设备上的文件系统或挂载点目录不存在，则 playbook 会创建它们。 					

**其它资源**

- ​						`/usr/share/ansible/roles/rhel-system-roles.storage/README.md` 文件。 				

# 第 32 章 根据需要挂载文件系统

​			作为系统管理员，您可以将 NFS 等文件系统配置为按需自动挂载。 	

## 32.1. autofs 服务

​				本节解释了 `autofs` 服务的优点和基本概念，用于按需挂载文件系统。 		

​				使用 `/etc/fstab` 配置进行永久挂载的一个缺点是，无论用户访问挂载的文件系统的频率有多低，系统都必须投入资源来保持装载的文件系统。例如，当系统同时维护多个系统的 NFS 挂载时，这可能会影响系统性能。 		

​				`/etc/fstab` 的替代方法是使用基于内核的 `autofs` 服务。它由以下组件组成： 		

- ​						实施文件系统的内核模块，以及 				
- ​						执行所有其他功能的用户空间服务。 				

​				`autofs` 服务可以自动挂载和卸载文件系统（按需），从而节省了系统资源。它可用于挂载文件系统，如 NFS、AFS、SMBFS、CIFS、CIFS 和本地文件系统。 		

**其它资源**

- ​						`autofs(8)` 手册页。 				

## 32.2. autofs 配置文件

​				本节描述了 `autofs` 服务所使用的配置文件的用法和语法。 		

**主映射文件**

​					`autofs` 服务使用 `/etc/auto.master` （主映射）作为其默认的主配置文件。这可以通过使用 `/etc/autofs.conf` 配置文件中的 `autofs` 配置以及名称服务开关(NSS)机制来将其更改为使用其他受支持的网络源和名称。 			

​				所有 on-demand 挂载点都必须在主映射中配置。挂载点、主机名、导出的目录和选项都可以在一组文件（或其他支持的网络源）中指定，而不必为每个主机手动配置它们。 		

​				主映射文件列出了 `autofs` 控制的挂载点，以及它们相应的配置文件或网络来源（称为自动挂载映射）。master 映射的格式如下： 		

```none
mount-point  map-name  options
```

​				使用这种格式的变量有： 		

- *mount-point*

  ​							`autofs` 挂载点；例如，`/mnt/data`。 					

- *map-file*

  ​							映射源文件，其中包含挂载点列表以及应该挂载这些挂载点的文件系统的位置。 					

- *options*

  ​							如果提供了这个选项，则它们适用于给定映射中的所有条目（如果它们本身没有指定选项的话）。 					

例 32.1. /etc/auto.master 文件

​					以下是 `/etc/auto.master` 文件中的一个示例行： 			

```none
/mnt/data  /etc/auto.data
```

**映射文件**

​					映射文件配置单个 on-demand 挂载点的属性。 			

​				如果目录不存在，自动挂载程序会创建它们。如果在自动挂载程序启动之前目录已存在，则自动挂载程序在退出时不会删除它们。如果指定了超时，则如果在超时时间内没有访问该目录，则目录会被自动卸载。 		

​				映射的一般格式与主映射类似。但是，options 字段会出现在挂载点和位置之间，而不是像 master 映射那样在条目的末尾： 		

```none
mount-point  options  location
```

​				使用这种格式的变量有： 		

- *mount-point*

  ​							这指的是 `autofs` 挂载点。这可以是间接挂载的单个目录名称，也可以是直接挂载的挂载点的完整路径。每个直接和间接映射条目键（*挂载点*）后面都跟着一个以空格分隔的偏移目录列表（每个子目录名称都以 `/` 开头），这就是所谓的多挂载条目。 					

- *options*

  ​							在提供这个选项时，这些选项将附加到主映射条目选项（如果有的话），或者如果配置条目 `append_options` 设为 `no`，则使用这些选项代替主映射选项。 					

- *location*

  ​							这指的是文件系统的位置，如本地文件系统路径（对于以 `/` 开头的映射名称，前面带有 Sun 映射格式转义字符 `：`）、NFS 文件系统或其他有效的文件系统位置。 					

例 32.2. 映射文件

​					以下是映射文件（例如 `/etc/auto.misc` ）中的一个示例： 			

```none
payroll  -fstype=nfs4  personnel:/exports/payroll
sales    -fstype=xfs   :/dev/hda4
```

​					映射文件中的第一列指示 `autofs` 挂载点：来自名为 `personnel` 的服务器的 `sales` 和 `payroll`。第二列指示 `autofs` 挂载的选项。第三列显示挂载源。 			

​					根据给定的配置，`autofs` 挂载点将是 `/home/payroll` 和 `/home/sales`。通常省略 `-fstype=` 选项，如果文件系统是 NFS，则不需要该选项，如果系统默认是 NFS 挂载的 NFSv4，则包括 NFSv4 的挂载。 			

​					使用给定配置时，如果进程需要访问 `autofs` 卸载的目录，如 `/home/payroll/2006/July.sxc`，则 `autofs` 服务会自动挂载该目录。 			

**amd 映射格式**

​					`autofs` 服务也识别 `amd` 格式的映射配置。如果要重复使用为 `am-utils` 服务编写的现有的自动挂载程序配置（已从 Red Hat Enterprise Linux 中删除），这将非常有用。 			

​				但是，红帽建议使用前面章节中描述的更简单的 `autofs` 格式。 		

**其它资源**

- ​						`autofs(5)` 手册页 				
- ​						`autofs.conf(5)` 手册页 				
- ​						`auto.master(5)` 手册页 				
- ​						`/usr/share/doc/autofs/README.amd-maps` 文件 				

## 32.3. 配置 autofs 挂载点

​				这个流程描述了如何使用 `autofs` 服务配置按需挂载点。 		

**先决条件**

- ​						安装 `autofs` 软件包： 				

  ```none
  # dnf install autofs
  ```

- ​						启动并启用 `autofs` 服务： 				

  ```none
  # systemctl enable --now autofs
  ```

**流程**

1. ​						为位于 `/etc/auto.*identifier*` 的按需挂载点创建一个映射文件。使用标识挂载点的名称替换 *identifier*。 				

2. ​						在 映射文件中，按照 [autofs 配置文件](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#the-autofs-configuration-files_assembly_mounting-file-systems-on-demand) 部分中所述填写挂载点、选项和位置字段。 				

3. ​						在主映射文件中注册映射文件，如 [autofs 配置文件部分中所述](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#the-autofs-configuration-files_assembly_mounting-file-systems-on-demand)。 				

4. ​						允许服务重新读取配置，以便它可以管理新配置的 `autofs` 挂载： 				

   ```none
   # systemctl reload autofs.service
   ```

5. ​						尝试访问 on-demand 目录中的内容： 				

   ```none
   # ls automounted-directory
   ```

## 32.4. 使用 autofs 服务自动挂载 NFS 服务器用户主目录

​				这个流程描述了如何配置 **autofs** 服务来自动挂载用户主目录。 		

**先决条件**

- ​						已安装 **autofs** 软件包。 				
- ​						**autofs** 服务已启用并正在运行。 				

**流程**

1. ​						通过在需要挂载用户主目录的服务器上编辑 `/etc/auto.master` 文件，指定映射文件的挂载点和位置。要做到这一点，请在 `/etc/auto.master` 文件中添加以下行： 				

   ```none
   /home /etc/auto.home
   ```

2. ​						在需要挂载用户主目录的服务器中创建名为 `/etc/auto.home` 的映射文件，并使用以下参数编辑该文件： 				

   ```none
   * -fstype=nfs,rw,sync host.example.com:/home/&i
   ```

   ​						您可以跳过 `*fstype*` 参数，因为它默认为 `*nfs*`。有关详细信息，请参阅 `autofs(5)` 手册页。 				

3. ​						重新载入 `autofs` 服务： 				

   ```none
   # systemctl reload autofs
   ```

## 32.5. 覆盖或添加 autofs 站点配置文件

​				有时覆盖客户端系统上特定挂载点的站点默认值会很有用。 		

例 32.3. 初始条件

​					例如，请考虑以下情况： 			

- ​							自动挂载程序映射存储在 NIS 中，`/etc/nsswitch.conf` 文件具有以下指令： 					

  ```none
  automount:    files nis
  ```

- ​							`auto.master` 文件包含： 					

  ```none
  +auto.master
  ```

- ​							NIS `auto.master` 映射文件包含： 					

  ```none
  /home auto.home
  ```

- ​							NIS `auto.home` 映射包含： 					

  ```none
  beth    fileserver.example.com:/export/home/beth
  joe     fileserver.example.com:/export/home/joe
  *       fileserver.example.com:/export/home/&
  ```

- ​							`autofs` 配置选项 `BROWSE_MODE` 设为 `yes` ： 					

  ```none
  BROWSE_MODE="yes"
  ```

- ​							文件映射 `/etc/auto.home` 不存在。 					

**流程**

​					这部分描述了从不同服务器挂载主目录的示例，并使用所选条目增强 `auto.home`。 			

例 32.4. 从不同服务器挂载主目录

​					根据上述条件，假设客户端系统需要覆盖 NIS 映射 `auto.home` ，并从其他服务器挂载主目录。 			

- ​							在这种情况下，客户端需要使用以下 `/etc/auto.master` 映射： 					

  ```none
  /home ­/etc/auto.home
  +auto.master
  ```

- ​							`/etc/auto.home` 映射包含条目： 					

  ```none
  *    host.example.com:/export/home/&
  ```

​					由于自动挂载程序仅处理第一次出现的挂载点，即包含 `/etc/auto.home` 内容的 `/home` 目录，而不是 NIS `auto.home` 映射。 			

例 32.5. 仅使用所选条目增强 auto.home

​					或者，使用几个条目来增加站点范围的 `auto.home` 映射： 			

1. ​							创建一个 `/etc/auto.home` 文件映射，并在其中放置新条目。在结尾处，包含 NIS `auto.home` 映射。然后 `/etc/auto.home` 文件映射类似： 					

   ```none
   mydir someserver:/export/mydir
   +auto.home
   ```

2. ​							有了这些 NIS `auto.home` 映射条件，列出 `/home` 目录输出的内容： 					

   ```none
   $ ls /home
   
   beth joe mydir
   ```

​					最后一个示例按预期工作，因为 `autofs` 不包含与正在读取的文件映射同名的文件映射的内容。因此，`autofs` 转到 `nsswitch` 配置中的下一个映射源。 			

## 32.6. 使用 LDAP 存储自动挂载器映射

​				此流程将 `autofs` 配置为将自动挂载程序映射存储在 LDAP 配置中，而不是存储在 `autofs` 映射文件中。 		

**先决条件**

- ​						必须在所有配置的系统中安装 LDAP 客户端程序库，以便从 LDAP 检索自动挂载程序映射。在 Red Hat Enterprise Linux 上，`openldap` 软件包应作为 `autofs` 软件包的依赖项自动安装。 				

**流程**

1. ​						要配置 LDAP 访问，请修改 `/etc/openldap/ldap.conf` 文件。确保为您的站点正确设置了 `BASE`、`URI` 和 `schema` 选项。 				

2. ​						`rfc2307bis` 草案中描述了最近建立的用于在 LDAP 中存储自动映射的模式。要使用此模式，请在 `/etc/autofs.conf` 配置文件中通过删除模式定义中的注释字符来设置它。例如： 				

   例 32.6. 设置 autofs 配置

   ```none
   DEFAULT_MAP_OBJECT_CLASS="automountMap"
   DEFAULT_ENTRY_OBJECT_CLASS="automount"
   DEFAULT_MAP_ATTRIBUTE="automountMapName"
   DEFAULT_ENTRY_ATTRIBUTE="automountKey"
   DEFAULT_VALUE_ATTRIBUTE="automountInformation"
   ```

3. ​						确保配置中所有其他模式条目都被注释了。`rfc2307bis` 模式的 `automountKey` 属性替换 `rfc2307` 模式的 `cn` 属性。以下是 LDAP 数据交换格式(LDIF)配置的一个示例： 				

   例 32.7. LDIF 配置

   ```none
   # auto.master, example.com
   dn: automountMapName=auto.master,dc=example,dc=com
   objectClass: top
   objectClass: automountMap
   automountMapName: auto.master
   
   # /home, auto.master, example.com
   dn: automountMapName=auto.master,dc=example,dc=com
   objectClass: automount
   automountKey: /home
   automountInformation: auto.home
   
   # auto.home, example.com
   dn: automountMapName=auto.home,dc=example,dc=com
   objectClass: automountMap
   automountMapName: auto.home
   
   # foo, auto.home, example.com
   dn: automountKey=foo,automountMapName=auto.home,dc=example,dc=com
   objectClass: automount
   automountKey: foo
   automountInformation: filer.example.com:/export/foo
   
   # /, auto.home, example.com
   dn: automountKey=/,automountMapName=auto.home,dc=example,dc=com
   objectClass: automount
   automountKey: /
   automountInformation: filer.example.com:/export/&
   ```

**其它资源**

- ​						[`rfc2307bis` 草案](https://tools.ietf.org/html/draft-howard-rfc2307bis) 				

## 32.7. 使用 systemd.automount 在 /etc/fstab 按需挂载文件系统

​				这个步骤演示了如何在 `/etc/fstab` 中定义挂载点时，使用自动挂载 systemd 单元根据需要挂载文件系统。您必须为每个挂载添加自动挂载单元并启用它。 		

**流程**

1. ​						添加所需的 fstab 条目，如 [Chapter 30 中所述。永久挂载文件系统](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#assembly_persistently-mounting-file-systems_managing-file-systems)。例如： 				

   ```none
   /dev/disk/by-id/da875760-edb9-4b82-99dc-5f4b1ff2e5f4  /mount/point  xfs  defaults  0 0
   ```

2. ​						将 `x-systemd.automount` 添加到上一步中创建的条目的 options 字段中。 				

3. ​						加载新创建的单元，以便您的系统注册新配置： 				

   ```none
   # systemctl daemon-reload
   ```

4. ​						启动自动挂载单元： 				

   ```none
   # systemctl start mount-point.automount
   ```

**验证**

1. ​						检查 `*mount-point.automount*` 是否正在运行： 				

   ```none
   # systemctl status mount-point.automount
   ```

2. ​						检查自动挂载的目录是否有所需的内容： 				

   ```none
   # ls /mount/point
   ```

**其它资源**

- ​						`systemd.automount(5)` 手册页. 				
- ​						`systemd.mount(5)` 手册页. 				
- ​						[systemd 简介](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_basic_system_settings/index#introduction-to-systemd_configuring-basic-system-settings). 				

## 32.8. 使用 systemd.automount 通过挂载单元根据需要挂载文件系统

​				这个步骤演示了如何在由挂载单元定义挂载点时，使用自动挂载 systemd 单元根据需要挂载文件系统。您必须为每个挂载添加自动挂载单元并启用它。 		

**流程**

1. ​						创建挂载单元。例如： 				

   ```none
   mount-point.mount
   [Mount]
   What=/dev/disk/by-uuid/f5755511-a714-44c1-a123-cfde0e4ac688
   Where=/mount/point
   Type=xfs
   ```

2. ​						创建一个名称与挂载单元相同的单元文件，但带有 `.automount` 扩展。 				

3. ​						打开文件并创建 `[Automount]` 部分。将 `Where=` 选项设置为挂载路径： 				

   ```none
   [Automount]
   Where=/mount/point
   [Install]
   WantedBy=multi-user.target
   ```

4. ​						加载新创建的单元，以便您的系统注册新配置： 				

   ```none
   # systemctl daemon-reload
   ```

5. ​						启用并启动自动挂载单元： 				

   ```none
   # systemctl enable --now mount-point.automount
   ```

**验证**

1. ​						检查 `*mount-point.automount*` 是否正在运行： 				

   ```none
   # systemctl status mount-point.automount
   ```

2. ​						检查自动挂载的目录是否有所需的内容： 				

   ```none
   # ls /mount/point
   ```

**其它资源**

- ​						`systemd.automount(5)` 手册页. 				
- ​						`systemd.mount(5)` 手册页. 				
- ​						[systemd 简介](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_basic_system_settings/index#introduction-to-systemd_configuring-basic-system-settings). 				

# 第 33 章 使用 IdM 中的 SSSD 组件来缓存 autofs 映射

​			系统安全服务守护进程(SSSD)是一种系统服务，来访问远程服务目录和身份验证机制。当网络连接较慢时，数据缓存非常有用。要将 SSSD 服务配置为缓存 autofs 映射，请按照本节中的以下步骤操作。 	

## 33.1. 手动配置 autofs ，来将 IdM 服务器用作 LDAP 服务器

​				这个流程演示了如何配置 `autofs` ，来将 IdM 服务器用作 LDAP 服务器。 		

**流程**

1. ​						编辑 `/etc/autofs.conf` 文件，来指定 `autofs` 搜索的模式属性： 				

   ```none
   #
   # Other common LDAP naming
   #
   map_object_class = "automountMap"
   entry_object_class = "automount"
   map_attribute = "automountMapName"
   entry_attribute = "automountKey"
   value_attribute = "automountInformation"
   ```

   注意

   ​							用户可以在 `/etc/autofs.conf` 文件中以小写和大写形式写入属性。 					

2. ​						（可选）指定 LDAP 配置。有两种方法可以做到这一点：最简单的方法是让自动挂载服务自行发现 LDAP 服务器和位置： 				

   ```none
   ldap_uri = "ldap:///dc=example,dc=com"
   ```

   ​						*这个选项要求 DNS 包含可发现服务器的 SRV 记录。* 				

   ​						或者，明确设置要使用的 LDAP 服务器，以及用于 LDAP 搜索的基本 DN： 				

   ```none
   ldap_uri = "ldap://ipa.example.com"
   search_base = "cn=location,cn=automount,dc=example,dc=com"
   ```

3. ​						编辑 `/etc/autofs_ldap_auth.conf` 文件，以便 autofs 允许客户端通过 IdM LDAP 服务器进行身份验证。 				

   - ​								将 `authrequired` 更改为 yes。 						

   - ​								将主体设置为 IdM LDAP 服务器（*host/fqdn@REALM*）的 Kerberos 主机主体。主体名称用于连接 IdM 目录，来作为 GSS 客户端身份验证的一部分。 						

     ```none
     <autofs_ldap_sasl_conf
          usetls="no"
          tlsrequired="no"
          authrequired="yes"
          authtype="GSSAPI"
          clientprinc="host/server.example.com@EXAMPLE.COM"
          />
     ```

     ​								有关主机主体的更多信息，请参阅在 [IdM 中使用规范的 DNS 主机名](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_and_managing_identity_management/index#using-canonicalized-dns-host-names-in-idm_configuring-and-managing-idm)。 						

     ​								如有必要，请运行 `klist -k` 来获取确切的主机主体信息。 						

## 33.2. 配置 SSSD 来缓存 autofs 映射

​				SSSD 服务可用于缓存存储在 IdM 服务器上的 `autofs` 映射，而无需配置 `autofs` 以使用 IdM 服务器。 		

**先决条件**

- ​						`sssd` 软件包已安装。 				

**流程**

1. ​						打开 SSSD 配置文件： 				

   ```none
   # vim /etc/sssd/sssd.conf
   ```

2. ​						将 `autofs` 服务添加到由 SSSD 处理的服务列表中。 				

   ```none
   [sssd]
   domains = ldap
   services = nss,pam,autofs
   ```

3. ​						创建一个新的 `[autofs]` 部分。您可以将此留空，因为 `autofs` 服务的默认设置适用于大多数基础架构。 				

   ```none
   [nss]
   
   [pam]
   
   [sudo]
   
   [autofs]
   
   [ssh]
   
   [pac]
   ```

   ​						如需更多信息，请参阅 `sssd.conf` 手册页。 				

4. ​						（可选）为 `autofs` 条目设置搜索库。默认情况下，这是 LDAP 搜索库，但可以在 `ldap_autofs_search_base` 参数中指定子树。 				

   ```none
   [domain/EXAMPLE]
   
   ldap_search_base = "dc=example,dc=com"
   ldap_autofs_search_base = "ou=automount,dc=example,dc=com"
   ```

5. ​						重启 SSSD 服务： 				

   ```none
   # systemctl restart sssd.service
   ```

6. ​						检查 `/etc/nsswitch.conf` 文件，以便 SSSD 被列为自动挂载配置的源： 				

   ```none
   automount: sss files
   ```

7. ​						重启 `autofs` 服务： 				

   ```none
   # systemctl restart autofs.service
   ```

8. ​						通过列出用户的 `/home` 目录来测试配置，假设 `/home` 有一个主映射条目： 				

   ```none
   # ls /home/userName
   ```

   ​						如果这没有挂载远程文件系统，请检查 `/var/log/messages` 文件是否有错误。如有必要，通过将 `logging` 参数设为 `debug` 来提高 `/etc/sysconfig/autofs` 文件的 debug 级别。 				

## /etc/fstab

```bash
UUID=a89929229-44dd-409a-68be2c9f5571	/		xfs		defaults	0 0
# 指定设备，使用UUID或者设备文件，如/dev/vdb1。
# 目录挂载点。
# 文件系统类型。
# 以逗号分隔的、应用于设备的选项列表。
# dump命令使用第5个字段来备份设备。其他备份应用通常不使用此字段。
# fsck顺序字段，决定了在系统启动时是否执行fsck命令，以验证文件系统是否干净。值指示了fsck的运行顺序。
# 对于XFS,不使用fsck来检查自己的文件系统状态，为0。
# 对于ext4,根文件系统，为1;如果是其他ext文件系统，为2。
```

在 `/etc/fstab` 文件中添加或删除条目时，运行如下命令，以便让systemd注册新配置。

```bash
systemctl daemon-reload
```

### 验证

1. 卸载新文件系统。

2. 挂载文件系统

   ```bash
   mount /mountpoint
   ```

替代方法

```bash
findmnt --verify
```

# 检查和修复文件系统

​			RHEL 提供可以检查和修复文件系统的文件系统管理工具。这些工具通常被称为 `fsck` 工具，其中 `fsck` 是 *文件系统检查* 的缩写版本。在大多数情况下，这些工具会根据需要在系统引导期间自动运行，但也可以根据需要手动调用。 	

重要

​				文件系统检查程序只保证跨文件系统的元数据的一致性。它们不知道文件系统中所包含的实际数据，它们不是数据恢复工具。 		

## 27.1. 需要文件系统检查的场景

​				如果出现以下情况，可以使用相关的 `fsck` 工具来检查您的系统： 		

- ​						系统无法引导 				
- ​						特定磁盘上的文件损坏 				
- ​						由于不一致，文件系统关闭或变为只读 				
- ​						文件系统上的文件无法访问 				

​				发生文件系统不一致的原因可能有多种，包括但不限于硬件错误、存储管理错误和软件 bug 。 		

重要

​					文件系统检查工具不能修复硬件问题。如果修复操作成功，文件系统必须是完全可读写的。如果文件系统因为硬件错误而损坏，则必须首先将该文件系统移至好的磁盘，例如，使用 `dd(8)` 工具。 			

​				对于日志文件系统，启动时通常需要的所有操作是重播日志（如果需要），此操作通常是一个短操作。 		

​				但是，如果发生文件系统不一致或损坏的情况，即使是对于日志记录文件系统，也必须使用文件系统检查程序来修复文件系统。 		

重要

​					通过将 `/etc/fstab` 中的第 6 字段设为 `0`，可以在引导时禁用文件系统检查。但是，红帽不建议这样做，除非您在启动时遇到 `fsck` 问题，例如对于非常大的或远程文件系统。 			

**其它资源**

- ​						`fstab(5)` 手册页。 				
- ​						`fsck(8)` 手册页。 				
- ​						`dd(8)` 手册页。 				

## 27.2. 运行 fsck 的潜在副作用

​				通常，运行文件系统检查和修复工具至少可以自动修复发现的一些不一致问题。在某些情况下可能会出现以下问题： 		

- ​						如果无法修复，可以丢弃严重损坏的 inode 或目录。 				
- ​						可能会对文件系统进行大量更改。 				

​				要确保不会永久地进行意外或不必要的更改，请确保遵循流程中概述的任何预防步骤。 		

## 27.3. XFS 中的错误处理机制

​				这部分论述了 XFS 如何处理文件系统中各种错误。 		

#### 未完全卸载

​				日志维护文件系统上发生的元数据变化的事务记录。 		

​				在系统崩溃、电源故障或其他未完全卸载的情况下，XFS 使用 journal （也称为 log ）来恢复文件系统。挂载 XFS 文件系统时，内核执行日志恢复。 		

#### 损坏

​				在这种情况下，*损坏* 意味着文件系统中出现以下情况引起的错误，例如： 		

- ​						硬件故障 				
- ​						存储固件、设备驱动程序、软件堆栈或者文件系统本身的错误 				
- ​						导致文件系统部分内容被文件系统之外的内容覆盖的问题 				

​				当 XFS 检测到文件系统或文件系统元数据中的损坏时，它可以关闭文件系统，并在系统日志中报告该事件。请注意，如果损坏发生在托管 `/var` 目录的文件系统上，重启后这些日志将不可用。 		

例 27.1. 系统日志条目报告 XFS 崩溃

```none
# dmesg --notime | tail -15

XFS (loop0): Mounting V5 Filesystem
XFS (loop0): Metadata CRC error detected at xfs_agi_read_verify+0xcb/0xf0 [xfs], xfs_agi block 0x2
XFS (loop0): Unmount and run xfs_repair
XFS (loop0): First 128 bytes of corrupted metadata buffer:
00000000027b3b56: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000005f9abc7a: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000005b0aef35: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
00000000da9d2ded: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000001e265b07: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000006a40df69: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000000b272907: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
00000000e484aac5: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
XFS (loop0): metadata I/O error in "xfs_trans_read_buf_map" at daddr 0x2 len 1 error 74
XFS (loop0): xfs_imap_lookup: xfs_ialloc_read_agi() returned error -117, agno 0
XFS (loop0): Failed to read root inode 0x80, error 11
```

​				当尝试访问损坏的 XFS 文件系统时，用户空间工具通常会报告 *输入/输出错误* 消息。挂载带有损坏日志的 XFS 文件系统会导致挂载失败，并出现以下错误消息： 		

```none
mount: /mount-point: mount(2) system call failed: Structure needs cleaning.
```

​				您必须手动使用 `xfs_repair` 工具来修复损坏。 		

**其它资源**

- ​						`xfs_repair(8)` 手册页。 				

## 27.4. 使用 xfs_repair 检查 XFS 文件系统

​				这个过程使用 `xfs_repair` 工具对 XFS 文件系统执行只读检查。您必须手动使用 `xfs_repair` 工具来修复任何损坏。与其他文件系统修复工具不同，`xfs_repair` 不会在引导时运行，即使 XFS 文件系统没有被完全卸载。在未完全卸载的情况下，XFS 会在挂载时重播日志，从而确保文件系统一致；`xfs_repair` 不能在不先重新挂载脏日志的情况下修复带有脏日志的 XFS 文件系统。 		

注意

​					虽然 `xfsprogs` 软件包中有 `fsck.xfs` 二进制文件，但这仅用于满足在引导时查找 `fsck.file` 系统二进制文件的 `initscripts`。`fsck.xfs` 立即退出，退出代码为 0。 			

**流程**

1. ​						通过挂载和卸载文件系统重新显示日志： 				

   ```none
   # mount file-system
   # umount file-system
   ```

   注意

   ​							如果挂载失败，并带有结构需要清理的错误，则日志已损坏，且无法重播。试运行应发现并报告更多有关磁盘损坏的信息。 					

2. ​						使用 `xfs_repair` 工具执行试运行来检查文件系统。打印任何错误并指示将要采取的操作，而不修改文件系统。 				

   ```none
   # xfs_repair -n block-device
   ```

3. ​						挂载文件系统： 				

   ```none
   # mount file-system
   ```

**其它资源**

- ​						`xfs_repair(8)` 手册页。 				
- ​						`xfs_metadump(8)` 手册页。 				

## 27.5. 使用 xfs_repair 修复 XFS 文件系统

​				这个过程使用 `xfs_repair` 工具修复损坏的 XFS 文件系统。 		

**流程**

1. ​						使用 `xfs_metadump` 工具在修复前为诊断或测试目的创建元数据镜像。如果损坏是由软件 bug 导致的，则预修复文件系统元数据映像对于支持调查非常有用。预修复镜像中出现的损坏模式有助于分析根本原因。 				

   - ​								使用 `xfs_metadump` 调试工具将 XFS 文件系统中的元数据复制到文件。如果需要发送大的 `metadump` 文件来支持，可使用标准压缩工具来压缩生成的 `metadump` 文件，以减少文件大小。 						

     ```none
     # xfs_metadump block-device metadump-file
     ```

2. ​						通过重新挂载文件系统来重新显示日志： 				

   ```none
   # mount file-system
   # umount file-system
   ```

3. ​						使用 `xfs_repair` 工具来修复卸载的文件系统： 				

   - ​								如果挂载成功，则不需要额外的选项： 						

     ```none
     # xfs_repair block-device
     ```

   - ​								如果挂载失败，带有 *Structure needs cleaning* 错误，日志会破坏且无法重复显示。使用 `-L` 选项（*强制日志归零*）来清除日志： 						

     警告

     ​									该命令会导致崩溃时正在进行的所有元数据更新丢失，这可能会造成严重的文件系统损坏和数据丢失。只有在无法重播日志时，才应将其作为最后的手段。 							

     ```none
     # xfs_repair -L block-device
     ```

4. ​						挂载文件系统： 				

   ```none
   # mount file-system
   ```

**其它资源**

- ​						`xfs_repair(8)` 手册页。 				

## 27.6. ext2、ext3 和 ext4 中的处理机制出错

​				ext2、ext3 和 ext4 文件系统使用 `e2fsck` 工具来执行文件系统检查和修复。文件名 `fsck.ext2`、`fsck.ext3` 和 `fsck.ext4` 是 `e2fsck` 工具的硬链接。这些二进制文件在引导时自动运行，其行为因正在检查的文件系统和文件系统的状态而异。 		

​				对于不是元数据日志记录文件系统的 ext2 和没有日志的 ext4 文件系统，会调用完整的文件系统检查和修复。 		

​				对于带有元数据日志的 ext3 和 ext4 文件系统，日志将在用户空间中重播，从实用工具退出。这是默认操作，因为日志重播确保崩溃后文件系统的一致性。 		

​				如果这些文件系统在挂载时遇到元数据不一致的情况，它们会在文件系统超级块中记录此事实。如果 `e2fsck` 发现文件系统标记有这样的错误，`e2fsck` 会在重播日志（如果存在）后执行全面的检查。 		

**其它资源**

- ​						`fsck(8)` 手册页。 				
- ​						`e2fsck(8)` 手册页。 				

## 27.7. 使用 e2fsck 检查 ext2、ext3 或者 ext4 文件系统

​				这个流程使用 `e2fsck` 工具检查 ext2、ext3 或 ext4 文件系统。 		

**流程**

1. ​						通过重新挂载文件系统来重新显示日志： 				

   ```none
   # mount file-system
   # umount file-system
   ```

2. ​						执行空运行检查文件系统。 				

   ```none
   # e2fsck -n block-device
   ```

   注意

   ​							打印任何错误并指示将要采取的操作，而不修改文件系统。稍后一致性检查阶段可能会打印额外的错误，因为在修复模式下运行时，它会发现可能在早期阶段已经修复了的不一致问题。 					

**其它资源**

- ​						`e2image(8)` 手册页。 				
- ​						`e2fsck(8)` 手册页。 				

## 27.8. 使用 e2fsck 修复 ext2、ext3 或者 ext4 文件系统

​				这个流程使用 `e2fsck` 工具修复损坏的 ext2、ext3 或 ext4 文件系统。 		

**流程**

1. ​						保存文件系统镜像以进行支持调查。如果损坏是由软件 bug 导致的，则预修复文件系统元数据映像对于支持调查非常有用。预修复镜像中出现的损坏模式有助于分析根本原因。 				

   注意

   ​							严重损坏的文件系统可能会导致元数据镜像创建出现问题。 					

   - ​								如果要为测试目的创建镜像，请使用 `-r` 选项来创建与文件系统本身大小相同的稀疏文件。然后 `e2fsck` 可以直接对生成的文件进行操作。 						

     ```none
     # e2image -r block-device image-file
     ```

   - ​								如果您要创建要存档或提供用于诊断的镜像，请使用 `-Q` 选项，该选项可创建适合于传输的更紧凑的文件格式。 						

     ```none
     # e2image -Q block-device image-file
     ```

2. ​						通过重新挂载文件系统来重新显示日志： 				

   ```none
   # mount file-system
   # umount file-system
   ```

3. ​						自动修复文件系统。如果需要用户干预，`e2fsck` 指明其输出中未修复的问题，并在退出代码中反映此状态。 				

   ```none
   # e2fsck -p block-device
   ```

   **其它资源**

   - ​								`e2image(8)` 手册页。 						
   - ​								`e2fsck(8)` 手册页。 						

# 为 root 文件系统设置只读权限

​			有时，您需要使用只读权限挂载 root 文件系统(`/`)。示例用例包括在系统意外断电后增强安全性或确保数据完整性。 	

## 34.1. 始终保留写入权限的文件和目录

​				要使系统正常工作，一些文件和目录需要保留写权限。当 root 文件系统以只读模式挂载时，这些文件将使用 `tmpfs` 临时文件系统挂载到 RAM 中。 		

​				这些文件和目录的默认集合是从 `/etc/rwtab` 文件中读取的。请注意，`readonly-root` 需要在系统中存在这个文件。 		

```none
dirs	/var/cache/man
dirs	/var/gdm
<content truncated>

empty	/tmp
empty	/var/cache/foomatic
<content truncated>

files	/etc/adjtime
files	/etc/ntp.conf
<content truncated>
```

​				`/etc/rwtab` 文件中的条目遵循以下格式： 		

```none
copy-method    path
```

​				在这个语法中： 		

- ​						用指定如何将文件或者目录复制到 tmpfs 的关键字之一替换 *copy-method*。 				
- ​						使用到文件或目录的路径替换 *path*。 				

​				`/etc/rwtab` 文件可识别将文件或目录复制到 `tmpfs` 的以下方法： 		

- `empty`

  ​							一个空路径被复制到 `tmpfs`。例如： 					`empty /tmp`

- `dirs`

  ​							目录树被空复制到 `tmpfs`。例如： 					`dirs /var/run`

- `files`

  ​							将文件或目录树被完整地复制到 `tmpfs`。例如： 					`files /etc/resolv.conf`

​				在向 `/etc/rwtab.d/` 添加自定义路径时，也适用相同的格式。 		

## 34.2. 将 root 文件系统配置为在引导时使用只读权限挂载

​				使用这个流程时，根文件系统将以只读方式安装在所有后续引导上。 		

**流程**

1. ​						在 `/etc/sysconfig/readonly-root` 文件中，将 `READONLY` 选项设为 `yes` ： 				

   ```none
   # Set to 'yes' to mount the file systems as read-only.
   READONLY=yes
   ```

2. ​						在 / `etc/fstab` 文件中的 root 条目(`/` )中添加 `ro` 选项： 				

   ```none
   /dev/mapper/luks-c376919e...  /  xfs  x-systemd.device-timeout=0,ro  1  1
   ```

3. ​						在 `/etc/default/grub` 文件中的 `GRUB_CMDLINE_LINUX` 指令中添加 `ro` 选项，并确保该指令不包含 `rw` ： 				

   ```none
   GRUB_CMDLINE_LINUX="rhgb quiet... ro"
   ```

4. ​						重新创建 GRUB2 配置文件： 				

   ```none
   # grub2-mkconfig -o /boot/grub2/grub.cfg
   ```

5. ​						如果您需要在 `tmpfs` 文件系统中添加需要挂载具有写权限的文件和目录，请在 `/etc/rwtab.d/` 目录中创建一个文本文件，并将配置放在其中。 				

   ​						例如：要将 `/etc/example/file` 文件挂载为具有写权限，请将此行添加到 `/etc/rwtab.d/example` 文件中： 				

   ```none
   files /etc/example/file
   ```

   重要

   ​							对 `tmpfs` 中的文件和目录所做的更改不会在启动后保留。 					

6. ​						重启系统以应用更改。 				

**故障排除**

- ​						如果您错误地将 root 文件系统挂载为具有只读权限，则可以使用以下命令再次将其重新挂载为具有读写权限： 				

  ```none
  # mount -o remount,rw /
  ```

# 对带有配额的 XFS 限制存储空间的使用

​			您可以使用磁盘配额来限制用户或组群可用的磁盘空间量。您还可以定义一个警告级别，在用户消耗太多磁盘空间或分区已满前通知系统管理员。 	

​			XFS 配额子系统管理对磁盘空间（块）和文件(inode)使用情况的限制。XFS 配额控制或报告在用户、组群、目录或项目级别使用这些项目的使用情况。组和项目配额只适用于旧的非默认 XFS 磁盘格式。 	

​			在按目录或按项目管理时，XFS 管理与特定项目相关联的目录层次结构的磁盘使用情况。 	

## 35.1. 磁盘配额

​				在大多数计算环境中，磁盘空间不会是无限的。quota 子系统提供控制磁盘空间使用的机制。 		

​				您可以为独立用户和本地文件系统中的用户组群配置磁盘配额。这样就使得可以将分配给用户特定文件(如电子邮件)的空间与分配给用户所从事的项目的空间分开来管理。配额子系统在用户超过分配的限制时警告用户，但会为当前的工作提供一些额外的空间（硬限制/软限制）。 		

​				如果实施了配额，您需要检查是否超过了配额，并确保配额准确。如果用户重复超过配额或者持续达到其软限制，则系统管理员可以帮助用户确定如何使用较少的磁盘空间或增加用户的磁盘配额。 		

​				您可以通过配额设置来控制： 		

- ​						消耗的磁盘块数量。 				
- ​						内节点数，这是在 UNIX 文件系统中包含文件信息的数据结构。由于 inode 存储与文件相关的信息，因此这允许控制可创建的文件数。 				

## 35.2. xfs_quota 工具

​				您可以使用 `xfs_quota` 工具来管理 XFS 文件系统上的配额。另外，您可以使用关闭了限制强制的 XFS 文件系统作为有效的磁盘用量记帐系统。 		

​				XFS 配额系统在许多方面与其他文件系统不同。最重要的是，XFS 将配额信息视为文件系统元数据，并使用日志记录来提供更高级别的一致性保证。 		

**其它资源**

- ​						`xfs_quota(8)` 手册页。 				

## 35.3. XFS 中的文件系统配额管理

​				XFS 配额子系统管理对磁盘空间（块）和文件(inode)使用情况的限制。XFS 配额控制或报告在用户、组群、目录或项目级别使用这些项目的使用情况。组和项目配额只适用于旧的非默认 XFS 磁盘格式。 		

​				在按目录或按项目管理时，XFS 管理与特定项目相关联的目录层次结构的磁盘使用情况。 		

## 35.4. 为 XFS 启用磁盘配额

​				这个过程为 XFS 文件系统中的用户、组群和项目启用磁盘配额。启用配额后，`xfs_quota` 工具可用来设置限制并报告磁盘使用情况。 		

**流程**

1. ​						为用户启用配额： 				

   ```none
   # mount -o uquota /dev/xvdb1 /xfs
   ```

   ​						使用 `uqnoenforce` 替换 `uquota` ，以允许在不强制实施任何限制的情况下报告使用情况。 				

2. ​						为组群启用配额： 				

   ```none
   # mount -o gquota /dev/xvdb1 /xfs
   ```

   ​						使用 `gqnoenforce` 替换 `gquota`，以允许在不强制实施任何限制的情况下报告使用情况。 				

3. ​						为项目启用配额： 				

   ```none
   # mount -o pquota /dev/xvdb1 /xfs
   ```

   ​						将 `pquota` 替换为 `pqnoenforce`，以允许在不强制实施任何限制的情况下报告使用情况。 				

4. ​						或者，也可以在 `/etc/fstab` 文件中包含配额挂载选项。以下示例显示了 `/etc/fstab` 文件中用来分别在 XFS 文件系统上为用户、组和项目启用配额的条目。这些示例还使用读写权限挂载文件系统： 				

   ```none
   # vim /etc/fstab
   /dev/xvdb1    /xfs    xfs    rw,quota       0  0
   /dev/xvdb1    /xfs    xfs    rw,gquota      0  0
   /dev/xvdb1    /xfs    xfs    rw,prjquota    0  0
   ```

**其它资源**

- ​						`mount(8)` 手册页。 				
- ​						`xfs_quota(8)` 手册页。 				

## 35.5. 报告 XFS 使用量

​				您可以使用 `xfs_quota` 工具来设置限制并报告磁盘使用情况。默认情况下，`xfs_quota` 以交互方式运行，并处于基本模式。基本模式子命令只是报告使用情况，适用于所有用户。 		

**先决条件**

- ​						为 XFS 文件系统启用配额。[请参阅为 XFS 启用磁盘配额](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas)。 				

**流程**

1. ​						启动 `xfs_quota` shell： 				

   ```none
   # xfs_quota
   ```

2. ​						显示给定用户的使用情况和限制： 				

   ```none
   # xfs_quota> quota username
   ```

3. ​						显示块和内节点的空闲和已使用的数量： 				

   ```none
   # xfs_quota> df
   ```

4. ​						运行 help 命令来显示 `xfs_quota` 可使用的基本命令。 				

   ```none
   # xfs_quota> help
   ```

5. ​						指定 `q` 来退出 `xfs_quota`。 				

   ```none
   # xfs_quota> q
   ```

**其它资源**

- ​						`xfs_quota(8)` 手册页。 				

## 35.6. 修改 XFS 配额限制

​				启动带有 `-x` 选项的 `xfs_quota` 工具，来启用专家模式，并运行管理员命令，该命令允许修改配额系统。此模式的子命令允许实际限制的配置，并且仅可提供给具有升级特权的用户使用。 		

**先决条件**

- ​						为 XFS 文件系统启用配额。[请参阅为 XFS 启用磁盘配额](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas)。 				

**流程**

1. ​						启动带有 `-x` 选项的 `xfs_quota` shell ，来启用专家模式： 				

   ```none
   # xfs_quota -x
   ```

2. ​						报告具体文件系统的配额信息： 				

   ```none
   # xfs_quota> report /path
   ```

   ​						例如，若要显示 `/home` 的配额报告示例（在 `/dev/blockdevice` 上），请使用命令 `report -h /home`。此时会显示类似如下的输出： 				

   ```none
   User quota on /home (/dev/blockdevice)
   Blocks
   User ID      Used   Soft   Hard Warn/Grace
   ---------- ---------------------------------
   root            0      0      0  00 [------]
   testuser   103.4G      0      0  00 [------]
   ```

3. ​						修改配额限制： 				

   ```none
   # xfs_quota> limit isoft=500m ihard=700m user /path
   ```

   ​						例如，要为用户 `john` （其主目录为 `/home/john` ）软和硬 inode 数限制分别设置为 500 和 700，请使用以下命令： 				

   ```none
   # xfs_quota -x -c 'limit isoft=500 ihard=700 john' /home/
   ```

   ​						在这种情况下，传递 `mount_point`，这是挂载的 xfs 文件系统。 				

4. ​						运行 help 命令来显示 `xfs_quota -x` 可用的专家命令： 				

   ```none
   # xfs_quota> help
   ```

**其它资源**

- ​						`xfs_quota(8)` 手册页。 				

## 35.7. 为 XFS 设置项目限制

​				此流程为项目控制的目录配置限制。 		

**流程**

1. ​						将项目控制的目录添加到 `/etc/projects`。例如，以下命令将唯一 ID 为 11 的 `/var/log` 路径添加到 `/etc/projects` ：您的项目 ID 可以是任何映射到项目的数字值。 				

   ```none
   # echo 11:/var/log >> /etc/projects
   ```

2. ​						将项目名称添加到 `/etc/projid`，来将项目 ID 映射到项目名称。例如，以下命令将名为 `Logs` 的项目与上一步中定义的 ID 为 11 的项目相关联： 				

   ```none
   # echo Logs:11 >> /etc/projid
   ```

3. ​						初始化项目目录。例如，以下命令初始化项目目录 `/var`: 				

   ```none
   # xfs_quota -x -c 'project -s logfiles' /var
   ```

4. ​						为使用初始化目录的项目配置配额： 				

   ```none
   # xfs_quota -x -c 'limit -p bhard=lg logfiles' /var
   ```

**其它资源**

- ​						`xfs_quota(8)` 手册页。 				
- ​						`projid(5)` 手册页。 				
- ​						`projects(5)` 手册页。 				

# 第 36 章 对带有配额的 ext4 限制存储空间使用

​			在分配前，您必须在系统中启用磁盘配额。您可以为每个用户、每个组或每个项目分配磁盘配额。但是，如果设置了软限制，您可以在一个可配置的期间内（称为宽限期）超过这些配额。 	

## 36.1. 安装配额工具

​				您必须安装 `quota` RPM 软件包才能实现磁盘配额。 		

**流程**

- ​						安装 `quota` 软件包： 				

  ```none
  # dnf install quota
  ```

## 36.2. 在创建文件系统时启用配额功能

​				这个步骤描述了如何在创建文件系统时启用配额。 		

**流程**

1. ​						在创建文件系统时启用配额： 				

   ```none
   # mkfs.ext4 -O quota /dev/sda
   ```

   注意

   ​							默认仅启用和初始化用户和组群配额。 					

2. ​						更改创建文件系统时的默认设置： 				

   ```none
   # mkfs.ext4 -O quota -E quotatype=usrquota:grpquota:prjquota /dev/sda
   ```

3. ​						挂载文件系统： 				

   ```none
   # mount /dev/sda
   ```

**其它资源**

- ​						`ext4(5)` 手册页。 				

## 36.3. 在现有文件系统中启用配额功能

​				这个流程描述了如何使用 `tune2fs` 命令在现有文件系统上启用配额功能。 		

**流程**

1. ​						卸载文件系统： 				

   ```none
   # umount /dev/sda
   ```

2. ​						在现有文件系统中启用配额： 				

   ```none
   # tune2fs -O quota /dev/sda
   ```

   注意

   ​							默认只初始化用户和组群配额。 					

3. ​						更改默认值： 				

   ```none
   # tune2fs -Q usrquota,grpquota,prjquota /dev/sda
   ```

4. ​						挂载文件系统： 				

   ```none
   # mount /dev/sda
   ```

**其它资源**

- ​						`ext4(5)` 手册页。 				

## 36.4. 启用配额强制

​				在不使用任何额外选项挂载文件系统后，默认启用配额记帐，但不启用配额强制。 		

**先决条件**

- ​						启用配额功能，并初始化默认配额。 				

**流程**

- ​						通过 `quotaon` 为用户配额启用配额强制： 				

  ```none
  # mount /dev/sda /mnt
  ```

  ```none
  # quotaon /mnt
  ```

  注意

  ​							可以使用 `usrquota`、`grpquota` 或 `prjquota` 挂载选项在挂载时启用配额强制。 					

  ```none
  # mount -o usrquota,grpquota,prjquota /dev/sda /mnt
  ```

- ​						在所有文件系统中启用用户、组群和项目配额： 				

  ```none
  # quotaon -vaugP
  ```

  - ​								如果未指定 `-u`、`-g` 或 `-P` 选项，则仅启用用户配额。 						
  - ​								如果只指定 `-g` 选项，则只启用组配额。 						
  - ​								如果只指定 `-P` 选项，则只启用项目配额。 						

- ​						为特定文件系统（如 `/home`）启用配额： 				

  ```none
  # quotaon -vugP /home
  ```

**其它资源**

- ​						`quotaon(8)` 手册页。 				

## 36.5. 为每个用户分配配额

​				磁盘配额通过 `edquota` 命令分配给用户。 		

注意

​					`edquota` 使用由 `EDITOR` 环境变量定义的文本编辑器。要更改编辑器，请将 `~/.bash_profile` 文件中的 `EDITOR` 环境变量设为您选择的编辑器的完整路径。 			

**先决条件**

- ​						用户必须在设置用户配额前存在。 				

**流程**

1. ​						为用户分配配额： 				

   ```none
   # edquota username
   ```

   ​						使用您要为其分配配额的用户替换 *username*。 				

   ​						例如，如果您为 `/dev/sda` 分区启用配额，并执行命令 `quota testuser`，则会在系统配置的默认编辑器中显示以下内容： 				

   ```none
   Disk quotas for user testuser (uid 501):
   Filesystem   blocks   soft   hard   inodes   soft   hard
   /dev/sda      44043      0      0    37418      0      0
   ```

2. ​						更改所需限制。 				

   ​						如果值为 0，则代表没有设定限制。在文本编辑器中更改它们。 				

   ​						例如，下面显示了 testuser 的软和硬限制，它们分别被设置为 50000 和 55000。 				

   ```none
   Disk quotas for user testuser (uid 501):
   Filesystem   blocks   soft   hard   inodes   soft   hard
   /dev/sda      44043  50000  55000    37418      0      0
   ```

   - ​								第一列是启用了配额的文件系统的名称。 						
   - ​								第二列显示目前该用户使用的块数。 						
   - ​								下面的两列是为该用户在文件系统中设定软限制和硬限制。 						
   - ​								`inodes` 列显示用户当前使用的 inodes 数。 						
   - ​								最后两列是为该用户在文件系统中设定软和硬的内节点限制。 						
     - ​										硬块限制是用户或者组群可以使用的绝对最大磁盘空间量。达到这个限制后，就无法再使用其他磁盘空间。 								
     - ​										软块限制定义可以使用的最大磁盘空间量。然而，与硬限制不同，在一定时间内可以超过软限制。这段时间被称为*宽限期*。宽限期可以用秒、分钟、小时、天、周或月表示。 								

**验证步骤**

- ​						验证是否为该用户设定了配额： 				

  ```none
  # quota -v testuser
  Disk quotas for user testuser:
  Filesystem  blocks  quota  limit  grace  files  quota  limit  grace
  /dev/sda      1000*  1000   1000             0      0      0
  ```

## 36.6. 为每个组群分配配额

​				您可以根据组群分配配额。 		

**先决条件**

- ​						组群在设定组群配额前必须已经存在。 				

**流程**

1. ​						设置组群配额： 				

   ```none
   # edquota -g groupname
   ```

   ​						例如，要为 `devel` 组设置组配额： 				

   ```none
   # edquota -g devel
   ```

   ​						这个命令在文本编辑器中显示该组群的现有配额： 				

   ```none
   Disk quotas for group devel (gid 505):
   Filesystem   blocks  soft  hard  inodes  soft  hard
   /dev/sda     440400     0     0   37418     0     0
   ```

2. ​						修改限制并保存文件。 				

**验证步骤**

- ​						验证是否设定了组群配额： 				

  ```none
  # quota -vg groupname
  ```

## 36.7. 为每个项目分配配额

​				此流程为每个项目分配配额。 		

**先决条件**

- ​						在您的文件系统中启用了项目配额。 				

**流程**

1. ​						将项目控制的目录添加到 `/etc/projects`。例如，以下命令将唯一 ID 为 11 的 `/var/log` 路径添加到 `/etc/projects` ：您的项目 ID 可以是任何映射到项目的数字值。 				

   ```none
   # echo 11:/var/log >> /etc/projects
   ```

2. ​						将项目名称添加到 `/etc/projid`，来将项目 ID 映射到项目名称。例如，以下命令将名为 `Logs` 的项目与上一步中定义的 ID 为 11 的项目相关联： 				

   ```none
   # echo Logs:11 >> /etc/projid
   ```

3. ​						设置所需的限制： 				

   ```none
   # edquota -P 11
   ```

   注意

   ​							您可以通过其项目 ID（本例中为 `11`）或其名称（本例中为 `Logs`）来选择项目。 					

4. ​						使用 `quotaon`，启用配额强制： 				

   ​						请参阅 [启用配额强制](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#enabling-quota-enforcement_assembly_limiting-storage-space-usage-on-ext4-with-quotas)。 				

**验证步骤**

- ​						验证是否设置了项目配额： 				

  ```none
  # quota -vP 11
  ```

  注意

  ​							您可以使用项目 ID 或项目名称验证。 					

**其它资源**

- ​						`edquota(8)` 手册页。 				
- ​						`projid(5)` 手册页。 				
- ​						`projects(5)` 手册页。 				

## 36.8. 为软限制设置宽限期

​				如果给定配额具有软限制，您可以编辑宽限期，这是可以超过软限制的时间。您可以为用户、组或项目设置宽限期。 		

**流程**

- ​						编辑宽限期： 				

  ```none
  # edquota -t
  ```

重要

​					虽然其它 `edquota` 命令针对特定用户、组或项目的配额操作，但 `-t` 选项在每个启用了配额的文件系统上操作。 			

**其它资源**

- ​						`edquota(8)` 手册页。 				

## 36.9. 关闭文件系统配额

​				使用 `quotaoff` 来在指定的文件系统上关闭磁盘配额强制。执行此命令后可启用配额核算。 		

**流程**

- ​						关闭所有用户和组群配额： 				

  ```none
  # quotaoff -vaugP
  ```

  - ​								如果未指定 `-u`、`-g` 或 `-P` 选项，则仅禁用用户配额。 						
  - ​								如果只指定 `-g` 选项，则只禁用组配额。 						
  - ​								如果只指定 `-P` 选项，则只禁用项目配额。 						
  - ​								`-v` 开关会在命令执行时显示详细状态信息。 						

**其它资源**

- ​						`quotaoff(8)` 手册页。 				

## 36.10. 报告磁盘配额

​				您可以使用 `repquota` 工具创建磁盘配额报告。 		

**流程**

1. ​						运行 `repquota` 命令： 				

   ```none
   # repquota
   ```

   ​						例如，命令 `repquota /dev/sda` 产生此输出： 				

   ```none
   *** Report for user quotas on device /dev/sda
   Block grace time: 7days; Inode grace time: 7days
   			Block limits			File limits
   User		used	soft	hard	grace	used	soft	hard	grace
   ----------------------------------------------------------------------
   root      --      36       0       0              4     0     0
   kristin   --     540       0       0            125     0     0
   testuser  --  440400  500000  550000          37418     0     0
   ```

2. ​						查看所有启用了配额的文件系统的磁盘用量报告： 				

   ```none
   # repquota -augP
   ```

​				每个用户后显示的 `--` 符号确定是否超过了块或 inode 限制。如果超过了任何一个软限制，则 `+` 字符会出现在相应的 `-` 字符的位置。第一个 `-` 字符表示块限制，第二个表示 inode 限制。 		

​				`grace` 列通常为空。如果超过了软限制，则该列包含的时间规格等同于宽限期中剩余的时间量。如果宽限期过期了，则 `none` 会出现在其位置上。 		

**其它资源**

​					有关详细信息，请参阅 `repquota(8)` 手册页。 			

# 第 37 章 丢弃未使用块

​			您可以在支持它们的块设备中执行或调度丢弃操作。 	

## 37.1. 块忽略操作

​				块忽略操作丢弃了被挂载的文件系统不再使用的块。它们在以下方面很有用： 		

- ​						固态驱动器（SSD） 				
- ​						精简置备存储 				

#### 要求

​				基本文件系统的块设备必须支持物理的丢弃（discard）操作。 		

​				如果 `/sys/block/*device*/queue/discard_max_bytes` 文件中的值不为零，则支持物理丢弃操作。 		

## 37.2. 块丢弃操作的类型

​				您可以使用不同方法运行 discard 操作： 		

- 批量丢弃

  ​							由用户明确运行。它们丢弃所选文件系统中的所有未使用块。 					

- 在线丢弃

  ​							在挂载时指定。它们在没有用户干预的情况下实时运行。在线丢弃操作只丢弃从已使用到空闲的块。 					

- 定期丢弃

  ​							是 `systemd` 服务定期运行的批量操作。 					

​				XFS 和 ext4 文件系统以及 VDO 支持所有类型。 		

#### 建议

​				红帽建议您使用批处理或周期性丢弃。 		

​				仅在以下情况下使用在线丢弃： 		

- ​						系统负载不允许使用批量丢弃，或者 				
- ​						为了保持性能，需要在线丢弃操作。 				

## 37.3. 执行批块丢弃

​				这个过程执行批块丢弃操作，忽略挂载的文件系统中未使用的块。 		

**先决条件**

- ​						挂载文件系统。 				
- ​						文件系统底层的块设备支持物理忽略操作。 				

**流程**

- ​						使用 `fstrim` 工具： 				

  - ​								要只在所选文件系统中执行丢弃，请使用： 						

    ```none
    # fstrim mount-point
    ```

  - ​								要在所有挂载的文件系统中执行丢弃，请使用： 						

    ```none
    # fstrim --all
    ```

​				如果您在以下设备上执行 `fstrim` 命令： 		

- ​						不支持丢弃操作的设备，或者 				
- ​						由多个设备组成的逻辑设备（LVM 或者 MD），其中任意设备不支持丢弃操作： 				

​				下面的信息将显示： 		

```none
# fstrim /mnt/non_discard

fstrim: /mnt/non_discard: the discard operation is not supported
```

**其它资源**

- ​						`fstrim(8)` 手册页。 				

## 37.4. 启用在线块丢弃

​				这个过程启用在线块丢弃操作，该操作可自动丢弃所有支持的文件系统中未使用的块。 		

**流程**

- ​						在挂载时启用在线丢弃： 				

  - ​								手动挂载文件系统时，请添加 `-o discard` 挂载选项： 						

    ```none
    # mount -o discard device mount-point
    ```

  - ​								永久挂载文件系统时，请将 `discard` 选项添加到 `/etc/fstab` 文件的挂载条目中。 						

**其它资源**

- ​						`mount(8)` 手册页。 				
- ​						`fstab(5)` 手册页。 				

## 37.5. 启用定期块丢弃

​				这个流程启用 `systemd` 计时器，它会定期丢弃所有支持的文件系统上未使用的块。 		

**流程**

- ​						启用并启动 `systemd` 计时器： 				

  ```none
  # systemctl enable --now fstrim.timer
  ```

# 第 38 章 使用 RHEL 系统角色启用在线块丢弃

​			本节描述了如何使用 `存储` 角色启用在线块丢弃。 	

**先决条件**

- ​					包含 `存储` 角色的 Ansible playbook 已存在。 			

  ​					如需有关如何应用此类 playbook 的信息，[请参阅 应用角色](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_basic_system_settings/index#applying-a-role_getting-started-with-rhel-system-roles)。 			

## 38.1. 启用在线块丢弃的 Ansible playbook 示例

​				本节提供了一个 Ansible playbook 示例。此 playbook 应用存储角色，以挂载启用了在线块丢弃的 XFS 文件系统。 		

例 38.1. 一个 playbook，它在 /mnt/data/ 上启用在线块丢弃功能

```none
---
- hosts: all
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs
        mount_point: /mnt/data
        mount_options: discard
  roles:
    - rhel-system-roles.storage
```

**其它资源**

- ​						[永久挂载文件系统的 Ansible playbook 示例](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/managing-local-storage-using-rhel-system-roles_managing-file-systems#an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles) 				
- ​						`/usr/share/ansible/roles/rhel-system-roles.storage/README.md` 文件。 				

## 文件系统转换

### ext2 --> ext3

用 tune2fs 命令就能把一个 ext2fs 文件系统转为 ext3fs 文件系统。例如，如果在 /dev/hda4 上有个 ext2fs 文件系统，那么可以用下面的命令进行转换：

```bash
tune2fs -j /dev/hda4
```


接着要修改 /etc/fstab 中对应于该分区的配置项，使之读取 ext3 而不是 ext2 。