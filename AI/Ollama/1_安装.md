# 安装

[TOC]

## Linux

要安装 Ollama，请运行以下命令：

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 手动安装

> **注意：**
>
> 如果要从以前的版本升级，则应先使用 `sudo rm -rf /usr/lib/ollama` 删除旧库。

下载并解压软件包：

```bash
curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz
sudo tar -C /usr -xzf ollama-linux-amd64.tgz
```

启动 Ollama：

```bash
ollama serve
```

在另一个终端中，验证 Ollama 是否正在运行：

```bash
ollama -v
```

### AMD GPU 安装

如果有 AMD GPU，还要下载并解压缩其他 ROCm 软件包：

```bash
curl -L https://ollama.com/download/ollama-linux-amd64-rocm.tgz -o ollama-linux-amd64-rocm.tgz
sudo tar -C /usr -xzf ollama-linux-amd64-rocm.tgz
```

### ARM64 安装

下载并解压缩特定于 ARM64 的包：

```bash
curl -L https://ollama.com/download/ollama-linux-arm64.tgz -o ollama-linux-arm64.tgz
sudo tar -C /usr -xzf ollama-linux-arm64.tgz    
```

### 将 Ollama 添加为启动服务（推荐）

为 Ollama 创建用户和组：

```bash
sudo useradd -r -s /bin/false -U -m -d /usr/share/ollama ollama
sudo usermod -a -G ollama $(whoami)
```

创建 `/etc/systemd/system/ollama.service` 服务文件 ：

```ini
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=$PATH"

[Install]
WantedBy=default.target
```

然后启动服务：

```bash
sudo systemctl daemon-reload
sudo systemctl enable ollama   
```

### 安装 CUDA 驱动程序（可选）

[下载并安装](https://developer.nvidia.com/cuda-downloads) CUDA 。

通过运行以下命令验证驱动程序是否已安装，该命令应打印有关 GPU 的详细信息：

```bash
nvidia-smi    
```

### 安装 AMD ROCm 驱动程序（可选）

[下载并安装](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/tutorial/quick-start.html) ROCm v6 。

### 启动 Ollama

启动 Ollama 并验证它是否正在运行：

```bash
sudo systemctl start ollama
sudo systemctl status ollama
```

> **注意：**
>
> While AMD has contributed the `amdgpu` driver upstream to the official linux kernel source, the version is older and may not support all ROCm features. We recommend you install the latest driver from https://www.amd.com/en/support/linux-drivers for best support of your Radeon GPU.
> 虽然 AMD 已将 `amdgpu` 驱动程序贡献到官方 linux 的上游 kernel 源，版本较旧，可能不支持所有 ROCm 功能。我们 建议您安装最新的驱动程序 https://www.amd.com/en/support/linux-drivers 为您的 Radeon GPU 提供最佳支持。

### 定制

要自定义 Ollama 的安装，可以通过运行以下命令来编辑 systemd 服务文件或环境变量：

```bash
sudo systemctl edit ollama
```

或者，手动创建 `/etc/systemd/system/ollama.service.d/override.conf` 覆盖文件 ：

```ini
[Service]
Environment="OLLAMA_DEBUG=1"
```

### 更新

通过再次运行安装脚本来更新 Ollama：

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

或者通过重新下载 Ollama：

```bash
curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz
sudo tar -C /usr -xzf ollama-linux-amd64.tgz
```

### 安装特定版本

`OLLAMA_VERSION` 环境变量与安装脚本一起使用，以安装特定版本的 Ollama，包括预发行版。可以在 [releases 页面](https://github.com/ollama/ollama/releases)中找到版本号。

例如：

```bash
curl -fsSL https://ollama.com/install.sh | OLLAMA_VERSION=0.5.7 sh  
```

### 查看日志

要查看作为启动服务运行的 Ollama 的日志，请运行：

```bash
journalctl -e -u ollama
```

### 卸载

删除 ollama 服务：

```bash
sudo systemctl stop ollama
sudo systemctl disable ollama
sudo rm /etc/systemd/system/ollama.service
```

从 bin 目录（`/usr/local/bin`、`/usr/bin` 或 `/bin`）中删除 ollama 二进制文件：

```bash
sudo rm $(which ollama)
```

删除下载的模型以及 Ollama 服务用户和组：

```bash
sudo rm -r /usr/share/ollama
sudo userdel ollama
sudo groupdel ollama
```

删除已安装的库：

```bash
sudo rm -rf /usr/local/lib/ollama
```

## Docker

官方 [Ollama Docker 镜像](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` 可在 Docker Hub 上找到。

### 仅 CPU

```bash
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

### Nvidia GPU

安装 [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation) 。

#### 使用 Apt 安装

配置存储库

```bash
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey \
    | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list \
    | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' \
    | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt-get update
```

安装 NVIDIA Container Toolkit 软件包

```bash
sudo apt-get install -y nvidia-container-toolkit
```

#### 使用 Yum 或 Dnf 安装

配置存储库

```bash
curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo \
    | sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo
```

安装 NVIDIA Container Toolkit 软件包

```bash
sudo yum install -y nvidia-container-toolkit
```

#### 配置 Docker 以使用 Nvidia 驱动程序

```bash
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

#### 启动容器

```bash
docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

> 注意：
>
> 如果在 NVIDIA JetPack 系统上运行，Ollama 无法自动发现正确的 JetPack 版本。将环境变量 JETSON_JETPACK=5 或 JETSON_JETPACK=6 传递给容器以选择版本 5 或 6。

### AMD GPU

要使用带有 AMD GPU 的 Docker 运行 Ollama，请使用 `rocm` 标签和以下命令：

```bash
docker run -d --device /dev/kfd --device /dev/dri -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama:rocm
```

### 在本地运行模型

现在可以运行模型：

```bash
docker exec -it ollama ollama run llama3.2
```

## macOS

https://ollama.com/download/Ollama-darwin.zip

## Windows

https://ollama.com/download/OllamaSetup.exe

不再需要 WSL！

Ollama 现在作为本机 Windows 应用程序运行，包括 NVIDIA 和 AMD Radeon GPU 支持。安装 Ollama for Windows 后，Ollama 将在后台运行，并且 ` ollama` 命令行可在 `cmd`、`powershell` 或您最喜欢的终端应用程序中使用。像往常一样，Ollama [api](https://github.com/ollama/ollama/blob/main/docs/api.md) 将在 `http://localhost:11434` 。

### 系统要求

- Windows 10 22H2 或更高版本，家庭版或专业版
- NVIDIA 452.39 或更高版本的驱动程序（如果有 NVIDIA 卡）
- AMD Radeon 驱动程序 https://www.amd.com/en/support （如果有 Radeon 卡）

Ollama 使用 unicode 字符进行进度指示，在 Windows 10 中，这些字符可能会在某些较旧的终端字体中呈现为未知方块。如果看到此内容，请尝试更改终端字体设置。

### 文件系统要求

Ollama 安装不需要 Administrator，默认情况下安装在您的主目录中。至少需要 4GB 的空间来进行二进制安装。安装 Ollama  后，将需要额外的空间来存储大型语言模型，其大小可能为数十到数百 GB 。如果主目录没有足够的空间，可以更改二进制文件的安装位置和模型的存储位置。

#### 更改安装位置

要将 Ollama 应用程序安装在主目录以外的位置，请使用以下标志启动安装程序

```bash
OllamaSetup.exe /DIR="d:\some\location"
```

#### 更改模型位置

要更改 Ollama 存储下载模型的位置而不是使用主目录，请在用户帐户中设置环境变量 `OLLAMA_MODELS` 。

1. 启动设置 （Windows 11） 或控制面板 （Windows 10） 应用程序并搜索*环境变量*。
2. 单击 *Edit environment variables（编辑您账户的环境变量*）。
3. Edit or create a new variable for your user account for `OLLAMA_MODELS` where you want the models stored
   为要存储模型的`OLLAMA_MODELS`的用户帐户编辑或创建新变量
4. 单击 确定/应用 保存。

如果 Ollama 已在运行，请退出托盘应用程序并从 Start 菜单重新启动它，或者在保存环境变量后启动新终端。

### API Access

下面是一个快速示例，显示了从 `powershell` 进行 API 访问

```bash
(Invoke-WebRequest -method POST -Body '{"model":"llama3.2", "prompt":"Why is the sky blue?", "stream": false}' -uri http://localhost:11434/api/generate ).Content | ConvertFrom-json 
```

### 故障排除

Windows 上的 Ollama 将文件存储在几个不同的位置。可以通过点击 `<Ctrl>+R` 并在资源管理器窗口中输入以下内容来查看它们：

- 
   `explorer %LOCALAPPDATA%\Ollama` 包含日志和下载的更新
  - *app.log* contains most resent logs from the GUI application
    *app.log* 包含来自 GUI 应用程序的大多数重新发送的日志
  - *server.log* 包含最新的服务器日志
  - *upgrade.log* 包含升级的日志输出
- `explorer %LOCALAPPDATA%\Programs\Ollama` 包含二进制文件（安装程序将此添加到您的用户 PATH）
- `explorer %HOMEPATH%\.ollama` 包含模型和配置
- `explorer %TEMP%` 在一个或多个 `ollama*` 目录中包含临时可执行文件

### 卸载

The Ollama Windows installer registers an Uninstaller application.  Under `Add or remove programs` in Windows Settings, you can uninstall Ollama.

Ollama Windows 安装程序注册一个卸载程序应用程序。在 Windows 设置中的 `添加或删除程序`下，可以卸载 Ollama。

> 注意：
>
> 如果更改了 OLLAMA_MODELS 位置，安装程序将不会删除您下载的模型

### 独立 CLI


在 Windows 上安装 Ollama 的最简单方法是使用 `OllamaSetup.exe` 安装。它安装在您的帐户中，不需要管理员权限。 我们会定期更新 Ollama 以支持最新模型，此安装程序将 帮助您了解最新情况。

如果您想将 Ollama 安装或集成为一项服务，可以使用独立的 `ollama-windows-amd64.zip` zip 文件仅包含 Ollama CLI 以及 Nvidia 和 AMD 的 GPU 库依赖项。这允许将 Ollama 嵌入到现有应用程序中，或者使用 [NSSM](https://nssm.cc/) 等工具通过 `ollama serve` 将其作为系统服务运行。

> 注意：
>
> 如果要从以前的版本升级，则应先删除旧目录。