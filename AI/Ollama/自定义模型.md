## Customize a model 自定义模型



### Import from GGUF 从 GGUF 导入



Ollama supports importing GGUF models in the Modelfile:
Ollama 支持在 Modelfile 中导入 GGUF 模型：

1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.
   创建一个名为 `Modelfile` 的文件，其中包含 `FROM` 指令，其中包含要导入的模型的本地文件路径。

   ```
   FROM ./vicuna-33b.Q4_0.gguf
   ```

   ​    

Create the model in Ollama
在 Ollama 中创建模型

```
ollama create example -f Modelfile
```

​    

Run the model 运行模型

```
ollama run example
```

​    

### Import from Safetensors 从 Safetensor 导入



See the [guide](https://github.com/ollama/ollama/blob/main/docs/import.md) on importing models for more information.
请参阅 导入模型 以了解更多信息。

### Customize a prompt 自定义提示



Models from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:
Ollama 库中的模型可以通过提示进行自定义。例如，要自定义 `llama3.2` 模型：

```
ollama pull llama3.2
```

​    

Create a `Modelfile`:
创建一个 `Modelfile`：

```
FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM """
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
"""
```

​    

Next, create and run the model:
接下来，创建并运行模型：

```
ollama create mario -f ./Modelfile
ollama run mario
>>> hi
Hello! It's your friend Mario.
```

​    

For more information on working with a Modelfile, see the [Modelfile](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) documentation.
有关使用 Modelfile 的更多信息，请参阅 [Modelfile](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) 文档。