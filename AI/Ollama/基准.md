# Benchmark 基准



Go benchmark tests that measure end-to-end performance of a running Ollama server. Run these tests to evaluate model inference performance on your hardware and measure the impact of code changes.
Go 基准测试，用于测量正在运行的 Ollama 服务器的端到端性能。运行这些测试以评估模型推理对硬件的性能，并衡量代码更改的影响。

## When to use 适用情形



Run these benchmarks when:
在以下情况下运行这些基准测试：

- Making changes to the model inference engine
  对模型推理引擎进行更改
- Modifying model loading/unloading logic
  修改模型加载/卸载逻辑
- Changing prompt processing or token generation code
  更改提示处理或令牌生成代码
- Implementing a new model architecture
  实施新的模型架构
- Testing performance across different hardware setups
  在不同硬件设置下测试性能

## Prerequisites 先决条件



- Ollama server running locally with `ollama serve` on `127.0.0.1:11434`
  Ollama 服务器在本地运行，`ollama 服务`位于 `127.0.0.1：11434`

## Usage and Examples 用法和示例





Note 注意

All commands must be run from the root directory of the Ollama project.
所有命令都必须从 Ollama 项目的根目录运行。

Basic syntax: 基本语法：

```
go test -bench=. ./benchmark/... -m $MODEL_NAME
```

​    

Required flags: 必需的标志：

- `-bench=.`: Run all benchmarks
  `-bench=.`：运行所有基准测试
- `-m`: Model name to benchmark
  `-m`：要进行基准测试的模型名称

Optional flags: 可选标志：

- `-count N`: Number of times to run the benchmark (useful for statistical analysis)
  `-count N`：运行基准测试的次数（对统计分析有用）
- `-timeout T`: Maximum time for the benchmark to run (e.g. "10m" for 10 minutes)
  `-timeout T`：基准测试运行的最长时间（例如，“10m”持续 10 分钟）

Common usage patterns: 常见使用模式：

Single benchmark run with a model specified:
指定了模型的单个基准测试运行：

```
go test -bench=. ./benchmark/... -m llama3.3
```

​    

## Output metrics 输出指标



The benchmark reports several key metrics:
基准测试报告了几个关键指标：

- `gen_tok/s`: Generated tokens per second
  `gen_tok/s`：每秒生成的令牌数
- `prompt_tok/s`: Prompt processing tokens per second
  `prompt_tok/s`：每秒提示处理 Token 数
- `ttft_ms`: Time to first token in milliseconds
  `ttft_ms`：获得第一个令牌的时间（以毫秒为单位）
- `load_ms`: Model load time in milliseconds
  `load_ms`：模型加载时间（以毫秒为单位）
- `gen_tokens`: Total tokens generated
  `gen_tokens`：生成的令牌总数
- `prompt_tokens`: Total prompt tokens processed
  `prompt_tokens`：已处理的提示令牌总数

Each benchmark runs two scenarios:
每个基准测试运行两个场景：

- Cold start: Model is loaded from disk for each test
  冷启动：每次测试都从磁盘加载模型
- Warm start: Model is pre-loaded in memory
  热启动：模型预加载到内存中

Three prompt lengths are tested for each scenario:
针对每个场景测试三种提示长度：

- Short prompt (100 tokens)
  简短提示 （100 个令牌）
- Medium prompt (500 tokens)
  中等提示（500 个令牌）
- Long prompt (1000 tokens)
  长提示（1000 个 Token）