# 查询

- [Examples ](https://prometheus.io/docs/prometheus/latest/querying/basics/#examples)
- [Expression language data types ](https://prometheus.io/docs/prometheus/latest/querying/basics/#expression-language-data-types)
- [Literals ](https://prometheus.io/docs/prometheus/latest/querying/basics/#literals)
  - [String literals ](https://prometheus.io/docs/prometheus/latest/querying/basics/#string-literals)
  - [Float literals ](https://prometheus.io/docs/prometheus/latest/querying/basics/#float-literals)
- [Time series Selectors ](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-series-selectors)
  - [Instant vector selectors ](https://prometheus.io/docs/prometheus/latest/querying/basics/#instant-vector-selectors)
  - [Range Vector Selectors ](https://prometheus.io/docs/prometheus/latest/querying/basics/#range-vector-selectors)
  - [Time Durations ](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-durations)
  - [Offset modifier ](https://prometheus.io/docs/prometheus/latest/querying/basics/#offset-modifier)
  - [@ modifier ](https://prometheus.io/docs/prometheus/latest/querying/basics/#modifier)
- [Subquery ](https://prometheus.io/docs/prometheus/latest/querying/basics/#subquery)
- [Operators ](https://prometheus.io/docs/prometheus/latest/querying/basics/#operators)
- [Functions ](https://prometheus.io/docs/prometheus/latest/querying/basics/#functions)
- [Comments ](https://prometheus.io/docs/prometheus/latest/querying/basics/#comments)
- [Gotchas ](https://prometheus.io/docs/prometheus/latest/querying/basics/#gotchas)
  - [Staleness ](https://prometheus.io/docs/prometheus/latest/querying/basics/#staleness)
  - [Avoiding slow queries and overloads ](https://prometheus.io/docs/prometheus/latest/querying/basics/#avoiding-slow-queries-and-overloads)

## 概述

Prometheus 提供了一种称为 PromQL（Prometheus 查询语言）的功能性查询语言，允许用户实时选择和聚合时间序列数据。

When you send a query request to Prometheus, it can be an *instant query*, evaluated at one point in time, or a *range query* at equally-spaced steps between a start and an end time. the range query is just like an instant query run multiple times at different timestamps.

当向 Prometheus 发送查询请求时，它可以是在某个时间点评估的*即时查询*，也可以是在开始和结束时间之间间隔相等的步骤的范围*查询*。PromQL 在每种情况下的工作方式都完全相同；Range 查询就像在不同时间戳运行多次的即时查询一样。

在 Prometheus UI 中，“Table” 选项卡用于即时查询，“Graph” 选项卡用于范围查询。

其他程序可以通过 [HTTP API](https://prometheus.io/docs/prometheus/latest/querying/api/) 获取 PromQL 表达式的结果。

## 表达式语言数据类型

an expression or sub-expression can evaluate to one of four types:在 Prometheus 的表达式语言中，表达式或子表达式的计算结果可以是以下四种类型之一：

- **Instant vector** - a set of time series containing a single sample for each time series, all sharing the same timestamp一组时间序列，其中包含每个时间序列的单个样本，所有时间序列都共享相同的时间戳
- **Range vector** - a set of time series containing a range of data points over time for each time series一组时间序列，其中包含每个时间序列随时间变化的数据点范围
- **Scalar** - a simple numeric floating point value一个简单的数字浮点值
- **String** - 一个简单的字符串值；目前未使用

Depending on the use-case (e.g. when graphing vs. displaying the output of an expression), only some of these types are legal as the result from a user-specified expression. For example, an expression that returns an instant vector is the only type that can be directly graphed.

根据用例（例如，在绘制图形与显示表达式的输出时），只有其中一些类型作为用户指定的表达式是合法的。例如，返回即时向量的表达式是唯一可以绘制图形的类型。

*Notes about the experimental native histograms:*有关实验性原生直方图的说明：**

- Ingesting native histograms has to be enabled via a [feature flag](https://prometheus.io/docs/prometheus/latest/querying/feature_flags/#native-histograms).必须通过[功能标志](https://prometheus.io/docs/prometheus/latest/feature_flags/#native-histograms)启用提取原生直方图。
- Once native histograms have been ingested into the TSDB (and even after disabling the feature flag again), both instant vectors and range vectors may now contain samples that aren't simple floating point numbers (float samples) but complete histograms (histogram samples). A vector may contain a mix of float samples and histogram samples.
- 一旦原生直方图被摄取到 TSDB 中（甚至在再次禁用特征标志之后），即时向量和范围向量现在都可以包含不是简单浮点数（浮点样本）而是完整直方图（直方图样本）的样本。向量可以包含浮点样本和直方图样本的混合。

## Literals 文字

### String literals字符串

Strings may be specified as literals in single quotes, double quotes or backticks.字符串文字由单引号、双引号或反引号指定。

PromQL follows the same [escaping rules as Go](https://golang.org/ref/spec#String_literals). In single or double quotes a backslash begins an escape sequence, which may be followed by `a`, `b`, `f`, `n`, `r`, `t`, `v` or `\`. Specific characters can be provided using octal (`\nnn`) or hexadecimal (`\xnn`, `\unnnn` and `\Unnnnnnnn`).

PromQL 遵循[与 Go 相同的转义规则](https://golang.org/ref/spec#String_literals)。对于单引号或双引号中的字符串文字，反斜杠以转义序列开头，后跟 `a`、`b`、`f`、`n`、`r`、`t`、`v` 或 `\`。可以使用八进制 （`\nnn`） 或十六进制 （`\xnn``、\unnnn` 和 `\Unnnnnnnn）` 表示法提供特定字符。

Conversely, escape characters are not parsed in string literals  designated by backticks. It is important to note that, unlike Go,  Prometheus does not discard newlines inside backticks.

相反，转义字符不会在反引号指定的字符串文本中解析。需要注意的是，与 Go 不同，Prometheus 不会丢弃反引号内的换行符。

示例：

```go
"this is a string"
'these are unescaped: \n \\ \t'
`these are not unescaped: \n ' " \t`
```

### Float literals浮点文本

Scalar float values can be written as literal integer or  floating-point numbers in the format (whitespace only included for  better readability):标量浮点值可以按以下格式写入 Literals integer 或 floating-point 数字（为了提高可读性，仅包含空格）：

```go
[-+]?(
      [0-9]*\.?[0-9]+([eE][-+]?[0-9]+)?
    | 0[xX][0-9a-fA-F]+
    | [nN][aA][nN]
    | [iI][nN][fF]
)
```

示例：

```bash
23
-2.43
3.4e-9
0x8f
-Inf
NaN
```

As of version 2.54, float literals can also be represented using the  syntax of time durations, where the time duration is converted into a  float value corresponding to the number of seconds the time duration  represents. This is an experimental feature and might still change.

从版本 2.54 开始，浮点文本也可以使用持续时间语法表示，其中持续时间转换为与持续时间表示的秒数相对应的浮点值。这是一项实验性功能，可能仍会发生变化。

## Time series Selectors时间序列选择器

These are the basic building-blocks that instruct PromQL what data to fetch.
这些是指示 PromQL 要获取哪些数据的基本构建块。

### Instant vector selectors即时矢量选择器

Instant vector selectors allow the selection of a set of time series and a single sample value for each at a given timestamp (instant): in the simplest form, only a metric name is specified. This results in an instant vector containing elements for all time series that have this metric name.即时向量选择器允许在给定时间戳（时间点）选择一组时间序列和每个时间序列的单个样本值。在最简单的形式中，仅指定一个度量名称，这将生成一个即时向量，其中包含具有此度量名称的所有时间序列的元素。

This example selects all time series that have the `http_requests_total` metric name:此示例选择具有 `http_requests_total` 指标名称的所有时间序列：

```go
http_requests_total
```

It is possible to filter these time series further by appending a comma separated list of label matchers in curly braces (`{}`).可以通过在大括号 （`{}`） 中附加以逗号分隔的标签匹配器列表来进一步筛选这些时间序列。

This example selects only those time series with the `http_requests_total` metric name that also have the `job` label set to `prometheus` and their `group` label set to `canary`:此示例仅选择那些具有 `http_requests_total` 指标名称的时间序列，这些时间序列的`作业标签也`设置为 `prometheus`，并且它们的`组`标签设置为 `Canary`：

```go
http_requests_total{job="prometheus",group="canary"}
```

It is also possible to negatively match a label value, or to match label values against regular expressions. The following label matching operators exist:还可以对标签值进行负匹配，或者将标签值与正则表达式进行匹配。存在以下标签匹配运算符：

- `=`: Select labels that are exactly equal to the provided string.选择与提供的字符串完全相等的标签。
- `!=`: Select labels that are not equal to the provided string.选择不等于提供的字符串的标签。
- `=~`: Select labels that regex-match the provided string.选择正则表达式与提供的字符串匹配的标签。
- `!~`: Select labels that do not regex-match the provided string.选择与提供的字符串不进行正则表达式匹配的标签。

Regex matches are fully anchored. A match of `env=~"foo"` is treated as `env=~"^foo$"`.正则表达式匹配是完全锚定的。`en=~“foo”` 的匹配项被视为 `env=~“^foo$”。`

For example, this selects all `http_requests_total` time series for `staging`, `testing`, and `development` environments and HTTP methods other than `GET`.

例如，这将为`暂存`、`测试和``开发`环境选择所有 `http_requests_total` 时间序列以及除 `GET` 以外的 HTTP 方法。

```
http_requests_total{environment=~"staging|testing|development",method!="GET"}
```

Label matchers that match empty label values also select all time series that do not have the specific label set at all. It is possible to have multiple matchers for the same label name.与空标签值匹配的标签匹配器还会选择根本没有设置特定标签的所有时间序列。同一标签名称可以有多个匹配器。

For example, given the dataset:
例如，给定数据集：

```
http_requests_total
http_requests_total{replica="rep-a"}
http_requests_total{replica="rep-b"}
http_requests_total{environment="development"}
```

The query `http_requests_total{environment=""}` would match and return:
查询 `http_requests_total{environment=""}` 将匹配并返回：

```
http_requests_total
http_requests_total{replica="rep-a"}
http_requests_total{replica="rep-b"}
```

and would exclude: 并且将排除：

```
http_requests_total{environment="development"}
```

Multiple matchers can be used for the same label name; they all must pass for a result to be returned. 
多个匹配器可用于同一标签名称;它们都必须通过才能返回结果。

The query: 查询：

```
http_requests_total{replica!="rep-a",replica=~"rep.*"}
```

Would then match: 然后匹配：

```
http_requests_total{replica="rep-b"}
```

Vector selectors must either specify a name or at least one label matcher that does not match the empty string. The following expression is illegal:
矢量选择器必须指定一个名称或至少一个与空字符串不匹配的标签匹配器。以下表达式是非法的：

```
{job=~".*"} # Bad!
```

In contrast, these expressions are valid as they both have a selector that does not match empty label values.
相反，这些表达式是有效的，因为它们都有一个与空标签值不匹配的选择器。

```
{job=~".+"}              # Good!
{job=~".*",method="get"} # Good!
```

Label matchers can also be applied to metric names by matching against the internal `__name__` label. For example, the expression `http_requests_total` is equivalent to `{__name__="http_requests_total"}`. Matchers other than `=` (`!=`, `=~`, `!~`) may also be used. The following expression selects all metrics that have a name starting with `job:`:
标签匹配器还可以通过与内部 `__name__` 标签进行匹配来应用于指标名称。例如，表达式 `http_requests_total` 等效于 `{__name__="http_requests_total"}` .也可以使用 `=` （`！=`， `=~`， `！~`） 以外的匹配器。以下表达式选择名称以 `job：`：

```
{__name__=~"job:.*"}
```

The metric name must not be one of the keywords `bool`, `on`, `ignoring`, `group_left` and `group_right`. The following expression is illegal:
指标名称不能是关键字 `bool`、`on`、`ignoring`、`group_left` 和 `group_right` 之一。以下表达式是非法的：

```
on{} # Bad!
```

A workaround for this restriction is to use the `__name__` label:
此限制的解决方法是使用 `__name__` 标签：

```
{__name__="on"} # Good!
```

Prometheus 中的所有正则表达式都使用 [RE2 语法](https://github.com/google/re2/wiki/Syntax)。

### Range Vector Selectors范围矢量选择器

Range vector literals work like instant vector literals, except that they select a range of samples back from the current instant. Syntactically, a [time duration](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-durations) is appended in square brackets (`[]`) at the end of a vector selector to specify how far back in time values should be fetched for each resulting range vector element. The range is a closed interval, i.e. samples with timestamps coinciding with either boundary of the range are still included in the selection.

Range 向量文字的工作方式与即时向量文字类似，不同之处在于它们从当前时刻选择一系列样本。从语法上讲，[持续时间](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-durations)附加在向量选择器末尾的方括号 （`[]`） 中，以指定应为每个生成的范围向量元素获取多长时间以前的时间值。该范围是一个封闭的间隔，即时间戳与范围的任一边界重合的样本仍包含在选择中。

In this example, we select all the values we have recorded within the last 5 minutes for all time series that have the metric name `http_requests_total` and a `job` label set to `prometheus`:在此示例中，我们为指标名称为 `http_requests_total`且`作业`标签设置为 `prometheus` 的所有时间序列选择过去 5 分钟内记录的所有值：

```yaml
http_requests_total{job="prometheus"}[5m]
```

### Time Durations 持续时间

Time durations are specified as a number, followed immediately by one of the following units:持续时间以数字形式指定，后跟以下单位之一：

- `ms` - 毫秒
- `s` - 秒
- `m` - 分钟
- `h` - 小时
- `d` - 天 - assuming a day has always 24h假设一天总是有 24h
- `w` - 星期 - assuming a week has always 7d假设一周总是有 7d
- `y` - 年 - assuming a year has always 365d假设一年始终为 365d（For days in a year, the leap day is ignored, and conversely, for a minute, a leap second is ignored. 对于一年中的几天，闰日被忽略，相反，在一分钟内，闰秒被忽略。）

Time durations can be combined, by concatenation. Units must be ordered from the longest to the shortest. A given unit must only appear once in a time duration.持续时间可以通过串联来组合。单位必须按从最长到最短的顺序排序。给定单元在持续时间内只能出现一次。

Here are some examples of valid time durations:以下是有效持续时间的一些示例：

```yaml
5h
1h30m
5m
10s
```

time durations can also be represented using the  syntax of float literals, implying the number of seconds of the time  duration. This is an experimental feature and might still change.
从版本 2.54 开始，持续时间也可以使用 float literals 的语法表示，这意味着持续时间的秒数。这是一项实验性功能，可能仍会发生变化。

示例：

```yaml
1.0 	# Equivalent to 1s
0.001 	# Equivalent to 1ms
120		# Equivalent to 2m
```

### Offset modifier偏移编辑

The `offset` modifier allows changing the time offset for individual instant and range vectors in a query.`offset` 修饰符允许更改查询中各个 instant 和 range 向量的时间偏移量。

For example, the following expression returns the value of `http_requests_total` 5 minutes in the past relative to the current query evaluation time:例如，以下表达式返回相对于当前查询评估时间过去 `http_requests_total` 5 分钟的值：

```
http_requests_total offset 5m
```

Note that the `offset` modifier always needs to follow the selector immediately, i.e. the following would be correct:请注意，`offset` 修饰符始终需要立即跟随选择器，即以下内容是正确的：

```
sum(http_requests_total{method="GET"} offset 5m) // GOOD.
```

While the following would be *incorrect*:虽然*以下内容不正确：*

```
sum(http_requests_total{method="GET"}) offset 5m // INVALID.
```

The same works for range vectors. This returns the 5-minute rate that `http_requests_total` had a week ago:这同样适用于范围向量。这将返回 `http_requests_total` 一周前的 5 分钟[速率](https://prometheus.io/docs/prometheus/latest/querying/functions/#rate)：

```
rate(http_requests_total[5m] offset 1w)
```

For comparisons with temporal shifts forward in time, a negative offset can be specified:查询过去的样本时，负偏移量将启用时间向前的时间比较：

```
rate(http_requests_total[5m] offset -1w)
```

Note that this allows a query to look ahead of its evaluation time.请注意，这允许查询提前查看其评估时间。

### @ modifier@ 修饰符

The `@` modifier allows changing the evaluation time for individual instant and range vectors in a query. The time supplied to the `@` modifier is a unix timestamp and described with a float literal. `@` 修饰符允许更改查询中单个 instant 和 range 向量的求值时间。提供给 `@` 修饰符的时间是 unix 时间戳，并使用 float 文字进行描述。

For example, the following expression returns the value of `http_requests_total` at `2021-01-04T07:40:00+00:00`:例如，以下表达式在 `2021-01-04T07：40：00+00：00` 处返回 `http_requests_total` 的值：

```
http_requests_total @ 1609746000
```

Note that the `@` modifier always needs to follow the selector immediately, i.e. the following would be correct:

请注意，`@` 修饰符始终需要立即跟随选择器，即以下内容是正确的：

```
sum(http_requests_total{method="GET"} @ 1609746000) // GOOD.
```

While the following would be *incorrect*:虽然*以下内容不正确：*

```
sum(http_requests_total{method="GET"}) @ 1609746000 // INVALID.
```

The same works for range vectors. This returns the 5-minute rate that `http_requests_total` had at `2021-01-04T07:40:00+00:00`:这同样适用于范围向量。这将返回`http_requests_total`在 `2021-01-04T07：40：00+00：00` 的 5 分钟速率：

```
rate(http_requests_total[5m] @ 1609746000)
```

The `@` modifier supports all representation of float literals described above within the limits of `int64`. It can also be used along with the `offset` modifier where the offset is applied relative to the `@` modifier time irrespective of which modifier is written first. These 2 queries will produce the same result.

`@` 修饰符支持上述数字文本的所有表示形式。它与 `offset` 修饰符一起使用，其中偏移是相对于 `@` 修饰符时间应用的。无论修饰符的顺序如何，结果都是相同的。

```
# offset after @
http_requests_total @ 1609746000 offset 5m
# offset before @
http_requests_total offset 5m @ 1609746000
```

For example, these two queries will produce the same result:
例如，这两个查询将产生相同的结果：

```
# offset after @
http_requests_total @ 1609746000 offset 5m
# offset before @
http_requests_total offset 5m @ 1609746000
```

Additionally, `start()` and `end()` can also be used as values for the `@` modifier as special values.
此外，`start（）` 和 `end（）` 也可以用作 `@` 修饰符的值作为特殊值。

For a range query, they resolve to the start and end of the range query respectively and remain the same for all steps.
对于范围查询，它们分别解析到范围查询的开头和结尾，并且所有步骤都保持不变。

For an instant query, `start()` and `end()` both resolve to the evaluation time.
对于即时查询，`start（）` 和 `end（）` 都解析为评估时间。

```
http_requests_total @ start()
rate(http_requests_total[5m] @ end())
```

Note that the `@` modifier allows a query to look ahead of its evaluation time.
请注意，`@` 修饰符允许查询提前查看其评估时间。

## Subquery子查询

Subquery allows you to run an instant query for a given range and resolution. The result of a subquery is a range vector.Subquery 允许您对给定的范围和分辨率运行即时查询。子查询的结果是范围向量。

Syntax: `<instant_query> '[' <range> ':' [<resolution>] ']' [ @ <float_literal> ] [ offset <duration> ]` 语法： `<instant_query> '[' <range> ':' [<resolution>] ']' [ @ <float_literal> ] [ offset <duration> ]` 

- `<resolution>` is optional. Default is the global evaluation interval.
  `<resolution>` 是可选的。默认值为全局评估间隔。

## Operators运营商

Prometheus supports many binary and aggregation operators. These are described in detail in the [expression language operators](https://prometheus.io/docs/prometheus/latest/querying/operators/) page.Prometheus 支持许多二进制和聚合运算符。[表达式语言运算符](https://prometheus.io/docs/prometheus/latest/querying/operators/)页面中详细介绍了这些内容。

## Functions 功能

Prometheus supports several functions to operate on data. These are described in detail in the [expression language functions](https://prometheus.io/docs/prometheus/latest/querying/functions/) page.Prometheus 支持多种函数来操作数据。[表达式语言函数](https://prometheus.io/docs/prometheus/latest/querying/functions/)页面中详细介绍了这些内容。

## Comments评论

PromQL supports line comments that start with `#`. Example:PromQL 支持以 `#` 开头的行注释。例：

```go
# This is a comment
```

## Gotchas陷阱

### Staleness过时

The timestamps at which to sample data, during a query, are selected independently of the actual present time series data. This is mainly to support cases like aggregation (`sum`, `avg`, and so on), where multiple aggregated time series do not precisely align in time. Because of their independence, Prometheus needs to assign a value at those timestamps for each relevant time series. It does so by taking the newest sample before this timestamp within the lookback period. The lookback period is 5 minutes by default.
在查询期间，用于对数据进行采样的时间戳是独立于实际当前时间序列数据的选择。这主要是为了支持聚合 （`sum`、`avg` 等） 等情况，其中多个聚合时间序列在时间上不精确对齐。由于它们的独立性，Prometheus 需要在每个相关时间序列的时间戳处分配一个值。它通过在回溯期内获取此时间戳之前的最新样本来实现此目的。默认情况下，回溯期为 5 分钟。

If a target scrape or rule evaluation no longer returns a sample for a time series that was previously present, this time series will be marked as stale. If a target is removed, the previously retrieved time series will be marked as stale soon after removal.
如果 target 抓取或规则评估不再返回以前存在的时间序列的样本，则此时间序列将被标记为过时。如果删除了目标，则之前检索的时间序列将在删除后不久标记为过时。

If a query is evaluated at a sampling timestamp after a time series is marked as stale, then no value is returned for that time series. If new samples are subsequently ingested for that time series, they will be returned as expected.
如果在将时间序列标记为过时后在采样时间戳处评估查询，则不会为该时间序列返回任何值。如果随后为该时间序列提取了新样本，则这些样本将按预期返回。

A time series will go stale when it is no longer exported, or the target no longer exists. Such time series will disappear from graphs  at the times of their latest collected sample, and they will not be returned in queries after they are marked stale.
当时间序列不再导出或目标不再存在时，时间序列将过时。此类时间序列将在最近收集样本时从图表中消失，并且在标记为过时后不会在查询中返回。

Some exporters, which put their own timestamps on samples, get a different behaviour:  series that stop being exported take the last value for (by default) 5 minutes before disappearing. The `track_timestamps_staleness` setting can change this.
一些导出器在样本上放置自己的时间戳，会得到不同的行为：停止导出的序列在消失前（默认情况下）采用最后一个值 5 分钟。`track_timestamps_staleness` 设置可以更改此设置。

### Avoiding slow queries and overloads避免慢查询和重载

If a query needs to operate on a substantial amount of data, graphing it might time out or overload the server or browser. Thus, when constructing queries over unknown data, always start building the query in the tabular view of Prometheus's expression browser until the result set seems reasonable (hundreds, not thousands, of time series at most).  Only when you have filtered or aggregated your data sufficiently, switch to graph mode. If the expression still takes too long to graph ad-hoc, pre-record it via a [recording rule](https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/#recording-rules).
如果查询需要对大量数据进行操作，则绘制查询图表可能会超时或使服务器或浏览器过载。因此，在对未知数据构建查询时，请始终在 Prometheus  表达式浏览器的表格视图中开始构建查询，直到结果集看起来合理（最多数百次，而不是数千次时间序列）。只有在充分筛选或聚合数据后，才能切换到图形模式。如果表达式仍然需要很长时间来临时绘制图形，请通过[记录规则](https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/#recording-rules)预先录制它。

This is especially relevant for Prometheus's query language, where a bare metric name selector like `api_http_requests_total` could expand to thousands of time series with different labels. Also, keep in mind that expressions that aggregate over many time series will generate load on the server even if the output is only a small number of time series. This is similar to how it would be slow to sum all values of a column in a relational database, even if the output value is only a single number.
这与 Prometheus 的查询语言尤其相关，其中像 `api_http_requests_total` 这样的裸指标名称选择器可以扩展到数千个具有不同标签的时间序列。此外，请记住，即使输出只是少量时间序列，聚合多个时间序列的表达式也会在服务器上产生负载。这类似于在关系数据库中对列的所有值求和会很慢，即使输出值只是一个数字也是如此。

## Operators

- [Binary operators ](https://prometheus.io/docs/prometheus/latest/querying/operators/#binary-operators)
  - [Arithmetic binary operators ](https://prometheus.io/docs/prometheus/latest/querying/operators/#arithmetic-binary-operators)
  - [Trigonometric binary operators ](https://prometheus.io/docs/prometheus/latest/querying/operators/#trigonometric-binary-operators)
  - [Comparison binary operators ](https://prometheus.io/docs/prometheus/latest/querying/operators/#comparison-binary-operators)
  - [Logical/set binary operators ](https://prometheus.io/docs/prometheus/latest/querying/operators/#logical-set-binary-operators)
- [Vector matching ](https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching)
  - [Vector matching keywords ](https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching-keywords)
  - [Group modifiers ](https://prometheus.io/docs/prometheus/latest/querying/operators/#group-modifiers)
  - [One-to-one vector matches ](https://prometheus.io/docs/prometheus/latest/querying/operators/#one-to-one-vector-matches)
  - [Many-to-one and one-to-many vector matches ](https://prometheus.io/docs/prometheus/latest/querying/operators/#many-to-one-and-one-to-many-vector-matches)
- [Aggregation operators ](https://prometheus.io/docs/prometheus/latest/querying/operators/#aggregation-operators)
- [Binary operator precedence ](https://prometheus.io/docs/prometheus/latest/querying/operators/#binary-operator-precedence)
- [Operators for native histograms ](https://prometheus.io/docs/prometheus/latest/querying/operators/#operators-for-native-histograms)

### Binary operators二元运算符

Prometheus's query language supports basic logical and arithmetic operators. For operations between two instant vectors, the [matching behavior](https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching) can be modified.Prometheus 的查询语言支持基本的逻辑和算术运算符。对于两个即时向量之间的操作，可以修改[匹配行为](https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching)。

#### Arithmetic binary operators算术二元运算符

The following binary arithmetic operators exist in Prometheus:Prometheus 中存在以下二进制算术运算符：

- `+` (addition)
- `-` (subtraction)
- `*` (multiplication)
- `/` (division)
- `%` (modulo)
- `^` (power/exponentiation)

Binary arithmetic operators are defined between scalar/scalar, vector/scalar, and vector/vector value pairs.二进制算术运算符在标量/标量、向量/标量和向量/向量值对之间定义。

**Between two scalars**, the behavior is obvious: they evaluate to another scalar that is the result of the operator applied to both scalar operands.**在两个标量之间**，行为是显而易见的：它们计算为另一个标量，该标量是应用于两个标量操作数的运算符的结果。

**Between an instant vector and a scalar**, the operator is applied to the value of every data sample in the vector. E.g. if a time series instant vector is multiplied by 2, the result is another vector in which every sample value of the original vector is multiplied by 2. The metric name is dropped.**在即时向量和标量之间**，运算符应用于向量中每个数据样本的值。例如，如果时间序列即时向量乘以 2，则结果是另一个向量，其中原始向量的每个样本值都乘以 2。指标名称已删除。

**Between two instant vectors**, a binary arithmetic operator is applied to each entry in the left-hand side vector and its [matching element](https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching) in the right-hand vector. The result is propagated into the result vector with the grouping labels becoming the output label set. The metric name is dropped. Entries for which no matching entry in the right-hand vector can be found are not part of the result.

**在两个即时向量之间**，二进制算术运算符将应用于左侧向量中的每个条目及其右侧向量中的[匹配元素](https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching)。结果将传播到结果向量中，分组标签成为输出标签集。指标名称已删除。在右侧向量中找不到匹配条目的条目不是结果的一部分。

#### Trigonometric binary operators三角二元运算符

The following trigonometric binary operators, which work in radians, exist in Prometheus:Prometheus 中存在以下以弧度为单位的三角二元运算符：

- `atan2` (based on https://pkg.go.dev/math#Atan2)

Trigonometric operators allow trigonometric functions to be executed on two vectors using vector matching, which isn't available with normal functions. They act in the same manner as arithmetic operators.三角运算符允许使用向量匹配在两个向量上执行三角函数，这在普通函数中不可用。它们的作用方式与算术运算符相同。

#### Comparison binary operators比较二元运算符

The following binary comparison operators exist in Prometheus:Prometheus 中存在以下二进制比较运算符：

- `==` (equal)
- `!=` (not-equal)
- `>` (greater-than)
- `<` (less-than)
- `>=` (greater-or-equal)
- `<=` (less-or-equal)

Comparison operators are defined between scalar/scalar, vector/scalar, and vector/vector value pairs. By default they filter. Their behavior can be modified by providing `bool` after the operator, which will return `0` or `1` for the value rather than filtering.比较运算符在标量/标量、向量/标量和向量/向量值对之间定义。默认情况下，它们会进行筛选。可以通过在运算符后提供 `bool` 来修改它们的行为，这将为值返回 `0` 或 `1`，而不是筛选。

**Between two scalars**, the `bool` modifier must be provided and these operators result in another scalar that is either `0` (`false`) or `1` (`true`), depending on the comparison result.
**在两个标量之间**，必须提供 `bool` 修饰符，这些运算符会生成另一个标量，该标量为 `0` （`false`） 或 `1` （`true`），具体取决于比较结果。

**Between an instant vector and a scalar**, these operators are applied to the value of every data sample in the vector, and vector elements between which the comparison result is `false` get dropped from the result vector. If the `bool` modifier is provided, vector elements that would be dropped instead have the value `0` and vector elements that would be kept have the value `1`. The metric name is dropped if the `bool` modifier is provided.
**在即时向量和标量之间**，这些运算符应用于向量中每个数据样本的值，比较结果为 `false` 的向量元素将从结果向量中删除。如果提供了 `bool` 修饰符，则将删除的向量元素的值为 `0`，而将保留的向量元素的值为 `1`。如果提供了 `bool` 修饰符，则会删除 metric name。

**Between two instant vectors**, these operators behave as a filter by default, applied to matching entries. Vector elements for which the expression is not true or which do not find a match on the other side of the expression get dropped from the result, while the others are propagated into a result vector with the grouping labels becoming the output label set. If the `bool` modifier is provided, vector elements that would have been dropped instead have the value `0` and vector elements that would be kept have the value `1`, with the grouping labels again becoming the output label set. The metric name is dropped if the `bool` modifier is provided.
**在两个即时向量之间**，这些运算符默认充当过滤器，应用于匹配的条目。表达式不为 true 或在表达式的另一侧找不到匹配项的向量元素将从结果中删除，而其他向量元素将传播到结果向量中，分组标签成为输出标签集。如果提供了 `bool` 修饰符，则本应删除的矢量元素的值为 `0`，而将保留的矢量元素的值为 `1`，分组标签将再次成为输出标签集。如果提供了 `bool` 修饰符，则会删除 metric name。

#### Logical/set binary operators逻辑/集合二元运算符

These logical/set binary operators are only defined between instant vectors:
这些 logical/set 二进制运算符仅在 instant vectors 之间定义：

- `and` (intersection)
  `和` （交集）
- `or` (union) `或` （联合）
- `unless` (complement)
  `unless` （补语）

`vector1 and vector2` results in a vector consisting of the elements of `vector1` for which there are elements in `vector2` with exactly matching label sets. Other elements are dropped. The metric name and values are carried over from the left-hand side vector.
`vector1 和 vector2` 生成一个向量，该向量由 `vector1` 的元素组成，而 `vector2` 中的元素具有完全匹配的标签集。其他元素将被丢弃。量度名称和值是从左侧向量继承而来的。

`vector1 or vector2` results in a vector that contains all original elements (label sets + values) of `vector1` and additionally all elements of `vector2` which do not have matching label sets in `vector1`.
`vector1 或 vector2` 生成的向量包含 `vector1` 的所有原始元素（标签集 + 值），此外还包含 `vector2` 的所有元素，这些元素在 `vector1` 中没有匹配的标签集。

`vector1 unless vector2` results in a vector consisting of the elements of `vector1` for which there are no elements in `vector2` with exactly matching label sets. All matching elements in both vectors are dropped.
`vector1 的 Git，除非 vector2` 导致一个向量由 `vector1` 的元素组成，而 `vector2` 中没有具有完全匹配标签集的元素。两个向量中的所有匹配元素都将被删除。

### Vector matching向量匹配

Operations between vectors attempt to find a matching element in the right-hand side vector for each entry in the left-hand side. There are two basic types of matching behavior: One-to-one and many-to-one/one-to-many.
向量之间的操作尝试在右侧向量中为左侧的每个条目查找匹配的元素。匹配行为有两种基本类型：一对一和多对一/一对多。

#### Vector matching keywords向量匹配关键字

These vector matching keywords allow for matching between series with different label sets providing:这些向量匹配关键字允许在具有不同标签集的序列之间进行匹配，从而提供：

- `on`
- `ignoring`

Label lists provided to matching keywords will determine how vectors are combined. Examples can be found in [One-to-one vector matches](https://prometheus.io/docs/prometheus/latest/querying/operators/#one-to-one-vector-matches) and in [Many-to-one and one-to-many vector matches](https://prometheus.io/docs/prometheus/latest/querying/operators/#many-to-one-and-one-to-many-vector-matches)
提供给匹配关键字的标签列表将决定向量的组合方式。示例可以在 [One-to-one vector matches](https://prometheus.io/docs/prometheus/latest/querying/operators/#one-to-one-vector-matches) 和 [Many-to-one 和 one-to-many vector matches](https://prometheus.io/docs/prometheus/latest/querying/operators/#many-to-one-and-one-to-many-vector-matches) 中找到

#### Group modifiers组修饰符

These group modifiers enable many-to-one/one-to-many vector matching:
这些组修饰符支持多对一/一对多向量匹配：

- `group_left`
- `group_right`

Label lists can be provided to the group modifier which contain labels from the "one"-side to be included in the result metrics.
标签列表可以提供给 group 修饰符，其中包含要包含在结果量度中的“one”端的标签。

*Many-to-one and one-to-many matching are advanced use cases that should be carefully considered. Often a proper use of `ignoring(<labels>)` provides the desired outcome.
多对一和一对多匹配是应仔细考虑的高级使用案例。通常，正确使用 `ignorenoing（<labels>）` 可提供所需的结果。*

*Grouping modifiers can only be used for [comparison](https://prometheus.io/docs/prometheus/latest/querying/operators/#comparison-binary-operators) and [arithmetic](https://prometheus.io/docs/prometheus/latest/querying/operators/#arithmetic-binary-operators). Operations as `and`, `unless` and `or` operations match with all possible entries in the right vector by default.
分组修饰符只能用于[比较](https://prometheus.io/docs/prometheus/latest/querying/operators/#comparison-binary-operators)和[算术](https://prometheus.io/docs/prometheus/latest/querying/operators/#arithmetic-binary-operators)。默认情况下，操作 as `and`、`unless` 和 `or` 操作与右侧向量中的所有可能条目匹配。*

#### One-to-one vector matches一对一向量匹配

**One-to-one** finds a unique pair of entries from each side of the operation. In the default case, that is an operation following the format `vector1 <operator> vector2`. Two entries match if they have the exact same set of labels and corresponding values. The `ignoring` keyword allows ignoring certain labels when matching, while the `on` keyword allows reducing the set of considered labels to a provided list:
**One-to-one** 从操作的每一端查找一对唯一的条目。默认情况下，这是遵循 `vector1 <operator> vector2` 格式的操作。如果两个条目具有完全相同的标签集和相应的值，则它们匹配。`ignore` 关键字允许在匹配时忽略某些标签，而 `on` 关键字允许将考虑的标签集减少到提供的列表中：

```
<vector expr> <bin-op> ignoring(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) <vector expr>
```

示例输入：

```
method_code:http_errors:rate5m{method="get", code="500"}  24
method_code:http_errors:rate5m{method="get", code="404"}  30
method_code:http_errors:rate5m{method="put", code="501"}  3
method_code:http_errors:rate5m{method="post", code="500"} 6
method_code:http_errors:rate5m{method="post", code="404"} 21

method:http_requests:rate5m{method="get"}  600
method:http_requests:rate5m{method="del"}  34
method:http_requests:rate5m{method="post"} 120
```

示例查询：

```
method_code:http_errors:rate5m{code="500"} / ignoring(code) method:http_requests:rate5m
```

This returns a result vector containing the fraction of HTTP requests with status code of 500 for each method, as measured over the last 5 minutes. Without `ignoring(code)` there would have been no match as the metrics do not share the same set of labels. The entries with methods `put` and `del` have no match and will not show up in the result:
这将返回一个结果向量，其中包含每个方法的状态代码为 500 的 HTTP 请求的分数，这是在过去 5 分钟内测量的。如果没有 `ignoreing（code），`就不会有匹配项，因为指标不共享同一组标签。带有方法 `put` 和 `del` 的条目没有匹配项，并且不会显示在结果中：

```
{method="get"}  0.04            //  24 / 600
{method="post"} 0.05            //   6 / 120
```

#### Many-to-one and one-to-many vector matches

**Many-to-one** and **one-to-many** matchings refer to the case where each vector element on the "one"-side can match with multiple elements on the "many"-side. This has to be explicitly requested using the `group_left` or `group_right` [modifiers](https://prometheus.io/docs/prometheus/latest/querying/operators/#group-modifiers), where left/right determines which vector has the higher cardinality.

```
<vector expr> <bin-op> ignoring(<label list>) group_left(<label list>) <vector expr>
<vector expr> <bin-op> ignoring(<label list>) group_right(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) group_left(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) group_right(<label list>) <vector expr>
```

The label list provided with the [group modifier](https://prometheus.io/docs/prometheus/latest/querying/operators/#group-modifiers) contains additional labels from the "one"-side to be included in the result metrics. For `on` a label can only appear in one of the lists. Every time series of the result vector must be uniquely identifiable.

Example query:

```
method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m
```

In this case the left vector contains more than one entry per `method` label value. Thus, we indicate this using `group_left`. The elements from the right side are now matched with multiple elements with the same `method` label on the left:

```
{method="get", code="500"}  0.04            //  24 / 600
{method="get", code="404"}  0.05            //  30 / 600
{method="post", code="500"} 0.05            //   6 / 120
{method="post", code="404"} 0.175           //  21 / 120
```

### Aggregation operators

Prometheus supports the following built-in aggregation operators that can be used to aggregate the elements of a single instant vector, resulting in a new vector of fewer elements with aggregated values:

- `sum` (calculate sum over dimensions)
- `min` (select minimum over dimensions)
- `max` (select maximum over dimensions)
- `avg` (calculate the average over dimensions)
- `group` (all values in the resulting vector are 1)
- `stddev` (calculate population standard deviation over dimensions)
- `stdvar` (calculate population standard variance over dimensions)
- `count` (count number of elements in the vector)
- `count_values` (count number of elements with the same value)
- `bottomk` (smallest k elements by sample value)
- `topk` (largest k elements by sample value)
- `quantile` (calculate φ-quantile (0 ≤ φ ≤ 1) over dimensions)

These operators can either be used to aggregate over **all** label dimensions or preserve distinct dimensions by including a `without` or `by` clause. These clauses may be used before or after the expression.

```
<aggr-op> [without|by (<label list>)] ([parameter,] <vector expression>)
```

or

```
<aggr-op>([parameter,] <vector expression>) [without|by (<label list>)]
```

`label list` is a list of unquoted labels that may include a trailing comma, i.e. both `(label1, label2)` and `(label1, label2,)` are valid syntax.

`without` removes the listed labels from the result vector, while all other labels are preserved in the output. `by` does the opposite and drops labels that are not listed in the `by` clause, even if their label values are identical between all elements of the vector.

`parameter` is only required for `count_values`, `quantile`, `topk` and `bottomk`.

`count_values` outputs one time series per unique sample value. Each series has an additional label. The name of that label is given by the aggregation parameter, and the label value is the unique sample value. The value of each time series is the number of times that sample value was present.

`topk` and `bottomk` are different from other aggregators in that a subset of the input samples, including the original labels, are returned in the result vector. `by` and `without` are only used to bucket the input vector.

`quantile` calculates the φ-quantile, the value that ranks at number φ*N among the N metric values of the dimensions aggregated over. φ is provided as the aggregation parameter. For example, `quantile(0.5, ...)` calculates the median, `quantile(0.95, ...)` the 95th percentile. For φ = `NaN`, `NaN` is returned. For φ < 0, `-Inf` is returned. For φ > 1, `+Inf` is returned.

Example:

If the metric `http_requests_total` had time series that fan out by `application`, `instance`, and `group` labels, we could calculate the total number of seen HTTP requests per application and group over all instances via:

```
sum without (instance) (http_requests_total)
```

Which is equivalent to:

```
 sum by (application, group) (http_requests_total)
```

If we are just interested in the total of HTTP requests we have seen in **all** applications, we could simply write:

```
sum(http_requests_total)
```

To count the number of binaries running each build version we could write:

```
count_values("version", build_version)
```

To get the 5 largest HTTP requests counts across all instances we could write:

```
topk(5, http_requests_total)
```

### Binary operator precedence

The following list shows the precedence of binary operators in Prometheus, from highest to lowest.

1. `^`
2. `*`, `/`, `%`, `atan2`
3. `+`, `-`
4. `==`, `!=`, `<=`, `<`, `>=`, `>`
5. `and`, `unless`
6. `or`

Operators on the same precedence level are left-associative. For example, `2 * 3 % 2` is equivalent to `(2 * 3) % 2`. However `^` is right associative, so `2 ^ 3 ^ 2` is equivalent to `2 ^ (3 ^ 2)`.

### Operators for native histograms

Native histograms are an experimental feature. Ingesting native histograms has to be enabled via a [feature flag](https://prometheus.io/docs/prometheus/latest/querying/feature_flags/#native-histograms). Once native histograms have been ingested, they can be queried (even after the feature flag has been disabled again). However, the operator support for native histograms is still very limited.

Logical/set binary operators work as expected even if histogram samples are involved. They only check for the existence of a vector element and don't change their behavior depending on the sample type of an element (float or histogram). The `count` aggregation operator works similarly.

The binary `+` and `-` operators between two native histograms and the `sum` and `avg` aggregation operators to aggregate native histograms are fully supported. Even if the histograms involved have different bucket layouts, the buckets are automatically converted appropriately so that the operation can be performed. (With the currently supported bucket schemas, that's always possible.) If either operator has to aggregate a mix of histogram samples and float samples, the corresponding vector element is removed from the output vector entirely.

The binary `*` operator works between a native histogram and a float in any order, while the binary `/` operator can be used between a native histogram and a float in that exact order.

All other operators (and unmentioned cases for the above operators) do not behave in a meaningful way. They either treat the histogram sample as if it were a float sample of value 0, or (in case of arithmetic operations between a scalar and a vector) they leave the histogram sample unchanged. This behavior will change to a meaningful one before native histograms are a stable feature.

## Functions

- [ `abs()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#abs)
- [ `absent()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#absent)
- [ `absent_over_time()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#absent_over_time)
- [ `ceil()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#ceil)
- [ `changes()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#changes)
- [ `clamp()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#clamp)
- [ `clamp_max()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#clamp_max)
- [ `clamp_min()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#clamp_min)
- [ `day_of_month()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#day_of_month)
- [ `day_of_week()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#day_of_week)
- [ `day_of_year()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#day_of_year)
- [ `days_in_month()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#days_in_month)
- [ `delta()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#delta)
- [ `deriv()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#deriv)
- [ `exp()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#exp)
- [ `floor()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#floor)
- [ `histogram_count()` and `histogram_sum()`  ](https://prometheus.io/docs/prometheus/latest/querying/functions/#histogram_count-and-histogram_sum)
- [ `histogram_fraction()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#histogram_fraction)
- [ `histogram_quantile()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#histogram_quantile)
- [ `holt_winters()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#holt_winters)
- [ `hour()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#hour)
- [ `idelta()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#idelta)
- [ `increase()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#increase)
- [ `irate()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#irate)
- [ `label_join()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#label_join)
- [ `label_replace()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#label_replace)
- [ `ln()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#ln)
- [ `log2()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#log2)
- [ `log10()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#log10)
- [ `minute()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#minute)
- [ `month()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#month)
- [ `predict_linear()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#predict_linear)
- [ `rate()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#rate)
- [ `resets()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#resets)
- [ `round()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#round)
- [ `scalar()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#scalar)
- [ `sgn()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#sgn)
- [ `sort()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#sort)
- [ `sort_desc()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#sort_desc)
- [ `sqrt()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#sqrt)
- [ `time()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#time)
- [ `timestamp()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#timestamp)
- [ `vector()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#vector)
- [ `year()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#year)
- [ `_over_time()` ](https://prometheus.io/docs/prometheus/latest/querying/functions/#aggregation_over_time)
- [Trigonometric Functions ](https://prometheus.io/docs/prometheus/latest/querying/functions/#trigonometric-functions)

Some functions have default arguments, e.g. `year(v=vector(time()) instant-vector)`. This means that there is one argument `v` which is an instant vector, which if not provided it will default to the value of the expression `vector(time())`.

*Notes about the experimental native histograms:*

- Ingesting native histograms has to be enabled via a [feature flag](https://prometheus.io/docs/prometheus/latest/querying/feature_flags/#native-histograms). As long as no native histograms have been ingested into the TSDB, all functions will behave as usual.
- Functions that do not explicitly mention native histograms in their documentation (see below) will ignore histogram samples.
- Functions that do already act on native histograms might still change their behavior in the future.
- If a function requires the same bucket layout between multiple native histograms it acts on, it will automatically convert them appropriately. (With the currently supported bucket schemas, that's always possible.)

### `abs()`

`abs(v instant-vector)` returns the input vector with all sample values converted to their absolute value.

### `absent()`

`absent(v instant-vector)` returns an empty vector if the vector passed to it has any elements (floats or native histograms) and a 1-element vector with the value 1 if the vector passed to it has no elements.

This is useful for alerting on when no time series exist for a given metric name and label combination.

```
absent(nonexistent{job="myjob"})
# => {job="myjob"}

absent(nonexistent{job="myjob",instance=~".*"})
# => {job="myjob"}

absent(sum(nonexistent{job="myjob"}))
# => {}
```

In the first two examples, `absent()` tries to be smart about deriving labels of the 1-element output vector from the input vector.

### `absent_over_time()`

`absent_over_time(v range-vector)` returns an empty vector if the range vector passed to it has any elements (floats or native histograms) and a 1-element vector with the value 1 if the range vector passed to it has no elements.

This is useful for alerting on when no time series exist for a given metric name and label combination for a certain amount of time.

```
absent_over_time(nonexistent{job="myjob"}[1h])
# => {job="myjob"}

absent_over_time(nonexistent{job="myjob",instance=~".*"}[1h])
# => {job="myjob"}

absent_over_time(sum(nonexistent{job="myjob"})[1h:])
# => {}
```

In the first two examples, `absent_over_time()` tries to be smart about deriving labels of the 1-element output vector from the input vector.

### `ceil()`

`ceil(v instant-vector)` rounds the sample values of all elements in `v` up to the nearest integer.

### `changes()`

For each input time series, `changes(v range-vector)` returns the number of times its value has changed within the provided time range as an instant vector.

### `clamp()`

`clamp(v instant-vector, min scalar, max scalar)` clamps the sample values of all elements in `v` to have a lower limit of `min` and an upper limit of `max`.

Special cases: - Return an empty vector if `min > max` - Return `NaN` if `min` or `max` is `NaN`

### `clamp_max()`

`clamp_max(v instant-vector, max scalar)` clamps the sample values of all elements in `v` to have an upper limit of `max`.

### `clamp_min()`

`clamp_min(v instant-vector, min scalar)` clamps the sample values of all elements in `v` to have a lower limit of `min`.

### `day_of_month()`

`day_of_month(v=vector(time()) instant-vector)` returns the day of the month for each of the given times in UTC. Returned values are from 1 to 31.

### `day_of_week()`

`day_of_week(v=vector(time()) instant-vector)` returns the day of the week for each of the given times in UTC. Returned values are from 0 to 6, where 0 means Sunday etc.

### `day_of_year()`

`day_of_year(v=vector(time()) instant-vector)` returns the day of the year for each of the given times in UTC. Returned values are from 1 to 365 for non-leap years, and 1 to 366 in leap years.

### `days_in_month()`

`days_in_month(v=vector(time()) instant-vector)` returns number of days in the month for each of the given times in UTC. Returned values are from 28 to 31.

### `delta()`

`delta(v range-vector)` calculates the difference between the first and last value of each time series element in a range vector `v`, returning an instant vector with the given deltas and equivalent labels. The delta is extrapolated to cover the full time range as specified in the range vector selector, so that it is possible to get a non-integer result even if the sample values are all integers.

The following example expression returns the difference in CPU temperature between now and 2 hours ago:

```
delta(cpu_temp_celsius{host="zeus"}[2h])
```

`delta` acts on native histograms by calculating a new histogram where each compononent (sum and count of observations, buckets) is the difference between the respective component in the first and last native histogram in `v`. However, each element in `v` that contains a mix of float and native histogram samples within the range, will be missing from the result vector.

`delta` should only be used with gauges and native histograms where the components behave like gauges (so-called gauge histograms).

### `deriv()`

`deriv(v range-vector)` calculates the per-second derivative of the time series in a range vector `v`, using [simple linear regression](https://en.wikipedia.org/wiki/Simple_linear_regression). The range vector must have at least two samples in order to perform the calculation. When `+Inf` or  `-Inf` are found in the range vector, the slope and offset value calculated will be `NaN`.

`deriv` should only be used with gauges.

### `exp()`

`exp(v instant-vector)` calculates the exponential function for all elements in `v`. Special cases are:

- `Exp(+Inf) = +Inf`
- `Exp(NaN) = NaN`

### `floor()`

`floor(v instant-vector)` rounds the sample values of all elements in `v` down to the nearest integer.

### `histogram_count()` and `histogram_sum()`

*Both functions only act on native histograms, which are an experimental feature. The behavior of these functions may change in future versions of Prometheus, including their removal from PromQL.*

`histogram_count(v instant-vector)` returns the count of observations stored in a native histogram. Samples that are not native histograms are ignored and do not show up in the returned vector.

Similarly, `histogram_sum(v instant-vector)` returns the sum of observations stored in a native histogram.

Use `histogram_count` in the following way to calculate a rate of observations (in this case corresponding to “requests per second”) from a native histogram:

```
histogram_count(rate(http_request_duration_seconds[10m]))
```

The additional use of `histogram_sum` enables the calculation of the average of observed values (in this case corresponding to “average request duration”):

```
  histogram_sum(rate(http_request_duration_seconds[10m]))
/
  histogram_count(rate(http_request_duration_seconds[10m]))
```

### `histogram_fraction()`

*This function only acts on native histograms, which are an experimental feature. The behavior of this function may change in future versions of Prometheus, including its removal from PromQL.*

For a native histogram, `histogram_fraction(lower scalar, upper scalar, v instant-vector)` returns the estimated fraction of observations between the provided lower and upper values. Samples that are not native histograms are ignored and do not show up in the returned vector.

For example, the following expression calculates the fraction of HTTP requests over the last hour that took 200ms or less:

```
histogram_fraction(0, 0.2, rate(http_request_duration_seconds[1h]))
```

The error of the estimation depends on the resolution of the underlying native histogram and how closely the provided boundaries are aligned with the bucket boundaries in the histogram.

`+Inf` and `-Inf` are valid boundary values. For example, if the histogram in the expression above included negative observations (which shouldn't be the case for request durations), the appropriate lower boundary to include all observations less than or equal 0.2 would be `-Inf` rather than `0`.

Whether the provided boundaries are inclusive or exclusive is only relevant if the provided boundaries are precisely aligned with bucket boundaries in the underlying native histogram. In this case, the behavior depends on the schema definition of the histogram. The currently supported schemas all feature inclusive upper boundaries and exclusive lower boundaries for positive values (and vice versa for negative values). Without a precise alignment of boundaries, the function uses linear interpolation to estimate the fraction. With the resulting uncertainty, it becomes irrelevant if the boundaries are inclusive or exclusive.

### `histogram_quantile()`

`histogram_quantile(φ scalar, b instant-vector)` calculates the φ-quantile (0 ≤ φ ≤ 1) from a [conventional histogram](https://prometheus.io/docs/concepts/metric_types/#histogram) or from a native histogram. (See [histograms and summaries](https://prometheus.io/docs/practices/histograms) for a detailed explanation of φ-quantiles and the usage of the (conventional) histogram metric type in general.)

*Note that native histograms are an experimental feature. The behavior of this function when dealing with native histograms may change in future versions of Prometheus.*

The conventional float samples in `b` are considered the counts of observations in each bucket of one or more conventional histograms. Each float sample must have a label `le` where the label value denotes the inclusive upper bound of the bucket. (Float samples without such a label are silently ignored.) The other labels and the metric name are used to identify the buckets belonging to each conventional histogram. The [histogram metric type](https://prometheus.io/docs/concepts/metric_types/#histogram) automatically provides time series with the `_bucket` suffix and the appropriate labels.

The native histogram samples in `b` are treated each individually as a separate histogram to calculate the quantile from.

As long as no naming collisions arise, `b` may contain a mix of conventional and native histograms.

Use the `rate()` function to specify the time window for the quantile calculation.

Example: A histogram metric is called `http_request_duration_seconds` (and therefore the metric name for the buckets of a conventional histogram is `http_request_duration_seconds_bucket`). To calculate the 90th percentile of request durations over the last 10m, use the following expression in case `http_request_duration_seconds` is a conventional histogram:

```
histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[10m]))
```

For a native histogram, use the following expression instead:

```
histogram_quantile(0.9, rate(http_request_duration_seconds[10m]))
```

The quantile is calculated for each label combination in `http_request_duration_seconds`. To aggregate, use the `sum()` aggregator around the `rate()` function. Since the `le` label is required by `histogram_quantile()` to deal with conventional histograms, it has to be included in the `by` clause. The following expression aggregates the 90th percentile by `job` for conventional histograms:

```
histogram_quantile(0.9, sum by (job, le) (rate(http_request_duration_seconds_bucket[10m])))
```

When aggregating native histograms, the expression simplifies to:

```
histogram_quantile(0.9, sum by (job) (rate(http_request_duration_seconds[10m])))
```

To aggregate all conventional histograms, specify only the `le` label:

```
histogram_quantile(0.9, sum by (le) (rate(http_request_duration_seconds_bucket[10m])))
```

With native histograms, aggregating everything works as usual without any `by` clause:

```
histogram_quantile(0.9, sum(rate(http_request_duration_seconds[10m])))
```

The `histogram_quantile()` function interpolates quantile values by assuming a linear distribution within a bucket. 

If `b` has 0 observations, `NaN` is returned. For φ < 0, `-Inf` is returned. For φ > 1, `+Inf` is returned. For φ = `NaN`, `NaN` is returned.

The following is only relevant for conventional histograms: If `b` contains fewer than two buckets, `NaN` is returned. The highest bucket must have an upper bound of `+Inf`. (Otherwise, `NaN` is returned.) If a quantile is located in the highest bucket, the upper bound of the second highest bucket is returned. A lower limit of the lowest bucket is assumed to be 0 if the upper bound of that bucket is greater than 0. In that case, the usual linear interpolation is applied within that bucket. Otherwise, the upper bound of the lowest bucket is returned for quantiles located in the lowest bucket. 

You can use `histogram_quantile(0, v instant-vector)` to get the estimated minimum value stored in a histogram.

You can use `histogram_quantile(1, v instant-vector)` to get the estimated maximum value stored in a histogram.

### `holt_winters()`

`holt_winters(v range-vector, sf scalar, tf scalar)` produces a smoothed value for time series based on the range in `v`. The lower the smoothing factor `sf`, the more importance is given to old data. The higher the trend factor `tf`, the more trends in the data is considered. Both `sf` and `tf` must be between 0 and 1.

`holt_winters` should only be used with gauges.

### `hour()`

`hour(v=vector(time()) instant-vector)` returns the hour of the day for each of the given times in UTC. Returned values are from 0 to 23.

### `idelta()`

`idelta(v range-vector)` calculates the difference between the last two samples in the range vector `v`, returning an instant vector with the given deltas and equivalent labels.

`idelta` should only be used with gauges.

### `increase()`

`increase(v range-vector)` calculates the increase in the time series in the range vector. Breaks in monotonicity (such as counter resets due to target restarts) are automatically adjusted for. The increase is extrapolated to cover the full time range as specified in the range vector selector, so that it is possible to get a non-integer result even if a counter increases only by integer increments.

The following example expression returns the number of HTTP requests as measured over the last 5 minutes, per time series in the range vector:

```
increase(http_requests_total{job="api-server"}[5m])
```

`increase` acts on native histograms by calculating a new histogram where each component (sum and count of observations, buckets) is the increase between the respective component in the first and last native histogram in `v`. However, each element in `v` that contains a mix of float and native histogram samples within the range, will be missing from the result vector.

`increase` should only be used with counters and native histograms where the components behave like counters. It is syntactic sugar for `rate(v)` multiplied by the number of seconds under the specified time range window, and should be used primarily for human readability.  Use `rate` in recording rules so that increases are tracked consistently on a per-second basis.

### `irate()`

`irate(v range-vector)` calculates the per-second instant rate of increase of the time series in the range vector. This is based on the last two data points. Breaks in monotonicity (such as counter resets due to target restarts) are automatically adjusted for.

The following example expression returns the per-second rate of HTTP requests looking up to 5 minutes back for the two most recent data points, per time series in the range vector:

```
irate(http_requests_total{job="api-server"}[5m])
```

`irate` should only be used when graphing volatile, fast-moving counters. Use `rate` for alerts and slow-moving counters, as brief changes in the rate can reset the `FOR` clause and graphs consisting entirely of rare spikes are hard to read.

Note that when combining `irate()` with an [aggregation operator](https://prometheus.io/docs/prometheus/latest/querying/operators/#aggregation-operators) (e.g. `sum()`) or a function aggregating over time (any function ending in `_over_time`), always take a `irate()` first, then aggregate. Otherwise `irate()` cannot detect counter resets when your target restarts.

### `label_join()`

For each timeseries in `v`, `label_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, ...)` joins all the values of all the `src_labels` using `separator` and returns the timeseries with the label `dst_label` containing the joined value. There can be any number of `src_labels` in this function.

`label_join` acts on float and histogram samples in the same way.

This example will return a vector with each time series having a `foo` label with the value `a,b,c` added to it:

```
label_join(up{job="api-server",src1="a",src2="b",src3="c"}, "foo", ",", "src1", "src2", "src3")
```

### `label_replace()`

For each timeseries in `v`, `label_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string)` matches the regular expression `regex` against the value of the label `src_label`. If it matches, the value of the label `dst_label` in the returned timeseries will be the expansion of `replacement`, together with the original labels in the input. Capturing groups in the regular expression can be referenced with `$1`, `$2`, etc. If the regular expression doesn't match then the timeseries is returned unchanged.

`label_replace` acts on float and histogram samples in the same way.

This example will return timeseries with the values `a:c` at label `service` and `a` at label `foo`:

```
label_replace(up{job="api-server",service="a:c"}, "foo", "$1", "service", "(.*):.*")
```

### `ln()`

`ln(v instant-vector)` calculates the natural logarithm for all elements in `v`. Special cases are:

- `ln(+Inf) = +Inf`
- `ln(0) = -Inf`
- `ln(x < 0) = NaN`
- `ln(NaN) = NaN`

### `log2()`

`log2(v instant-vector)` calculates the binary logarithm for all elements in `v`. The special cases are equivalent to those in `ln`.

### `log10()`

`log10(v instant-vector)` calculates the decimal logarithm for all elements in `v`. The special cases are equivalent to those in `ln`.

### `minute()`

`minute(v=vector(time()) instant-vector)` returns the minute of the hour for each of the given times in UTC. Returned values are from 0 to 59.

### `month()`

`month(v=vector(time()) instant-vector)` returns the month of the year for each of the given times in UTC. Returned values are from 1 to 12, where 1 means January etc.

### `predict_linear()`

`predict_linear(v range-vector, t scalar)` predicts the value of time series `t` seconds from now, based on the range vector `v`, using [simple linear regression](https://en.wikipedia.org/wiki/Simple_linear_regression). The range vector must have at least two samples in order to perform the  calculation. When `+Inf` or `-Inf` are found in the range vector,  the slope and offset value calculated will be `NaN`.

`predict_linear` should only be used with gauges.

### `rate()`

`rate(v range-vector)` calculates the per-second average rate of increase of the time series in the range vector. Breaks in monotonicity (such as counter resets due to target restarts) are automatically adjusted for. Also, the calculation extrapolates to the ends of the time range, allowing for missed scrapes or imperfect alignment of scrape cycles with the range's time period.

The following example expression returns the per-second rate of HTTP requests as measured over the last 5 minutes, per time series in the range vector:

```
rate(http_requests_total{job="api-server"}[5m])
```

`rate` acts on native histograms by calculating a new histogram where each compononent (sum and count of observations, buckets) is the rate of increase between the respective component in the first and last native histogram in `v`. However, each element in `v` that contains a mix of float and native histogram samples within the range, will be missing from the result vector.

`rate` should only be used with counters and native histograms where the components behave like counters. It is best suited for alerting, and for graphing of slow-moving counters.

Note that when combining `rate()` with an aggregation operator (e.g. `sum()`) or a function aggregating over time (any function ending in `_over_time`), always take a `rate()` first, then aggregate. Otherwise `rate()` cannot detect counter resets when your target restarts.

### `resets()`

For each input time series, `resets(v range-vector)` returns the number of counter resets within the provided time range as an instant vector. Any decrease in the value between two consecutive float samples is interpreted as a counter reset. A reset in a native histogram is detected in a more complex way: Any decrease in any bucket, including the zero bucket, or in the count of observation constitutes a counter reset, but also the disappearance of any previously populated bucket, an increase in bucket resolution, or a decrease of the zero-bucket width.

`resets` should only be used with counters and counter-like native histograms.

If the range vector contains a mix of float and histogram samples for the same series, counter resets are detected separately and their numbers added up. The change from a float to a histogram sample is *not* considered a counter reset. Each float sample is compared to the next float sample, and each histogram is comprared to the next histogram.

### `round()`

`round(v instant-vector, to_nearest=1 scalar)` rounds the sample values of all elements in `v` to the nearest integer. Ties are resolved by rounding up. The optional `to_nearest` argument allows specifying the nearest multiple to which the sample values should be rounded. This multiple may also be a fraction.

### `scalar()`

Given a single-element input vector, `scalar(v instant-vector)` returns the sample value of that single element as a scalar. If the input vector does not have exactly one element, `scalar` will return `NaN`.

### `sgn()`

`sgn(v instant-vector)` returns a vector with all sample  values converted to their sign, defined as this: 1 if v is positive, -1  if v is negative and 0 if v is equal to zero.

### `sort()`

`sort(v instant-vector)` returns vector elements sorted by their sample values, in ascending order. Native histograms are sorted by their sum of observations.

### `sort_desc()`

Same as `sort`, but sorts in descending order.

### `sqrt()`

`sqrt(v instant-vector)` calculates the square root of all elements in `v`.

### `time()`

`time()` returns the number of seconds since January 1, 1970 UTC. Note that this does not actually return the current time, but the time at which the expression is to be evaluated.

### `timestamp()`

`timestamp(v instant-vector)` returns the timestamp of each of the samples of the given vector as the number of seconds since January 1, 1970 UTC. It also works with histogram samples.

### `vector()`

`vector(s scalar)` returns the scalar `s` as a vector with no labels.

### `year()`

`year(v=vector(time()) instant-vector)` returns the year for each of the given times in UTC.

### `<aggregation>_over_time()`

The following functions allow aggregating each series of a given range vector over time and return an instant vector with per-series aggregation results:

- `avg_over_time(range-vector)`: the average value of all points in the specified interval.
- `min_over_time(range-vector)`: the minimum value of all points in the specified interval.
- `max_over_time(range-vector)`: the maximum value of all points in the specified interval.
- `sum_over_time(range-vector)`: the sum of all values in the specified interval.
- `count_over_time(range-vector)`: the count of all values in the specified interval.
- `quantile_over_time(scalar, range-vector)`: the φ-quantile (0 ≤ φ ≤ 1) of the values in the specified interval.
- `stddev_over_time(range-vector)`: the population standard deviation of the values in the specified interval.
- `stdvar_over_time(range-vector)`: the population standard variance of the values in the specified interval.
- `last_over_time(range-vector)`: the most recent point value in the specified interval.
- `present_over_time(range-vector)`: the value 1 for any series in the specified interval.

Note that all values in the specified interval have the same weight in the aggregation even if the values are not equally spaced throughout the interval.

`avg_over_time`, `sum_over_time`, `count_over_time`, `last_over_time`, and `present_over_time` handle native histograms as expected. All other functions ignore histogram samples.

### Trigonometric Functions

The trigonometric functions work in radians:

- `acos(v instant-vector)`: calculates the arccosine of all elements in `v` ([special cases](https://pkg.go.dev/math#Acos)).
- `acosh(v instant-vector)`: calculates the inverse hyperbolic cosine of all elements in `v` ([special cases](https://pkg.go.dev/math#Acosh)).
- `asin(v instant-vector)`: calculates the arcsine of all elements in `v` ([special cases](https://pkg.go.dev/math#Asin)).
- `asinh(v instant-vector)`: calculates the inverse hyperbolic sine of all elements in `v` ([special cases](https://pkg.go.dev/math#Asinh)).
- `atan(v instant-vector)`: calculates the arctangent of all elements in `v` ([special cases](https://pkg.go.dev/math#Atan)).
- `atanh(v instant-vector)`: calculates the inverse hyperbolic tangent of all elements in `v` ([special cases](https://pkg.go.dev/math#Atanh)).
- `cos(v instant-vector)`: calculates the cosine of all elements in `v` ([special cases](https://pkg.go.dev/math#Cos)).
- `cosh(v instant-vector)`: calculates the hyperbolic cosine of all elements in `v` ([special cases](https://pkg.go.dev/math#Cosh)).
- `sin(v instant-vector)`: calculates the sine of all elements in `v` ([special cases](https://pkg.go.dev/math#Sin)).
- `sinh(v instant-vector)`: calculates the hyperbolic sine of all elements in `v` ([special cases](https://pkg.go.dev/math#Sinh)).
- `tan(v instant-vector)`: calculates the tangent of all elements in `v` ([special cases](https://pkg.go.dev/math#Tan)).
- `tanh(v instant-vector)`: calculates the hyperbolic tangent of all elements in `v` ([special cases](https://pkg.go.dev/math#Tanh)).

The following are useful for converting between degrees and radians:

- `deg(v instant-vector)`: converts radians to degrees for all elements in `v`.
- `pi()`: returns pi.
- `rad(v instant-vector)`: converts degrees to radians for all elements in `v`.

## Query examples

- [Simple time series selection ](https://prometheus.io/docs/prometheus/latest/querying/examples/#simple-time-series-selection)
- [Subquery ](https://prometheus.io/docs/prometheus/latest/querying/examples/#subquery)
- [Using functions, operators, etc. ](https://prometheus.io/docs/prometheus/latest/querying/examples/#using-functions-operators-etc)

### Simple time series selection

Return all time series with the metric `http_requests_total`:

```
http_requests_total
```

Return all time series with the metric `http_requests_total` and the given `job` and `handler` labels:

```
http_requests_total{job="apiserver", handler="/api/comments"}
```

Return a whole range of time (in this case 5 minutes up to the query time) for the same vector, making it a [range vector](https://prometheus.io/docs/prometheus/latest/querying/basics/#range-vector-selectors):

```
http_requests_total{job="apiserver", handler="/api/comments"}[5m]
```

Note that an expression resulting in a range vector cannot be graphed directly, but viewed in the tabular ("Console") view of the expression browser.

Using regular expressions, you could select time series only for jobs whose name match a certain pattern, in this case, all jobs that end with `server`:

```
http_requests_total{job=~".*server"}
```

All regular expressions in Prometheus use [RE2 syntax](https://github.com/google/re2/wiki/Syntax).

To select all HTTP status codes except 4xx ones, you could run:

```
http_requests_total{status!~"4.."}
```

### Subquery

Return the 5-minute rate of the `http_requests_total` metric for the past 30 minutes, with a resolution of 1 minute.

```
rate(http_requests_total[5m])[30m:1m]
```

This is an example of a nested subquery. The subquery for the `deriv` function uses the default resolution. Note that using subqueries unnecessarily is unwise.

```
max_over_time(deriv(rate(distance_covered_total[5s])[30s:5s])[10m:])
```

### Using functions, operators, etc.

Return the per-second rate for all time series with the `http_requests_total` metric name, as measured over the last 5 minutes:

```
rate(http_requests_total[5m])
```

Assuming that the `http_requests_total` time series all have the labels `job` (fanout by job name) and `instance` (fanout by instance of the job), we might want to sum over the rate of all instances, so we get fewer output time series, but still preserve the `job` dimension:

```
sum by (job) (
  rate(http_requests_total[5m])
)
```

If we have two different metrics with the same dimensional labels, we can apply binary operators to them and elements on both sides with the same label set will get matched and propagated to the output. For example, this expression returns the unused memory in MiB for every instance (on a fictional cluster scheduler exposing these metrics about the instances it runs):

```
(instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 / 1024
```

The same expression, but summed by application, could be written like this:

```
sum by (app, proc) (
  instance_memory_limit_bytes - instance_memory_usage_bytes
) / 1024 / 1024
```

If the same fictional cluster scheduler exposed CPU usage metrics like the following for every instance:

```
instance_cpu_time_ns{app="lion", proc="web", rev="34d0f99", env="prod", job="cluster-manager"}
instance_cpu_time_ns{app="elephant", proc="worker", rev="34d0f99", env="prod", job="cluster-manager"}
instance_cpu_time_ns{app="turtle", proc="api", rev="4d3a513", env="prod", job="cluster-manager"}
instance_cpu_time_ns{app="fox", proc="widget", rev="4d3a513", env="prod", job="cluster-manager"}
...
```

...we could get the top 3 CPU users grouped by application (`app`) and process type (`proc`) like this:

```
topk(3, sum by (app, proc) (rate(instance_cpu_time_ns[5m])))
```

Assuming this metric contains one time series per running instance, you could count the number of running instances per application like this:

```
count by (app) (instance_cpu_time_ns)
```

## HTTP API

- [Format overview ](https://prometheus.io/docs/prometheus/latest/querying/api/#format-overview)
- [Expression queries ](https://prometheus.io/docs/prometheus/latest/querying/api/#expression-queries)
  - [Instant queries ](https://prometheus.io/docs/prometheus/latest/querying/api/#instant-queries)
  - [Range queries ](https://prometheus.io/docs/prometheus/latest/querying/api/#range-queries)
- [Formatting query expressions ](https://prometheus.io/docs/prometheus/latest/querying/api/#formatting-query-expressions)
- [Querying metadata ](https://prometheus.io/docs/prometheus/latest/querying/api/#querying-metadata)
  - [Finding series by label matchers ](https://prometheus.io/docs/prometheus/latest/querying/api/#finding-series-by-label-matchers)
  - [Getting label names ](https://prometheus.io/docs/prometheus/latest/querying/api/#getting-label-names)
  - [Querying label values ](https://prometheus.io/docs/prometheus/latest/querying/api/#querying-label-values)
- [Querying exemplars ](https://prometheus.io/docs/prometheus/latest/querying/api/#querying-exemplars)
- [Expression query result formats ](https://prometheus.io/docs/prometheus/latest/querying/api/#expression-query-result-formats)
  - [Range vectors ](https://prometheus.io/docs/prometheus/latest/querying/api/#range-vectors)
  - [Instant vectors ](https://prometheus.io/docs/prometheus/latest/querying/api/#instant-vectors)
  - [Scalars ](https://prometheus.io/docs/prometheus/latest/querying/api/#scalars)
  - [Strings ](https://prometheus.io/docs/prometheus/latest/querying/api/#strings)
  - [Native histograms ](https://prometheus.io/docs/prometheus/latest/querying/api/#native-histograms)
- [Targets ](https://prometheus.io/docs/prometheus/latest/querying/api/#targets)
- [Rules ](https://prometheus.io/docs/prometheus/latest/querying/api/#rules)
- [Alerts ](https://prometheus.io/docs/prometheus/latest/querying/api/#alerts)
- [Querying target metadata ](https://prometheus.io/docs/prometheus/latest/querying/api/#querying-target-metadata)
- [Querying metric metadata ](https://prometheus.io/docs/prometheus/latest/querying/api/#querying-metric-metadata)
- [Alertmanagers ](https://prometheus.io/docs/prometheus/latest/querying/api/#alertmanagers)
- [Status ](https://prometheus.io/docs/prometheus/latest/querying/api/#status)
  - [Config ](https://prometheus.io/docs/prometheus/latest/querying/api/#config)
  - [Flags ](https://prometheus.io/docs/prometheus/latest/querying/api/#flags)
  - [Runtime Information ](https://prometheus.io/docs/prometheus/latest/querying/api/#runtime-information)
  - [Build Information ](https://prometheus.io/docs/prometheus/latest/querying/api/#build-information)
  - [TSDB Stats ](https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-stats)
  - [WAL Replay Stats ](https://prometheus.io/docs/prometheus/latest/querying/api/#wal-replay-stats)
- [TSDB Admin APIs ](https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis)
  - [Snapshot ](https://prometheus.io/docs/prometheus/latest/querying/api/#snapshot)
  - [Delete Series ](https://prometheus.io/docs/prometheus/latest/querying/api/#delete-series)
  - [Clean Tombstones ](https://prometheus.io/docs/prometheus/latest/querying/api/#clean-tombstones)
- [Remote Write Receiver ](https://prometheus.io/docs/prometheus/latest/querying/api/#remote-write-receiver)

The current stable HTTP API is reachable under `/api/v1` on a Prometheus server. Any non-breaking additions will be added under that endpoint.

### Format overview

The API response format is JSON. Every successful API request returns a `2xx` status code.

Invalid requests that reach the API handlers return a JSON error object and one of the following HTTP response codes:

- `400 Bad Request` when parameters are missing or incorrect.
- `422 Unprocessable Entity` when an expression can't be executed ([RFC4918](https://tools.ietf.org/html/rfc4918#page-78)).
- `503 Service Unavailable` when queries time out or abort.

Other non-`2xx` codes may be returned for errors occurring before the API endpoint is reached.

An array of warnings may be returned if there are errors that do not inhibit the request execution. All of the data that was successfully collected will be returned in the data field.

The JSON response envelope format is as follows:

```
{
  "status": "success" | "error",
  "data": <data>,

  // Only set if status is "error". The data field may still hold
  // additional data.
  "errorType": "<string>",
  "error": "<string>",

  // Only if there were warnings while executing the request.
  // There will still be data in the data field.
  "warnings": ["<string>"]
}
```

Generic placeholders are defined as follows:

- `<rfc3339 | unix_timestamp>`: Input timestamps may be provided either in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format or as a Unix timestamp in seconds, with optional decimal places for sub-second precision. Output timestamps are always represented as Unix timestamps in seconds.
- `<series_selector>`: Prometheus [time series selectors](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-series-selectors) like `http_requests_total` or `http_requests_total{method=~"(GET|POST)"}` and need to be URL-encoded.
- `<duration>`: [Prometheus duration strings](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-durations). For example, `5m` refers to a duration of 5 minutes.
- `<bool>`: boolean values (strings `true` and `false`).

Note: Names of query parameters that may be repeated end with `[]`.

### Expression queries

Query language expressions may be evaluated at a single instant or over a range of time. The sections below describe the API endpoints for each type of expression query.

#### Instant queries

The following endpoint evaluates an instant query at a single point in time:

```
GET /api/v1/query
POST /api/v1/query
```

URL query parameters:

- `query=<string>`: Prometheus expression query string.
- `time=<rfc3339 | unix_timestamp>`: Evaluation timestamp. Optional.
- `timeout=<duration>`: Evaluation timeout. Optional. Defaults to and is capped by the value of the `-query.timeout` flag.

The current server time is used if the `time` parameter is omitted.

You can URL-encode these parameters directly in the request body by using the `POST` method and `Content-Type: application/x-www-form-urlencoded` header. This is useful when specifying a large query that may breach server-side URL character limits.

The `data` section of the query result has the following format:

```
{
  "resultType": "matrix" | "vector" | "scalar" | "string",
  "result": <value>
}
```

`<value>` refers to the query result data, which has varying formats depending on the `resultType`. See the [expression query result formats](https://prometheus.io/docs/prometheus/latest/querying/api/#expression-query-result-formats).

The following example evaluates the expression `up` at the time `2015-07-01T20:10:51.781Z`:

```
$ curl 'http://localhost:9090/api/v1/query?query=up&time=2015-07-01T20:10:51.781Z'
{
   "status" : "success",
   "data" : {
      "resultType" : "vector",
      "result" : [
         {
            "metric" : {
               "__name__" : "up",
               "job" : "prometheus",
               "instance" : "localhost:9090"
            },
            "value": [ 1435781451.781, "1" ]
         },
         {
            "metric" : {
               "__name__" : "up",
               "job" : "node",
               "instance" : "localhost:9100"
            },
            "value" : [ 1435781451.781, "0" ]
         }
      ]
   }
}
```

#### Range queries

The following endpoint evaluates an expression query over a range of time:

```
GET /api/v1/query_range
POST /api/v1/query_range
```

URL query parameters:

- `query=<string>`: Prometheus expression query string.
- `start=<rfc3339 | unix_timestamp>`: Start timestamp, inclusive.
- `end=<rfc3339 | unix_timestamp>`: End timestamp, inclusive.
- `step=<duration | float>`: Query resolution step width in `duration` format or float number of seconds.
- `timeout=<duration>`: Evaluation timeout. Optional. Defaults to and is capped by the value of the `-query.timeout` flag.

You can URL-encode these parameters directly in the request body by using the `POST` method and `Content-Type: application/x-www-form-urlencoded` header. This is useful when specifying a large query that may breach server-side URL character limits.

The `data` section of the query result has the following format:

```
{
  "resultType": "matrix",
  "result": <value>
}
```

For the format of the `<value>` placeholder, see the [range-vector result format](https://prometheus.io/docs/prometheus/latest/querying/api/#range-vectors).

The following example evaluates the expression `up` over a 30-second range with a query resolution of 15 seconds.

```
$ curl 'http://localhost:9090/api/v1/query_range?query=up&start=2015-07-01T20:10:30.781Z&end=2015-07-01T20:11:00.781Z&step=15s'
{
   "status" : "success",
   "data" : {
      "resultType" : "matrix",
      "result" : [
         {
            "metric" : {
               "__name__" : "up",
               "job" : "prometheus",
               "instance" : "localhost:9090"
            },
            "values" : [
               [ 1435781430.781, "1" ],
               [ 1435781445.781, "1" ],
               [ 1435781460.781, "1" ]
            ]
         },
         {
            "metric" : {
               "__name__" : "up",
               "job" : "node",
               "instance" : "localhost:9091"
            },
            "values" : [
               [ 1435781430.781, "0" ],
               [ 1435781445.781, "0" ],
               [ 1435781460.781, "1" ]
            ]
         }
      ]
   }
}
```

### Formatting query expressions

The following endpoint formats a PromQL expression in a prettified way:

```
GET /api/v1/format_query
POST /api/v1/format_query
```

URL query parameters:

- `query=<string>`: Prometheus expression query string.

You can URL-encode these parameters directly in the request body by using the `POST` method and `Content-Type: application/x-www-form-urlencoded` header. This is useful when specifying a large query that may breach server-side URL character limits.

The `data` section of the query result is a string  containing the formatted query expression. Note that any comments are  removed in the formatted string.

The following example formats the expression `foo/bar`:

```
$ curl 'http://localhost:9090/api/v1/format_query?query=foo/bar'
{
   "status" : "success",
   "data" : "foo / bar"
}
```

### Querying metadata

Prometheus offers a set of API endpoints to query metadata about series and their labels.

**NOTE:** These API endpoints may return metadata for  series for which there is no sample within the selected time range,  and/or for series whose samples have been marked as deleted via the  deletion API endpoint. The exact extent of additionally returned series  metadata is an implementation detail that may change in the future.

#### Finding series by label matchers

The following endpoint returns the list of time series that match a certain label set.

```
GET /api/v1/series
POST /api/v1/series
```

URL query parameters:

- `match[]=<series_selector>`: Repeated series selector argument that selects the series to return. At least one `match[]` argument must be provided.
- `start=<rfc3339 | unix_timestamp>`: Start timestamp.
- `end=<rfc3339 | unix_timestamp>`: End timestamp.

You can URL-encode these parameters directly in the request body by using the `POST` method and `Content-Type: application/x-www-form-urlencoded` header. This is useful when specifying a large or dynamic number of series selectors that may breach server-side URL character limits.

The `data` section of the query result consists of a list of objects that contain the label name/value pairs which identify each series.

The following example returns all series that match either of the selectors `up` or `process_start_time_seconds{job="prometheus"}`:

```
$ curl -g 'http://localhost:9090/api/v1/series?' --data-urlencode 'match[]=up' --data-urlencode 'match[]=process_start_time_seconds{job="prometheus"}'
{
   "status" : "success",
   "data" : [
      {
         "__name__" : "up",
         "job" : "prometheus",
         "instance" : "localhost:9090"
      },
      {
         "__name__" : "up",
         "job" : "node",
         "instance" : "localhost:9091"
      },
      {
         "__name__" : "process_start_time_seconds",
         "job" : "prometheus",
         "instance" : "localhost:9090"
      }
   ]
}
```

#### Getting label names

The following endpoint returns a list of label names:

```
GET /api/v1/labels
POST /api/v1/labels
```

URL query parameters:

- `start=<rfc3339 | unix_timestamp>`: Start timestamp. Optional.
- `end=<rfc3339 | unix_timestamp>`: End timestamp. Optional.
- `match[]=<series_selector>`: Repeated series selector argument that selects the series from which to read the label names. Optional.

The `data` section of the JSON response is a list of string label names.

Here is an example.

```
$ curl 'localhost:9090/api/v1/labels'
{
    "status": "success",
    "data": [
        "__name__",
        "call",
        "code",
        "config",
        "dialer_name",
        "endpoint",
        "event",
        "goversion",
        "handler",
        "instance",
        "interval",
        "job",
        "le",
        "listener_name",
        "name",
        "quantile",
        "reason",
        "role",
        "scrape_job",
        "slice",
        "version"
    ]
}
```

#### Querying label values

The following endpoint returns a list of label values for a provided label name:

```
GET /api/v1/label/<label_name>/values
```

URL query parameters:

- `start=<rfc3339 | unix_timestamp>`: Start timestamp. Optional.
- `end=<rfc3339 | unix_timestamp>`: End timestamp. Optional.
- `match[]=<series_selector>`: Repeated series selector argument that selects the series from which to read the label values. Optional.

The `data` section of the JSON response is a list of string label values.

This example queries for all label values for the `job` label:

```
$ curl http://localhost:9090/api/v1/label/job/values
{
   "status" : "success",
   "data" : [
      "node",
      "prometheus"
   ]
}
```

### Querying exemplars

This is **experimental** and might change in the future. The following endpoint returns a list of exemplars for a valid PromQL query for a specific time range:

```
GET /api/v1/query_exemplars
POST /api/v1/query_exemplars
```

URL query parameters:

- `query=<string>`: Prometheus expression query string.
- `start=<rfc3339 | unix_timestamp>`: Start timestamp.
- `end=<rfc3339 | unix_timestamp>`: End timestamp.

```
$ curl -g 'http://localhost:9090/api/v1/query_exemplars?query=test_exemplar_metric_total&start=2020-09-14T15:22:25.479Z&end=2020-09-14T15:23:25.479Z'
{
    "status": "success",
    "data": [
        {
            "seriesLabels": {
                "__name__": "test_exemplar_metric_total",
                "instance": "localhost:8090",
                "job": "prometheus",
                "service": "bar"
            },
            "exemplars": [
                {
                    "labels": {
                        "traceID": "EpTxMJ40fUus7aGY"
                    },
                    "value": "6",
                    "timestamp": 1600096945.479
                }
            ]
        },
        {
            "seriesLabels": {
                "__name__": "test_exemplar_metric_total",
                "instance": "localhost:8090",
                "job": "prometheus",
                "service": "foo"
            },
            "exemplars": [
                {
                    "labels": {
                        "traceID": "Olp9XHlq763ccsfa"
                    },
                    "value": "19",
                    "timestamp": 1600096955.479
                },
                {
                    "labels": {
                        "traceID": "hCtjygkIHwAN9vs4"
                    },
                    "value": "20",
                    "timestamp": 1600096965.489
                }
            ]
        }
    ]
}
```

### Expression query result formats

Expression queries may return the following response values in the `result` property of the `data` section. `<sample_value>` placeholders are numeric sample values. JSON does not support special float values such as `NaN`, `Inf`, and `-Inf`, so sample values are transferred as quoted JSON strings rather than raw numbers.

The keys `"histogram"` and `"histograms"` only show up if the experimental native histograms are present in the response. Their placeholder `<histogram>` is explained in detail in its own section below. 

#### Range vectors

Range vectors are returned as result type `matrix`. The corresponding `result` property has the following format:

```
[
  {
    "metric": { "<label_name>": "<label_value>", ... },
    "values": [ [ <unix_time>, "<sample_value>" ], ... ],
    "histograms": [ [ <unix_time>, <histogram> ], ... ]
  },
  ...
]
```

Each series could have the `"values"` key, or the `"histograms"` key, or both.  For a given timestamp, there will only be one sample of either float or histogram type.

#### Instant vectors

Instant vectors are returned as result type `vector`. The corresponding `result` property has the following format:

```
[
  {
    "metric": { "<label_name>": "<label_value>", ... },
    "value": [ <unix_time>, "<sample_value>" ],
    "histogram": [ <unix_time>, <histogram> ]
  },
  ...
]
```

Each series could have the `"value"` key, or the `"histogram"` key, but not both.

#### Scalars

Scalar results are returned as result type `scalar`. The corresponding `result` property has the following format:

```
[ <unix_time>, "<scalar_value>" ]
```

#### Strings

String results are returned as result type `string`. The corresponding `result` property has the following format:

```
[ <unix_time>, "<string_value>" ]
```

#### Native histograms

The `<histogram>` placeholder used above is formatted as follows.

*Note that native histograms are an experimental feature, and the format below might still change.*

```
{
  "count": "<count_of_observations>",
  "sum": "<sum_of_observations>",
  "buckets": [ [ <boundary_rule>, "<left_boundary>", "<right_boundary>", "<count_in_bucket>" ], ... ]
}
```

The `<boundary_rule>` placeholder is an integer between 0 and 3 with the following meaning:

- 0: “open left” (left boundary is exclusive, right boundary in inclusive)
- 1: “open right” (left boundary is inclusive, right boundary in exclusive)
- 2: “open both” (both boundaries are exclusive)
- 3: “closed both” (both boundaries are inclusive)

Note that with the currently implemented bucket schemas, positive buckets are “open left”, negative buckets are “open right”, and the zero bucket (with a negative left boundary and a positive right boundary) is “closed both”.

### Targets

The following endpoint returns an overview of the current state of the Prometheus target discovery:

```
GET /api/v1/targets
```

Both the active and dropped targets are part of the response by default. `labels` represents the label set after relabeling has occurred. `discoveredLabels` represent the unmodified labels retrieved during service discovery before relabeling has occurred.

```
$ curl http://localhost:9090/api/v1/targets
{
  "status": "success",
  "data": {
    "activeTargets": [
      {
        "discoveredLabels": {
          "__address__": "127.0.0.1:9090",
          "__metrics_path__": "/metrics",
          "__scheme__": "http",
          "job": "prometheus"
        },
        "labels": {
          "instance": "127.0.0.1:9090",
          "job": "prometheus"
        },
        "scrapePool": "prometheus",
        "scrapeUrl": "http://127.0.0.1:9090/metrics",
        "globalUrl": "http://example-prometheus:9090/metrics",
        "lastError": "",
        "lastScrape": "2017-01-17T15:07:44.723715405+01:00",
        "lastScrapeDuration": 0.050688943,
        "health": "up",
        "scrapeInterval": "1m",
        "scrapeTimeout": "10s"
      }
    ],
    "droppedTargets": [
      {
        "discoveredLabels": {
          "__address__": "127.0.0.1:9100",
          "__metrics_path__": "/metrics",
          "__scheme__": "http",
          "__scrape_interval__": "1m",
          "__scrape_timeout__": "10s",
          "job": "node"
        },
      }
    ]
  }
}
```

The `state` query parameter allows the caller to filter by active or dropped targets, (e.g., `state=active`, `state=dropped`, `state=any`). Note that an empty array is still returned for targets that are filtered out. Other values are ignored.

```
$ curl 'http://localhost:9090/api/v1/targets?state=active'
{
  "status": "success",
  "data": {
    "activeTargets": [
      {
        "discoveredLabels": {
          "__address__": "127.0.0.1:9090",
          "__metrics_path__": "/metrics",
          "__scheme__": "http",
          "job": "prometheus"
        },
        "labels": {
          "instance": "127.0.0.1:9090",
          "job": "prometheus"
        },
        "scrapePool": "prometheus",
        "scrapeUrl": "http://127.0.0.1:9090/metrics",
        "globalUrl": "http://example-prometheus:9090/metrics",
        "lastError": "",
        "lastScrape": "2017-01-17T15:07:44.723715405+01:00",
        "lastScrapeDuration": 50688943,
        "health": "up"
      }
    ],
    "droppedTargets": []
  }
}
```

The `scrapePool` query parameter allows the caller to filter by scrape pool name.

```
$ curl 'http://localhost:9090/api/v1/targets?scrapePool=node_exporter'
{
  "status": "success",
  "data": {
    "activeTargets": [
      {
        "discoveredLabels": {
          "__address__": "127.0.0.1:9091",
          "__metrics_path__": "/metrics",
          "__scheme__": "http",
          "job": "node_exporter"
        },
        "labels": {
          "instance": "127.0.0.1:9091",
          "job": "node_exporter"
        },
        "scrapePool": "node_exporter",
        "scrapeUrl": "http://127.0.0.1:9091/metrics",
        "globalUrl": "http://example-prometheus:9091/metrics",
        "lastError": "",
        "lastScrape": "2017-01-17T15:07:44.723715405+01:00",
        "lastScrapeDuration": 50688943,
        "health": "up"
      }
    ],
    "droppedTargets": []
  }
}
```

### Rules

The `/rules` API endpoint returns a list of alerting and recording rules that are currently loaded. In addition it returns the currently active alerts fired by the Prometheus instance of each alerting rule.

As the `/rules` endpoint is fairly new, it does not have the same stability guarantees as the overarching API v1.

```
GET /api/v1/rules
```

URL query parameters:

- `type=alert|record`: return only the alerting rules (e.g. `type=alert`) or the recording rules (e.g. `type=record`). When the parameter is absent or empty, no filtering is done.
- `rule_name[]=<string>`: only return rules with the  given rule name. If the parameter is repeated, rules with any of the  provided names are returned. If we've filtered out all the rules of a  group, the group is not returned. When the parameter is absent or empty, no filtering is done.
- `rule_group[]=<string>`: only return rules with the  given rule group name. If the parameter is repeated, rules with any of  the provided rule group names are returned. When the parameter is absent or empty, no filtering is done.
- `file[]=<string>`: only return rules with the given  filepath. If the parameter is repeated, rules with any of the provided  filepaths are returned. When the parameter is absent or empty, no  filtering is done.

```
$ curl http://localhost:9090/api/v1/rules

{
    "data": {
        "groups": [
            {
                "rules": [
                    {
                        "alerts": [
                            {
                                "activeAt": "2018-07-04T20:27:12.60602144+02:00",
                                "annotations": {
                                    "summary": "High request latency"
                                },
                                "labels": {
                                    "alertname": "HighRequestLatency",
                                    "severity": "page"
                                },
                                "state": "firing",
                                "value": "1e+00"
                            }
                        ],
                        "annotations": {
                            "summary": "High request latency"
                        },
                        "duration": 600,
                        "health": "ok",
                        "labels": {
                            "severity": "page"
                        },
                        "name": "HighRequestLatency",
                        "query": "job:request_latency_seconds:mean5m{job=\"myjob\"} > 0.5",
                        "type": "alerting"
                    },
                    {
                        "health": "ok",
                        "name": "job:http_inprogress_requests:sum",
                        "query": "sum by (job) (http_inprogress_requests)",
                        "type": "recording"
                    }
                ],
                "file": "/rules.yaml",
                "interval": 60,
                "limit": 0,
                "name": "example"
            }
        ]
    },
    "status": "success"
}
```

### Alerts

The `/alerts` endpoint returns a list of all active alerts.

As the `/alerts` endpoint is fairly new, it does not have the same stability guarantees as the overarching API v1.

```
GET /api/v1/alerts
$ curl http://localhost:9090/api/v1/alerts

{
    "data": {
        "alerts": [
            {
                "activeAt": "2018-07-04T20:27:12.60602144+02:00",
                "annotations": {},
                "labels": {
                    "alertname": "my-alert"
                },
                "state": "firing",
                "value": "1e+00"
            }
        ]
    },
    "status": "success"
}
```

### Querying target metadata

The following endpoint returns metadata about metrics currently scraped from targets. This is **experimental** and might change in the future.

```
GET /api/v1/targets/metadata
```

URL query parameters:

- `match_target=<label_selectors>`: Label selectors that match targets by their label sets. All targets are selected if left empty.
- `metric=<string>`: A metric name to retrieve metadata for. All metric metadata is retrieved if left empty.
- `limit=<number>`: Maximum number of targets to match.

The `data` section of the query result consists of a list of objects that contain metric metadata and the target label set.

The following example returns all metadata entries for the `go_goroutines` metric from the first two targets with label `job="prometheus"`.

```
curl -G http://localhost:9091/api/v1/targets/metadata \
    --data-urlencode 'metric=go_goroutines' \
    --data-urlencode 'match_target={job="prometheus"}' \
    --data-urlencode 'limit=2'
{
  "status": "success",
  "data": [
    {
      "target": {
        "instance": "127.0.0.1:9090",
        "job": "prometheus"
      },
      "type": "gauge",
      "help": "Number of goroutines that currently exist.",
      "unit": ""
    },
    {
      "target": {
        "instance": "127.0.0.1:9091",
        "job": "prometheus"
      },
      "type": "gauge",
      "help": "Number of goroutines that currently exist.",
      "unit": ""
    }
  ]
}
```

The following example returns metadata for all metrics for all targets with label `instance="127.0.0.1:9090`.

```
curl -G http://localhost:9091/api/v1/targets/metadata \
    --data-urlencode 'match_target={instance="127.0.0.1:9090"}'
{
  "status": "success",
  "data": [
    // ...
    {
      "target": {
        "instance": "127.0.0.1:9090",
        "job": "prometheus"
      },
      "metric": "prometheus_treecache_zookeeper_failures_total",
      "type": "counter",
      "help": "The total number of ZooKeeper failures.",
      "unit": ""
    },
    {
      "target": {
        "instance": "127.0.0.1:9090",
        "job": "prometheus"
      },
      "metric": "prometheus_tsdb_reloads_total",
      "type": "counter",
      "help": "Number of times the database reloaded block data from disk.",
      "unit": ""
    },
    // ...
  ]
}
```

### Querying metric metadata

It returns metadata about metrics currently scraped from targets. However, it does not provide any target information. This is considered **experimental** and might change in the future.

```
GET /api/v1/metadata
```

URL query parameters:

- `limit=<number>`: Maximum number of metrics to return.
- `limit_per_metric=<number>`: Maximum number of metadata to return per metric.
- `metric=<string>`: A metric name to filter metadata for. All metric metadata is retrieved if left empty.

The `data` section of the query result consists of an  object where each key is a metric name and each value is a list of  unique metadata objects, as exposed for that metric name across all  targets.

The following example returns two metrics. Note that the metric `http_requests_total` has more than one object in the list. At least one target has a value for `HELP` that do not match with the rest.

```
curl -G http://localhost:9090/api/v1/metadata?limit=2

{
  "status": "success",
  "data": {
    "cortex_ring_tokens": [
      {
        "type": "gauge",
        "help": "Number of tokens in the ring",
        "unit": ""
      }
    ],
    "http_requests_total": [
      {
        "type": "counter",
        "help": "Number of HTTP requests",
        "unit": ""
      },
      {
        "type": "counter",
        "help": "Amount of HTTP requests",
        "unit": ""
      }
    ]
  }
}
```

The following example returns only one metadata entry for each metric.

```
curl -G http://localhost:9090/api/v1/metadata?limit_per_metric=1

{
  "status": "success",
  "data": {
    "cortex_ring_tokens": [
      {
        "type": "gauge",
        "help": "Number of tokens in the ring",
        "unit": ""
      }
    ],
    "http_requests_total": [
      {
        "type": "counter",
        "help": "Number of HTTP requests",
        "unit": ""
      }
    ]
  }
}
```

The following example returns metadata only for the metric `http_requests_total`.

```
curl -G http://localhost:9090/api/v1/metadata?metric=http_requests_total

{
  "status": "success",
  "data": {
    "http_requests_total": [
      {
        "type": "counter",
        "help": "Number of HTTP requests",
        "unit": ""
      },
      {
        "type": "counter",
        "help": "Amount of HTTP requests",
        "unit": ""
      }
    ]
  }
}
```

### Alertmanagers

The following endpoint returns an overview of the current state of the Prometheus alertmanager discovery:

```
GET /api/v1/alertmanagers
```

Both the active and dropped Alertmanagers are part of the response.

```
$ curl http://localhost:9090/api/v1/alertmanagers
{
  "status": "success",
  "data": {
    "activeAlertmanagers": [
      {
        "url": "http://127.0.0.1:9090/api/v1/alerts"
      }
    ],
    "droppedAlertmanagers": [
      {
        "url": "http://127.0.0.1:9093/api/v1/alerts"
      }
    ]
  }
}
```

### Status

Following status endpoints expose current Prometheus configuration.

#### Config

The following endpoint returns currently loaded configuration file:

```
GET /api/v1/status/config
```

The config is returned as dumped YAML file. Due to limitation of the YAML library, YAML comments are not included.

```
$ curl http://localhost:9090/api/v1/status/config
{
  "status": "success",
  "data": {
    "yaml": "<content of the loaded config file in YAML>",
  }
}
```

#### Flags

The following endpoint returns flag values that Prometheus was configured with:

```
GET /api/v1/status/flags
```

All values are of the result type `string`.

```
$ curl http://localhost:9090/api/v1/status/flags
{
  "status": "success",
  "data": {
    "alertmanager.notification-queue-capacity": "10000",
    "alertmanager.timeout": "10s",
    "log.level": "info",
    "query.lookback-delta": "5m",
    "query.max-concurrency": "20",
    ...
  }
}
```

*New in v2.2*

#### Runtime Information

The following endpoint returns various runtime information properties about the Prometheus server:

```
GET /api/v1/status/runtimeinfo
```

The returned values are of different types, depending on the nature of the runtime property.

```
$ curl http://localhost:9090/api/v1/status/runtimeinfo
{
  "status": "success",
  "data": {
    "startTime": "2019-11-02T17:23:59.301361365+01:00",
    "CWD": "/",
    "reloadConfigSuccess": true,
    "lastConfigTime": "2019-11-02T17:23:59+01:00",
    "timeSeriesCount": 873,
    "corruptionCount": 0,
    "goroutineCount": 48,
    "GOMAXPROCS": 4,
    "GOGC": "",
    "GODEBUG": "",
    "storageRetention": "15d"
  }
}
```

**NOTE:** The exact returned runtime properties may change without notice between Prometheus versions.

*New in v2.14*

#### Build Information

The following endpoint returns various build information properties about the Prometheus server:

```
GET /api/v1/status/buildinfo
```

All values are of the result type `string`.

```
$ curl http://localhost:9090/api/v1/status/buildinfo
{
  "status": "success",
  "data": {
    "version": "2.13.1",
    "revision": "cb7cbad5f9a2823a622aaa668833ca04f50a0ea7",
    "branch": "master",
    "buildUser": "julius@desktop",
    "buildDate": "20191102-16:19:59",
    "goVersion": "go1.13.1"
  }
}
```

**NOTE:** The exact returned build properties may change without notice between Prometheus versions.

*New in v2.14*

#### TSDB Stats

The following endpoint returns various cardinality statistics about the Prometheus TSDB:

```
GET /api/v1/status/tsdb
```

URL query parameters: - `limit=<number>`: Limit the number of returned items to a given number for each set of statistics. By default, 10 items are returned.

The `data` section of the query result consists of - **headStats**: This provides the following data about the head block of the TSDB:  - **numSeries**: The number of series.  - **chunkCount**: The number of chunks.  - **minTime**: The current minimum timestamp in milliseconds.  - **maxTime**: The current maximum timestamp in milliseconds. - **seriesCountByMetricName:**  This will provide a list of metrics names and their series count. - **labelValueCountByLabelName:** This will provide a list of the label names and their value count. - **memoryInBytesByLabelName** This will provide a list of  the label names and memory used in bytes. Memory usage is calculated by  adding the length of all values for a given label name. - **seriesCountByLabelPair** This will provide a list of label value pairs and their series count.

```
$ curl http://localhost:9090/api/v1/status/tsdb
{
  "status": "success",
  "data": {
    "headStats": {
      "numSeries": 508,
      "chunkCount": 937,
      "minTime": 1591516800000,
      "maxTime": 1598896800143,
    },
    "seriesCountByMetricName": [
      {
        "name": "net_conntrack_dialer_conn_failed_total",
        "value": 20
      },
      {
        "name": "prometheus_http_request_duration_seconds_bucket",
        "value": 20
      }
    ],
    "labelValueCountByLabelName": [
      {
        "name": "__name__",
        "value": 211
      },
      {
        "name": "event",
        "value": 3
      }
    ],
    "memoryInBytesByLabelName": [
      {
        "name": "__name__",
        "value": 8266
      },
      {
        "name": "instance",
        "value": 28
      }
    ],
    "seriesCountByLabelValuePair": [
      {
        "name": "job=prometheus",
        "value": 425
      },
      {
        "name": "instance=localhost:9090",
        "value": 425
      }
    ]
  }
}
```

*New in v2.15*

#### WAL Replay Stats

The following endpoint returns information about the WAL replay:

```
GET /api/v1/status/walreplay
```

**read**: The number of segments replayed so far. **total**: The total number segments needed to be replayed. **progress**: The progress of the replay (0 - 100%). **state**: The state of the replay. Possible states: - **waiting**: Waiting for the replay to start. - **in progress**: The replay is in progress. - **done**: The replay has finished.

```
$ curl http://localhost:9090/api/v1/status/walreplay
{
  "status": "success",
  "data": {
    "min": 2,
    "max": 5,
    "current": 40,
    "state": "in progress"
  }
}
```

**NOTE:** This endpoint is available before the server has  been marked ready and is updated in real time to facilitate monitoring  the progress of the WAL replay.

*New in v2.28*

### TSDB Admin APIs

These are APIs that expose database functionalities for the advanced user. These APIs are not enabled unless the `--web.enable-admin-api` is set.

#### Snapshot

Snapshot creates a snapshot of all current data into `snapshots/<datetime>-<rand>` under the TSDB's data directory and returns the directory as response. It will optionally skip snapshotting data that is only present in the head block, and which has not yet been compacted to disk.

```
POST /api/v1/admin/tsdb/snapshot
PUT /api/v1/admin/tsdb/snapshot
```

URL query parameters:

- `skip_head=<bool>`: Skip data present in the head block. Optional.

```
$ curl -XPOST http://localhost:9090/api/v1/admin/tsdb/snapshot
{
  "status": "success",
  "data": {
    "name": "20171210T211224Z-2be650b6d019eb54"
  }
}
```

The snapshot now exists at `<data-dir>/snapshots/20171210T211224Z-2be650b6d019eb54`

*New in v2.1 and supports PUT from v2.9*

#### Delete Series

DeleteSeries deletes data for a selection of series in a time range.  The actual data still exists on disk and is cleaned up in future  compactions or can be explicitly cleaned up by hitting the [Clean Tombstones](https://prometheus.io/docs/prometheus/latest/querying/api/#clean-tombstones) endpoint.

If successful, a `204` is returned.

```
POST /api/v1/admin/tsdb/delete_series
PUT /api/v1/admin/tsdb/delete_series
```

URL query parameters:

- `match[]=<series_selector>`: Repeated label matcher argument that selects the series to delete. At least one `match[]` argument must be provided.
- `start=<rfc3339 | unix_timestamp>`: Start timestamp. Optional and defaults to minimum possible time.
- `end=<rfc3339 | unix_timestamp>`: End timestamp. Optional and defaults to maximum possible time.

Not mentioning both start and end times would clear all the data for the matched series in the database.

Example:

```
$ curl -X POST \
  -g 'http://localhost:9090/api/v1/admin/tsdb/delete_series?match[]=up&match[]=process_start_time_seconds{job="prometheus"}'
```

**NOTE:** This endpoint marks samples from series as  deleted, but will not necessarily prevent associated series metadata  from still being returned in metadata queries for the affected time  range (even after cleaning tombstones). The exact extent of metadata  deletion is an implementation detail that may change in the future.

*New in v2.1 and supports PUT from v2.9*

#### Clean Tombstones

CleanTombstones removes the deleted data from disk and cleans up the  existing tombstones. This can be used after deleting series to free up  space.

If successful, a `204` is returned.

```
POST /api/v1/admin/tsdb/clean_tombstones
PUT /api/v1/admin/tsdb/clean_tombstones
```

This takes no parameters or body.

```
$ curl -XPOST http://localhost:9090/api/v1/admin/tsdb/clean_tombstones
```

*New in v2.1 and supports PUT from v2.9*

### Remote Write Receiver

Prometheus can be configured as a receiver for the Prometheus remote write protocol. This is not considered an efficient way of ingesting samples. Use it with caution for specific low-volume use cases. It is not suitable for replacing the ingestion via scraping and turning Prometheus into a push-based metrics collection system.

Enable the remote write receiver by setting `--web.enable-remote-write-receiver`. When enabled, the remote write receiver endpoint is `/api/v1/write`. Find more details [here](https://prometheus.io/docs/prometheus/latest/storage/#overview).

*New in v2.33*

## Remote Read API



This is not currently considered part of the stable API and is subject to change even between non-major version releases of Prometheus.

### Format overview

The API response format is JSON. Every successful API request returns a `2xx` status code.

Invalid requests that reach the API handlers return a JSON error object and one of the following HTTP response codes:

- `400 Bad Request` when parameters are missing or incorrect.
- `422 Unprocessable Entity` when an expression can't be executed ([RFC4918](https://tools.ietf.org/html/rfc4918#page-78)).
- `503 Service Unavailable` when queries time out or abort.

Other non-`2xx` codes may be returned for errors occurring before the API endpoint is reached.

An array of warnings may be returned if there are errors that do not inhibit the request execution. All of the data that was successfully collected will be returned in the data field.

The JSON response envelope format is as follows:

```
{
  "status": "success" | "error",
  "data": <data>,

  // Only set if status is "error". The data field may still hold
  // additional data.
  "errorType": "<string>",
  "error": "<string>",

  // Only if there were warnings while executing the request.
  // There will still be data in the data field.
  "warnings": ["<string>"]
}
```

Generic placeholders are defined as follows:

- `<rfc3339 | unix_timestamp>`: Input timestamps may be provided either in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format or as a Unix timestamp in seconds, with optional decimal places for sub-second precision. Output timestamps are always represented as Unix timestamps in seconds.
- `<series_selector>`: Prometheus [time series selectors](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-series-selectors) like `http_requests_total` or `http_requests_total{method=~"(GET|POST)"}` and need to be URL-encoded.
- `<duration>`: [Prometheus duration strings](https://prometheus.io/docs/prometheus/latest/querying/basics/#time_durations). For example, `5m` refers to a duration of 5 minutes.
- `<bool>`: boolean values (strings `true` and `false`).

Note: Names of query parameters that may be repeated end with `[]`.

### Remote Read API

> This is not currently considered part of the stable API and is subject to  change even between non-major version releases of Prometheus.
> 这目前不被视为稳定 API 的一部分，即使在 Prometheus 的非主要版本版本之间也可能发生变化。

This API provides data read functionality from Prometheus. This interface expects [snappy](https://github.com/google/snappy) compression. The API definition is located [here](https://github.com/prometheus/prometheus/blob/master/prompb/remote.proto).
此 API 提供来自 Prometheus 的数据读取功能。此接口需要[快速](https://github.com/google/snappy)压缩。API 定义位于[此处](https://github.com/prometheus/prometheus/blob/master/prompb/remote.proto)。

Request are made to the following endpoint. ` /api/v1/read `
请求发送到以下端点。` /api/v1/读取 `

### Samples 样品

This returns a message that includes a list of raw samples.
这将返回一条消息，其中包含原始样本列表。

### Streamed Chunks 流式数据块

These streamed chunks utilize an XOR algorithm inspired by the [Gorilla](http://www.vldb.org/pvldb/vol8/p1816-teller.pdf) compression to encode the chunks. However, it provides resolution to the millisecond instead of to the second.
这些流式数据块利用受 [Gorilla](http://www.vldb.org/pvldb/vol8/p1816-teller.pdf) 压缩启发的 XOR 算法对数据块进行编码。但是，它提供的分辨率为毫秒，而不是秒。