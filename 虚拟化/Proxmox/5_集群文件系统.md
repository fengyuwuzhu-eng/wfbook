## 6. Proxmox Cluster File System (pmxcfs) 6. Proxmox集群文件系统（pmxcfs）

The Proxmox Cluster file system (“pmxcfs”) is a database-driven file system for storing configuration files, replicated in real time to all cluster nodes using corosync. We use this to store all Proxmox VE related configuration files.
Proxmox 集群文件系统（“pmxcfs”）是一个数据库驱动的文件系统，用于存储配置文件，使用 corosync 实时复制到所有集群节点。我们使用它来存储所有与Proxmox VE相关的配置文件。

Although the file system stores all data inside a persistent database on disk, a copy of the data resides in RAM. This imposes restrictions on the maximum size, which is currently 128 MiB. This is still enough to store the configuration of several thousand virtual machines.
尽管文件系统将所有数据存储在磁盘上的持久性数据库中，但数据的副本驻留在 RAM 中。这会对最大大小施加限制，当前为 128 MiB。这仍然足以存储数千个虚拟机的配置。

This system provides the following advantages:
该系统具有以下优点：

- Seamless replication of all configuration to all nodes in real time 
  将所有配置实时无缝复制到所有节点
- Provides strong consistency checks to avoid duplicate VM IDs 
  提供强大的一致性检查，以避免重复的 VM ID
- Read-only when a node loses quorum 
  节点失去仲裁时的只读
- Automatic updates of the corosync cluster configuration to all nodes 
  自动将 corosync 集群配置更新到所有节点
- Includes a distributed locking mechanism 
  包括分布式锁定机制

### 6.1. POSIX Compatibility 6.1. POSIX兼容性

The file system is based on FUSE, so the behavior is POSIX like. But some feature are simply not implemented, because we do not need them:
文件系统基于 FUSE，因此行为类似于 POSIX。但是有些功能根本没有实现，因为我们不需要它们：

- You can just generate normal files and directories, but no symbolic  links, … 
  您可以只生成普通文件和目录，但没有符号链接，...
- You can’t rename non-empty directories (because this makes it easier  to guarantee that VMIDs are unique). 
  不能重命名非空目录（因为这样可以更轻松地保证 VMID 是唯一的）。
- You can’t change file permissions (permissions are based on paths) 
  您无法更改文件权限（权限基于路径）
- O_EXCL creates were not atomic (like old NFS) 
  O_EXCL创建不是原子的（如旧的 NFS）
- O_TRUNC creates are not atomic (FUSE restriction) 
  创建O_TRUNC不是原子的（FUSE 限制）

### 6.2. File Access Rights 6.2. 文件访问权限

All files and directories are owned by user root and have group www-data. Only root has write permissions, but group www-data can read most files. Files below the following paths are only accessible by root:
所有文件和目录都归用户 root 所有，并具有组 www-data。只有 root 具有写入权限，但组 www-data 可以读取大多数文件。以下路径下的文件只能通过 root 访问：

```
/etc/pve/priv/
/etc/pve/nodes/${NAME}/priv/
```

### 6.3. Technology 6.3. 技术

We use the [Corosync Cluster Engine](https://www.corosync.org) for cluster communication, and [SQlite](https://www.sqlite.org) for the database file. The file system is implemented in user space using [FUSE](https://github.com/libfuse/libfuse).
我们使用 Corosync 集群引擎进行集群通信，并使用 SQlite 进行数据库文件。文件系统使用 FUSE 在用户空间中实现。

### 6.4. File System Layout 6.4. 文件系统布局

The file system is mounted at:
文件系统挂载在：

```
/etc/pve
```

#### 6.4.1. Files 6.4.1. 文件

| authkey.pub                                                  | Public key used by the ticket system 工单系统使用的公钥      |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ceph.conf                                                    | Ceph configuration file (note: /etc/ceph/ceph.conf is a symbolic link to this) Ceph 配置文件（注意：/etc/ceph/ceph.conf 是指向此的符号链接） |
| corosync.conf                                                | Corosync cluster configuration file (prior to Proxmox VE 4.x, this file was called cluster.conf) Corosync 集群配置文件（在 Proxmox VE 4.x 之前，此文件称为 cluster.conf） |
| datacenter.cfg 数据中心.cfg                                  | Proxmox VE datacenter-wide configuration (keyboard layout, proxy, …) Proxmox VE数据中心范围的配置（键盘布局，代理等） |
| domains.cfg 域名.cfg                                         | Proxmox VE authentication domains Proxmox VE认证域           |
| firewall/cluster.fw 防火墙/cluster.fw                        | Firewall configuration applied to all nodes 应用于所有节点的防火墙配置 |
| firewall/<NAME>.fw 防火墙/<NAME>.fw                          | Firewall configuration for individual nodes 单个节点的防火墙配置 |
| firewall/<VMID>.fw 防火墙/<VMID>.fw                          | Firewall configuration for VMs and containers VM 和容器的防火墙配置 |
| ha/crm_commands 哈/crm_commands                              | Displays HA operations that are currently being carried out by the CRM 显示 CRM 当前正在执行的 HA 操作 |
| ha/manager_status 公顷/manager_status                        | JSON-formatted information regarding HA services on the cluster 有关集群上 HA 服务的 JSON 格式信息 |
| ha/resources.cfg                                             | Resources managed by high availability, and their current state 由高可用性管理的资源及其当前状态 |
| nodes/<NAME>/config 节点/<NAME>/config                       | Node-specific configuration 特定于节点的配置                 |
| nodes/<NAME>/lxc/<VMID>.conf 节点/<NAME>/lxc/<VMID>.conf     | VM configuration data for LXC containers LXC 容器的 VM 配置数据 |
| nodes/<NAME>/openvz/ 节点/<NAME>/openvz/                     | Prior to Proxmox VE 4.0, used for container configuration data (deprecated, removed soon) 在 Proxmox VE 4.0 之前，用于容器配置数据（已弃用，即将删除） |
| nodes/<NAME>/pve-ssl.key 节点/<NAME>/pve-ssl.key             | Private SSL key for pve-ssl.pem pve-ssl.pem 的私有 SSL 密钥  |
| nodes/<NAME>/pve-ssl.pem 节点/<NAME>/pve-ssl.pem             | Public SSL certificate for web server (signed by cluster CA) Web 服务器的公共 SSL 证书（由集群 CA 签名） |
| nodes/<NAME>/pveproxy-ssl.key 节点/<NAME>/pveproxy-ssl.key   | Private SSL key for pveproxy-ssl.pem (optional) pveproxy-ssl.pem 的私有 SSL 密钥（可选） |
| nodes/<NAME>/pveproxy-ssl.pem 节点/<NAME>/pveproxy-ssl.pem   | Public SSL certificate (chain) for web server (optional override for pve-ssl.pem) Web 服务器的公共 SSL 证书（链）（pve-ssl.pem 的可选覆盖） |
| nodes/<NAME>/qemu-server/<VMID>.conf 节点/<NAME>/qemu-server/<VMID>.conf | VM configuration data for KVM VMs KVM 虚拟机的虚拟机配置数据 |
| priv/authkey.key 私人/authkey.key                            | Private key used by ticket system 工单系统使用的私钥         |
| priv/authorized_keys 私人/authorized_keys                    | SSH keys of cluster members for authentication 用于身份验证的集群成员的 SSH 密钥 |
| priv/ceph* 私人/CEPH*                                        | Ceph authentication keys and associated capabilities Ceph 身份验证密钥和相关功能 |
| priv/known_hosts 私人/known_hosts                            | SSH keys of the cluster members for verification 用于验证的集群成员的 SSH 密钥 |
| priv/lock/* 私密/锁/*                                        | Lock files used by various services to ensure safe cluster-wide operations 锁定各种服务使用的文件，以确保集群范围的安全操作 |
| priv/pve-root-ca.key 私人/pve-root-ca.key                    | Private key of cluster CA 集群CA的私钥                       |
| priv/shadow.cfg                                              | Shadow password file for PVE Realm users PVE Realm 用户的影子密码文件 |
| priv/storage/<STORAGE-ID>.pw 私密/存储/<STORAGE-ID>.pw       | Contains the password of a storage in plain text 以纯文本形式包含存储的密码 |
| priv/tfa.cfg                                                 | Base64-encoded two-factor authentication configuration Base64 编码的双因素身份验证配置 |
| priv/token.cfg                                               | API token secrets of all tokens 所有令牌的 API 令牌机密      |
| pve-root-ca.pem                                              | Public certificate of cluster CA 集群 CA 的公共证书          |
| pve-www.key                                                  | Private key used for generating CSRF tokens 用于生成 CSRF 令牌的私钥 |
| sdn/*                                                        | Shared configuration files for Software Defined Networking (SDN) 软件定义网络 （SDN） 的共享配置文件 |
| status.cfg 状态.cfg                                          | Proxmox VE external metrics server configuration Proxmox VE外部指标服务器配置 |
| storage.cfg 存储.cfg                                         | Proxmox VE storage configuration Proxmox VE存储配置          |
| user.cfg 用户.cfg                                            | Proxmox VE access control configuration (users/groups/…) Proxmox VE访问控制配置（用户/组/...） |
| virtual-guest/cpu-models.conf                                | For storing custom CPU models 用于存储自定义 CPU 型号        |
| vzdump.cron                                                  | Cluster-wide vzdump backup-job schedule 集群范围的 vzdump 备份作业调度 |

#### 6.4.2. Symbolic links 6.4.2. 符号链接

Certain directories within the cluster file system use symbolic links, in order to point to a node’s own configuration files. Thus, the files pointed to in the table below refer to different files on each node of the cluster.
集群文件系统中的某些目录使用符号链接，以便指向节点自己的配置文件。因此，下表中指向的文件指的是群集的每个节点上的不同文件。

| local 当地      | nodes/<LOCAL_HOST_NAME> 节点/<LOCAL_HOST_NAME>               |
| --------------- | ------------------------------------------------------------ |
| lxc             | nodes/<LOCAL_HOST_NAME>/lxc/ 节点/<LOCAL_HOST_NAME>/lxc/     |
| openvz OpenVZ的 | nodes/<LOCAL_HOST_NAME>/openvz/ (deprecated, removed soon) nodes/<LOCAL_HOST_NAME>/openvz/（已弃用，即将删除） |
| qemu-server     | nodes/<LOCAL_HOST_NAME>/qemu-server/ 节点/<LOCAL_HOST_NAME>/qemu-server/ |

#### 6.4.3. Special status files for debugging (JSON) 6.4.3. 用于调试的特殊状态文件 （JSON）

| .version 。版本 | File versions (to detect file modifications) 文件版本（用于检测文件修改） |
| --------------- | ------------------------------------------------------------ |
| .members 。成员 | Info about cluster members 有关集群成员的信息                |
| .vmlist         | List of all VMs 所有 VM 的列表                               |
| .clusterlog     | Cluster log (last 50 entries) 群集日志（最近 50 个条目）     |
| .rrd            | RRD data (most recent entries) RRD 数据（最新条目）          |

#### 6.4.4. Enable/Disable debugging 6.4.4. 启用/禁用调试

You can enable verbose syslog messages with:
您可以使用以下方式启用详细的 syslog 消息：

```
echo "1" >/etc/pve/.debug
```

And disable verbose syslog messages with:
并使用以下命令禁用详细的 syslog 消息：

```
echo "0" >/etc/pve/.debug
```

### 6.5. Recovery 6.5. 恢复

If you have major problems with your Proxmox VE host, for example hardware issues, it could be helpful to copy the pmxcfs database file /var/lib/pve-cluster/config.db, and move it to a new Proxmox VE host. On the new host (with nothing running), you need to stop the pve-cluster service and replace the config.db file (required permissions 0600). Following this, adapt /etc/hostname and /etc/hosts according to the lost Proxmox VE host, then reboot and check (and don’t forget your VM/CT data).
如果您的 Proxmox VE 主机存在重大问题，例如硬件问题，复制 pmxcfs 数据库文件 /var/lib/pve-cluster/config.db 并将其移动到新的 Proxmox VE 主机可能会有所帮助。在新主机上（未运行任何内容），您需要停止 pve-cluster 服务并替换 config.db 文件（所需权限 0600）。在此之后，根据丢失的 Proxmox VE 主机调整 /etc/hostname 和 /etc/hosts，然后重新启动并检查（不要忘记您的 VM/CT 数据）。

#### 6.5.1. Remove Cluster Configuration 6.5.1. 删除集群配置

The recommended way is to reinstall the node after you remove it from your cluster. This ensures that all secret cluster/ssh keys and any shared configuration data is destroyed.
建议的方法是在从群集中删除节点后重新安装该节点。这可确保销毁所有机密群集/ssh 密钥和任何共享配置数据。

In some cases, you might prefer to put a node back to local mode without reinstalling, which is described in [Separate A Node Without Reinstalling](https://192.168.1.20:8006/pve-docs/pve-admin-guide.html#pvecm_separate_node_without_reinstall)
在某些情况下，您可能更愿意将节点放回本地模式而不重新安装，这在单独节点而不重新安装中进行了描述

#### 6.5.2. Recovering/Moving Guests from Failed Nodes 6.5.2. 从故障节点恢复/移动客户机

For the guest configuration files in nodes/<NAME>/qemu-server/ (VMs) and nodes/<NAME>/lxc/ (containers), Proxmox VE sees the containing node <NAME> as the owner of the respective guest. This concept enables the usage of local locks instead of expensive cluster-wide locks for preventing concurrent guest configuration changes.
对于nodes/<NAME>/qemu-server/（VM）和nodes/<NAME>/lxc/（容器）中的客户机配置文件，Proxmox VE将包含节点视为<NAME>相应客户机的所有者。此概念支持使用本地锁而不是昂贵的集群范围锁，以防止并发客户机配置更改。

As a consequence, if the owning node of a guest fails (for example, due to a power outage, fencing event, etc.), a regular migration is not possible (even if all the disks are located on shared storage), because such a local lock on the (offline) owning node is unobtainable. This is not a problem for HA-managed guests, as Proxmox VE’s High Availability stack includes the necessary (cluster-wide) locking and watchdog functionality to ensure correct and automatic recovery of guests from fenced nodes.
因此，如果客户机的拥有节点发生故障（例如，由于断电、隔离事件等），则无法进行定期迁移（即使所有磁盘都位于共享存储上），因为（脱机）拥有节点上的此类本地锁是无法获得的。对于HA管理的访客来说，这不是问题，因为Proxmox VE的高可用性堆栈包括必要的（集群范围）锁定和看门狗功能，以确保从受围栏的节点正确和自动地恢复访客。

If a non-HA-managed guest has only shared disks (and no other local resources which are only available on the failed node), a manual recovery is possible by simply moving the guest configuration file from the failed node’s directory in /etc/pve/ to an online node’s directory (which changes the logical owner or location of the guest).
如果非 HA 管理的客户机只有共享磁盘（而没有其他仅在故障节点上可用的本地资源），则只需将客户机配置文件从故障节点的 /etc/pve/ 目录移动到联机节点的目录（这会更改客户机的逻辑所有者或位置）即可手动恢复。

For example, recovering the VM with ID 100 from an offline node1 to another node node2 works by running the following command as root on any member node of the cluster:
例如，通过在群集的任何成员节点上以 root 身份运行以下命令，将 ID 为 100 的 VM 从脱机节点 1 恢复到另一个节点节点 node2：

```
mv /etc/pve/nodes/node1/qemu-server/100.conf /etc/pve/nodes/node2/qemu-server/
```

| ![Warning](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAMVUlEQVRogdWZeXDVVZbHP7/f27JBwtJIiCERRFlbx5FuHRrRBgtBsRIwCCOrFmGmiDBjYVNlQlgiQjU6IjI4xLJxGf5QGp0Cbaftsu3Rhu6aYXqgLZoWEsjyyDP7S972e7/l3vnj5cW3Ji9M/zOn6lRS997fvd/vueece+59ipSS/89iv5mPZEQQQsS23RQARVEAUFUVRVFQog0ZyogJSClld3c327Ztw7IsLMuKto90KgBsNhtVVVXMnj2bvLw87Ha7HBEJKWXGKoSQXV1dcsuWLfLSpUsyKkKIIdWyrLTqdrvlU089Jc+cOSM9Ho8Mh8NSCCEzxTRi8JWVlbKtre0vAt6yLGmapmxtbZXr1q2TZ86ckW1tbSMikTH4GzduyKqqqkHwsSA1TZOhUChOg8HgoBqGIQ3DSAk+VleuXDliEspwviullD09PbzwwgscO3Yszt91XScQCNDZ2YlhGIPfuFwu7Pb48FJVlZycnEG/z8/PRwiBqqqDYzweD88//zyrV69m7ty5jBs3DofDMWRgD0lASik9Hg979uzh2LFjcYEaCoVob2/n2q9+hbZ585BGSCWltbVMr61NtSYbN25k7dq1zJkzZ1gSaqrGWPD79+9PAh8MBuns7OTie+8R2rwZCYOaqTTt3cuf6+qSwAMcP36co0eP8vXXX9Pd3Y1hGMg0lk65A1HwdXV1vPHGG0mW7+jo4A8/+xn2BAAAI0riQOnu3cyork7Zt3btWtavX89dd92VdieSCEgppdvt5sCBAxw5ciSuLxQK0dTURMOHHyJ37hwh1NSiAKU7djDzxRdT9q9YsYJt27YxY8aMlCTiCEgp5eXLl6mvr+fVV1+NmygYDNLW1sY3J09ipLEYQDPw2sBfCTwMLARKgKwhiNxWU8OsXbvi2qLYnnzySSorK1PvRGyqvH79uty6dWtSLg8EAvLKlSvyo1275M8hSV8H+eMBvRPkP9Vslp0tV6W3u12+c7hOTgT5NyAXgtwE8gTIUyn0D9XV0jAMqet6klZUVMjPP/88KcWqUcs3NjZy+PBhDh06FGeFqNtcOnECY8+euICVwDWgFtj/m1/wD+8f5xtg6uy5ZI+5BSkkU6fexgu7tvLWhd/x1tXL5P/905wAggnzSODavn388Sc/SblDL7/8Mq+99hqXL1+OC2zb7t27uX79+u7Dhw+ndJvW1lYaP/qI0EDKS1z0XeDjC7/l9llz+d6EWxjv0imdcgeFRcVofR46vm1Cx8ndP5hP3qjR/GDuX/GbC5/iberl1qirxGjv73+PYRjc8tBDcVhGjRpFRUUF27dvp7i4mPz8fFwuV2QHVq1aldLyDQ0NXDt5En91NRIQCRqNHld2HsLUCfu6GD9mNIoVQggDy9RQpYLTbkdV7Vh6CH9vJ/fcfz/vALsAN2AlzHv1wAEu1tTExUI0Hl555RXq6upobm4mEAhECEyePDkOvK7rtLS0cOP0aby1tUnAo2oNkFAUSTjoRfN+ix7wgjRBShACVVFQRGSkHvTypwtnmXHPQhrbb3D0k1McAdpiDBLVhp/+lIvV1UlV7oQJE8jNzcXtduPz+ZIPMtM0aWhooPH99+mtrU1ymVRqUxUQFlJYSBFGCivGOSyEaSCFAGlhd+Vy7w/n43BmM3POXWx69hl8AyMTDXTl4EEu7t2bCBGAQCCAruupCdjtdrp3705r+ViN22YhsUwdyzRBCpACyzIRMnpngCxXNjYlMk4L+ggoYXxp5pbAlX37cDgcSQSEEAxmoVgQg/9nAP67bVdAUcFmQ3W6IgtIiWUKLCGwLGvQj69e+m+EsBB6iGB/N/3e9oyNlIgRYm5kiR2JH0L6MkFYEi0UQKAycdJUbIodT3Mjpu6n3xfCptoRlomQCqZpRkhLCykMhLBQSV1HJbalKnvSF3MpNO0OSIEwDWyuPCaVzCRv7ER8Ph+mtJM35lZsdjvuxktYhobDkYOCgqJEDWLLaAfSVc1p78SJO2AAvUBggLUNKIx2Kgqjv3crY2wOiqaqKKoKihKJCctCC/npbW+jq7sbS7UjkGCZCCkQQkdJsV6mRWHGBH4HLHpxF3LcGDq6u7nw2S85++V/4gb0kB9hFoAZwuZwgc2BqjpQVRWbzYXd4cDlysHn7WJi0W2EfH24XA6EjKySqhTPtDRPIjB4XUtoPw3sKV/O+KJipJT4V63mq3/7Obu21/LN/5xl9l/PIys7G2fOaBS7E5vNQrU7UW0KNlUFp5P8MeO5/8HFhPo7CXr7MMIaQW8neSkMlqnEEYj1s8QJbwXaWpopmDgJh93OqHGFLFy9jjunTeHNo2uAvUy54/uMuaUYV24BUpVYpoVEwaY4UVUbitNJ9ugxOBw2tEAPfX29QCjuVB9OEmNBTdeRGEj3A56OdkwtgDDCCKFjz8ql6N55/G3VcRouX+SXH72Ht6udcCg4cJiJSPIn8oCloIKUKAhURUUIiVCjx128pjtrEiVtFkrMNNOBA+s34XG3YIRDSMtAkSbOrDzuvOchHnmiklEFY3n76G7Of/nv9Ht7EMJCSjGoljCxjOBAnaSjhYPowevDZrx04FMSGLwnJEzmAOYCn33wAUYoiGXoSMsEoeNwZTO2aDrzFpWxck0VJVOn4fd2E/T7oneNyOFlGkjLwNTD6FoILRQEa/hDcyhJIuB0OlFVNeVE04B3XjnC+d9+hRYKYJlhpDBBGDidDiaUfp/xk24nJ3c0eaPzsKsgzEhtZJkGIuzDNDRCAR99fb309XYhNAYPsnQ6IgJSSgoKCihavDilJZ4Aajf8HVf/fAnLCCNNAyktECaqIsgbV8So0WMHrn2RGLBMHREOYBg6eiiIFgzQ7/US8vmYoEDuENa/u6oqcwJRPysoKOC+N9+kcNGiJGvkAQuADY+twn3tCuFg/4CVDbB0VKHhzHbhdGVhs6kgDKTuR9f86KEAWtBHd0c73p52pB5Av5KewJxnnmHeoUOEw+EkjHEEYi8MEHlFKyws5IfHjlG4cGHSxJOA1cATPy7nT388j+73YoYDCEuP1DhSRrKOlFhmmLAWQNMCBHw9tHtu8K2nBcsI8uGxf8HoiRBINNTtjz7KQ/X1xL6iRDHGvubZAfr7+1Nuz+TJk6G+nv/atInmX/86rq8AWAlUrahk/Fio/8XHjM4fi93pHCgRFCzLQtd1tFAQLeCjs9NNb4cHxdL44J8PozfD7XyXRqNy97p1PPz220gp0XU9zriKogw+SaqqGtmB48ePU15enkRASklRURH31tcz6cEHk1JrAfAUcEcPLLjvMU69/694uzsI+X3093TS5blBl8eNt72VHk8Tfd9eR+vv4MQ/HkZpiJwttgTL3/Hoo2nBNzY2smjRIhYsWEBBQQEulyvyLuT3+2VTUxM7d+7k5MmTKXNuS0sL555+mtYvv0zqE0A7kavhqFL4oAlCCWOygGIiqTiHyMnuTBgz/bHHKDt9GillnN8D+P1+ysrKWLJkCdOmTWPWrFmUlpZGCAghpN/vp7m5mZqaGl5//XUKCwtJFLfbzX+sX8+Nr75K6rtZiXr49KVLKf/4Y4QQ6LqeBP6RRx6hvLycadOmMXPmTEpKSsjNzf3uZS6WRHV1NadOnUpaTEpJa2sr5zZupOkmSaQqk2csWcLyTz4BQNO0uL7GxkbWr1+fErzNZlMGw1lVVSUvL4+SkhL27dvH8uXL8Xg8ceABiouLue+ttyieN2+IK2Z6TRx/5+LFacE3NDRQWVmZFjwknAOxJF566SW2bNnChQsXkmKipKSEB959l9vmzcvo1pZOpz/8ME98+mla8Bs2bGDZsmVpwUOa5/VEd0oXE319fXxWXs43Z88m9Q0n03/0I1YPJIRE8OfOnWPHjh2UlZUNCT4tgUQSO3fupKqqigceeGCwP/a7VM8emUg0VcbK+fPn2bp1KytWrBgW/JAEEknU1NTw7LPPMn/+/GFBZQI8lZw/f57nnnuO5cuXM2XKlGHBD0sgkURdXR2PP/44FRUVNwV+qP7Tp09z8ODBjNxmRAQSSRw4cIBly5axdOnSvwh4RVH44osv2L9/P2VlZRlbfkQEEkls376djo4OQqHE83bk4nK5EEKwZs0aSktLRwR+RATgOxItLS1cu3aNvr6+wTfK/4tEfzeeMmUKkydPzhg8jJAAREgEg0H6+vrQNC2pFL8ZUVWVrKws8vPzycnJQVXVjH/s/F/lgJiyQFHragAAAABJRU5ErkJggg==) | Before manually recovering a guest like this, make absolutely sure that the failed source node is really powered off/fenced. Otherwise Proxmox VE’s locking principles are violated by the mv command, which can have unexpected consequences. 在像这样手动恢复客户机之前，请绝对确保故障源节点确实已关闭电源/被隔离。否则，mv 命令会违反 Proxmox VE 的锁定原则，这可能会产生意想不到的后果。 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
|                                                              |                                                              |

| ![Warning](data:image/png;base64,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) | Guests with local disks (or other local resources which are only available on the offline node) are not recoverable like this. Either wait for the failed node to rejoin the cluster or restore such guests from backups. 具有本地磁盘（或仅在脱机节点上可用的其他本地资源）的客户机无法像这样恢复。等待发生故障的节点重新加入集群，或从备份中还原此类客户机。 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
|                                                              |                                                              |